{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a37e66",
   "metadata": {},
   "source": [
    "# Text Diffusion: From First Principles to Production\n",
    "\n",
    "**The core idea**: What if instead of generating text left-to-right, we could generate all tokens at once and *iteratively refine* them? Like sculpting: start with a rough block, chip away until the statue emerges.\n",
    "\n",
    "This is diffusion for text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb89469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pre_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x42c6ce850>> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:593\u001b[0m, in \u001b[0;36m_WandbInit._pre_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_pause()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:803\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    802\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n",
      "\u001b[0;32m--> 803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_pause(pause)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:330\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n",
      "\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    329\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n",
      "\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, nowait)\u001b[0m\n",
      "\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[0m, in \u001b[0;36mAsyncioManager.run\u001b[0;34m(self, fn)\u001b[0m\n",
      "\u001b[1;32m    133\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule(fn, daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mCancelledError:\n",
      "\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n",
      "\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n",
      "\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[0m, in \u001b[0;36mAsyncioManager._wrap\u001b[0;34m(self, fn, daemon, name)\u001b[0m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task \u001b[38;5;241m:=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcurrent_task()):\n",
      "\u001b[1;32m    217\u001b[0m         task\u001b[38;5;241m.\u001b[39mset_name(name)\n",
      "\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "    \u001b[0;31m[... skipping similar frames: ServiceClient._send_server_request at line 64 (2 times), StreamWriter.drain at line 366 (2 times), ServiceClient.publish at line 38 (2 times), AsyncioManager.run_soon.<locals>.fn_wrap_exceptions at line 181 (1 times)]\u001b[0m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/events.py:93\u001b[0m, in \u001b[0;36mEventManager.trigger\u001b[0;34m(self, event, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks[event][:]:\n",
      "\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 93\u001b[0m         func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "\u001b[1;32m     95\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_on_error:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:604\u001b[0m, in \u001b[0;36m_WandbInit._post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;32m    603\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_resume()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:811\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    810\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n",
      "\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_resume(resume)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:334\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n",
      "\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    333\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n",
      "\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, nowait)\u001b[0m\n",
      "\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[0m, in \u001b[0;36mAsyncioManager.run\u001b[0;34m(self, fn)\u001b[0m\n",
      "\u001b[1;32m    133\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule(fn, daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mCancelledError:\n",
      "\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n",
      "\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n",
      "\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[0m, in \u001b[0;36mAsyncioManager._wrap\u001b[0;34m(self, fn, daemon, name)\u001b[0m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task \u001b[38;5;241m:=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcurrent_task()):\n",
      "\u001b[1;32m    217\u001b[0m         task\u001b[38;5;241m.\u001b[39mset_name(name)\n",
      "\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "    \u001b[0;31m[... skipping similar frames: ServiceClient._send_server_request at line 64 (2 times), StreamWriter.drain at line 366 (2 times), ServiceClient.publish at line 38 (2 times), AsyncioManager.run_soon.<locals>.fn_wrap_exceptions at line 181 (1 times)]\u001b[0m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/events.py:93\u001b[0m, in \u001b[0;36mEventManager.trigger\u001b[0;34m(self, event, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks[event][:]:\n",
      "\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 93\u001b[0m         func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "\u001b[1;32m     95\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_on_error:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:593\u001b[0m, in \u001b[0;36m_WandbInit._pre_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_pause()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:803\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    802\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n",
      "\u001b[0;32m--> 803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_pause(pause)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:330\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n",
      "\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    329\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n",
      "\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, nowait)\u001b[0m\n",
      "\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[0m, in \u001b[0;36mAsyncioManager.run\u001b[0;34m(self, fn)\u001b[0m\n",
      "\u001b[1;32m    133\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule(fn, daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mCancelledError:\n",
      "\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n",
      "\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n",
      "\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[0m, in \u001b[0;36mAsyncioManager._wrap\u001b[0;34m(self, fn, daemon, name)\u001b[0m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task \u001b[38;5;241m:=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcurrent_task()):\n",
      "\u001b[1;32m    217\u001b[0m         task\u001b[38;5;241m.\u001b[39mset_name(name)\n",
      "\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "    \u001b[0;31m[... skipping similar frames: ServiceClient._send_server_request at line 64 (174 times), StreamWriter.drain at line 366 (174 times), ServiceClient.publish at line 38 (174 times), AsyncioManager.run_soon.<locals>.fn_wrap_exceptions at line 181 (173 times)]\u001b[0m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/events.py:93\u001b[0m, in \u001b[0;36mEventManager.trigger\u001b[0;34m(self, event, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks[event][:]:\n",
      "\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 93\u001b[0m         func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "\u001b[1;32m     95\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_on_error:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:604\u001b[0m, in \u001b[0;36m_WandbInit._post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;32m    603\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_resume()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:811\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    810\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n",
      "\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_resume(resume)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:334\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n",
      "\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    333\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n",
      "\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, nowait)\u001b[0m\n",
      "\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[0m, in \u001b[0;36mAsyncioManager.run\u001b[0;34m(self, fn)\u001b[0m\n",
      "\u001b[1;32m    133\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule(fn, daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mCancelledError:\n",
      "\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n",
      "\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n",
      "\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[0m, in \u001b[0;36mAsyncioManager._wrap\u001b[0;34m(self, fn, daemon, name)\u001b[0m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task \u001b[38;5;241m:=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcurrent_task()):\n",
      "\u001b[1;32m    217\u001b[0m         task\u001b[38;5;241m.\u001b[39mset_name(name)\n",
      "\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "    \u001b[0;31m[... skipping similar frames: ServiceClient._send_server_request at line 64 (2 times), StreamWriter.drain at line 366 (2 times), ServiceClient.publish at line 38 (2 times), AsyncioManager.run_soon.<locals>.fn_wrap_exceptions at line 181 (1 times)]\u001b[0m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/selector_events.py:1057\u001b[0m, in \u001b[0;36m_SelectorSocketTransport.write\u001b[0;34m(self, data)\u001b[0m\n",
      "\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer:\n",
      "\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# Optimization: try to send now.\u001b[39;00m\n",
      "\u001b[1;32m   1056\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m-> 1057\u001b[0m         n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msend(data)\n",
      "\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mBlockingIOError\u001b[39;00m, \u001b[38;5;167;01mInterruptedError\u001b[39;00m):\n",
      "\u001b[1;32m   1059\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating toy datasets...\n",
      "Creating tiny model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "socket.send() raised exception.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trainer...\n",
      "\n",
      "Running smoke test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "socket.send() raised exception.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b875f6f4bf7b43809c30a55ad29e0684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting smoke test training...\n",
      "   Model params: 1,663,473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 complete:\n",
      "   Avg Loss: 10.8309\n",
      "   Accuracy: 0.0000\n",
      "\n",
      " Smoke test complete! No errors detected.\n",
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x42c6ce850>> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:604\u001b[0m, in \u001b[0;36m_WandbInit._post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;32m    603\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_resume()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:811\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    810\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n",
      "\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_resume(resume)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:334\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n",
      "\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    333\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n",
      "\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, nowait)\u001b[0m\n",
      "\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[0m, in \u001b[0;36mAsyncioManager.run\u001b[0;34m(self, fn)\u001b[0m\n",
      "\u001b[1;32m    133\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule(fn, daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mCancelledError:\n",
      "\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n",
      "\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n",
      "\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[0m, in \u001b[0;36mAsyncioManager._wrap\u001b[0;34m(self, fn, daemon, name)\u001b[0m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task \u001b[38;5;241m:=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcurrent_task()):\n",
      "\u001b[1;32m    217\u001b[0m         task\u001b[38;5;241m.\u001b[39mset_name(name)\n",
      "\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "    \u001b[0;31m[... skipping similar frames: ServiceClient._send_server_request at line 64 (22 times), StreamWriter.drain at line 366 (22 times), ServiceClient.publish at line 38 (22 times), AsyncioManager.run_soon.<locals>.fn_wrap_exceptions at line 181 (21 times)]\u001b[0m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/events.py:93\u001b[0m, in \u001b[0;36mEventManager.trigger\u001b[0;34m(self, event, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks[event][:]:\n",
      "\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 93\u001b[0m         func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "\u001b[1;32m     95\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_on_error:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:593\u001b[0m, in \u001b[0;36m_WandbInit._pre_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_pause()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:803\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    802\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n",
      "\u001b[0;32m--> 803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_pause(pause)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:330\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n",
      "\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    329\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n",
      "\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, nowait)\u001b[0m\n",
      "\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[0m, in \u001b[0;36mAsyncioManager.run\u001b[0;34m(self, fn)\u001b[0m\n",
      "\u001b[1;32m    133\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule(fn, daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mCancelledError:\n",
      "\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n",
      "\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n",
      "\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[0m, in \u001b[0;36mAsyncioManager._wrap\u001b[0;34m(self, fn, daemon, name)\u001b[0m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task \u001b[38;5;241m:=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcurrent_task()):\n",
      "\u001b[1;32m    217\u001b[0m         task\u001b[38;5;241m.\u001b[39mset_name(name)\n",
      "\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "    \u001b[0;31m[... skipping similar frames: ServiceClient._send_server_request at line 64 (2 times), StreamWriter.drain at line 366 (2 times), ServiceClient.publish at line 38 (2 times), AsyncioManager.run_soon.<locals>.fn_wrap_exceptions at line 181 (1 times)]\u001b[0m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/events.py:93\u001b[0m, in \u001b[0;36mEventManager.trigger\u001b[0;34m(self, event, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks[event][:]:\n",
      "\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 93\u001b[0m         func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "\u001b[1;32m     95\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_on_error:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:604\u001b[0m, in \u001b[0;36m_WandbInit._post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;32m    603\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_resume()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:811\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    810\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n",
      "\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_resume(resume)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:334\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n",
      "\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    333\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n",
      "\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, nowait)\u001b[0m\n",
      "\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[0m, in \u001b[0;36mAsyncioManager.run\u001b[0;34m(self, fn)\u001b[0m\n",
      "\u001b[1;32m    133\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule(fn, daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mCancelledError:\n",
      "\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n",
      "\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n",
      "\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[0m, in \u001b[0;36mAsyncioManager._wrap\u001b[0;34m(self, fn, daemon, name)\u001b[0m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task \u001b[38;5;241m:=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcurrent_task()):\n",
      "\u001b[1;32m    217\u001b[0m         task\u001b[38;5;241m.\u001b[39mset_name(name)\n",
      "\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "    \u001b[0;31m[... skipping similar frames: ServiceClient._send_server_request at line 64 (2 times), StreamWriter.drain at line 366 (2 times), ServiceClient.publish at line 38 (2 times), AsyncioManager.run_soon.<locals>.fn_wrap_exceptions at line 181 (1 times)]\u001b[0m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/events.py:93\u001b[0m, in \u001b[0;36mEventManager.trigger\u001b[0;34m(self, event, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks[event][:]:\n",
      "\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 93\u001b[0m         func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "\u001b[1;32m     95\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_on_error:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:593\u001b[0m, in \u001b[0;36m_WandbInit._pre_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_pause()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:803\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    802\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n",
      "\u001b[0;32m--> 803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_pause(pause)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:330\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n",
      "\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    329\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n",
      "\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, nowait)\u001b[0m\n",
      "\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[0m, in \u001b[0;36mAsyncioManager.run\u001b[0;34m(self, fn)\u001b[0m\n",
      "\u001b[1;32m    133\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule(fn, daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mCancelledError:\n",
      "\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n",
      "\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n",
      "\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[0m, in \u001b[0;36mAsyncioManager._wrap\u001b[0;34m(self, fn, daemon, name)\u001b[0m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task \u001b[38;5;241m:=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcurrent_task()):\n",
      "\u001b[1;32m    217\u001b[0m         task\u001b[38;5;241m.\u001b[39mset_name(name)\n",
      "\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "    \u001b[0;31m[... skipping similar frames: ServiceClient._send_server_request at line 64 (174 times), StreamWriter.drain at line 366 (174 times), ServiceClient.publish at line 38 (174 times), AsyncioManager.run_soon.<locals>.fn_wrap_exceptions at line 181 (173 times)]\u001b[0m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/events.py:93\u001b[0m, in \u001b[0;36mEventManager.trigger\u001b[0;34m(self, event, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks[event][:]:\n",
      "\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 93\u001b[0m         func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "\u001b[1;32m     95\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_on_error:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:604\u001b[0m, in \u001b[0;36m_WandbInit._post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;32m    603\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_resume()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:811\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    810\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n",
      "\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_resume(resume)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:334\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n",
      "\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    333\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n",
      "\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, nowait)\u001b[0m\n",
      "\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[0m, in \u001b[0;36mAsyncioManager.run\u001b[0;34m(self, fn)\u001b[0m\n",
      "\u001b[1;32m    133\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule(fn, daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mCancelledError:\n",
      "\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n",
      "\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n",
      "\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[0m, in \u001b[0;36mAsyncioManager._wrap\u001b[0;34m(self, fn, daemon, name)\u001b[0m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task \u001b[38;5;241m:=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcurrent_task()):\n",
      "\u001b[1;32m    217\u001b[0m         task\u001b[38;5;241m.\u001b[39mset_name(name)\n",
      "\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "    \u001b[0;31m[... skipping similar frames: ServiceClient._send_server_request at line 64 (2 times), StreamWriter.drain at line 366 (2 times), ServiceClient.publish at line 38 (2 times), AsyncioManager.run_soon.<locals>.fn_wrap_exceptions at line 181 (1 times)]\u001b[0m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n",
      "\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/streams.py:366\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    364\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n",
      "\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n",
      "\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n",
      "\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/selector_events.py:1057\u001b[0m, in \u001b[0;36m_SelectorSocketTransport.write\u001b[0;34m(self, data)\u001b[0m\n",
      "\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer:\n",
      "\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# Optimization: try to send now.\u001b[39;00m\n",
      "\u001b[1;32m   1056\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m-> 1057\u001b[0m         n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msend(data)\n",
      "\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mBlockingIOError\u001b[39;00m, \u001b[38;5;167;01mInterruptedError\u001b[39;00m):\n",
      "\u001b[1;32m   1059\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# ============== SMOKE TEST SETUP ==============\n",
    "# This is a minimal, fast test to validate your training loop\n",
    "\n",
    "# 1. Create tiny synthetic dataset (no download needed)\n",
    "def create_toy_dataset(n_samples=50, seq_len=32, vocab_size=50257):\n",
    "    \"\"\"Create a tiny random dataset for quick testing\"\"\"\n",
    "    tokens = t.randint(0, vocab_size, (n_samples, seq_len))\n",
    "    # Create dataset dict matching the expected format\n",
    "    class ToyDataset:\n",
    "        def __init__(self, tokens):\n",
    "            self.tokens = tokens\n",
    "        def __len__(self):\n",
    "            return len(self.tokens)\n",
    "        def __getitem__(self, idx):\n",
    "            return {\"tokens\": self.tokens[idx]}\n",
    "    \n",
    "    return ToyDataset(tokens)\n",
    "\n",
    "# 2. Create tiny model config\n",
    "toy_model_cfg = Config(\n",
    "    debug=False,\n",
    "    d_model=16,      # Very small\n",
    "    n_heads=4,       # Very small\n",
    "    d_head=4,        # Very small\n",
    "    d_mlp=16 * 2,    # Very small\n",
    "    n_layers=2,      # Just 2 layers\n",
    "    n_ctx=32,        # Short context\n",
    "    d_vocab=reference_gpt2.cfg.d_vocab,\n",
    ")\n",
    "\n",
    "# 3. Create minimal training args\n",
    "@dataclass\n",
    "class ToyTrainingArgs:\n",
    "    batch_size: int = 4          # Small batch\n",
    "    epochs: int = 1              # Just 1 epoch\n",
    "    max_steps_per_epoch: int = 5 # Only 5 steps\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-2\n",
    "    wandb_project: str | None = None  # Disable wandb for speed\n",
    "    wandb_name: str | None = None\n",
    "\n",
    "# 4. Complete Trainer with all methods filled in\n",
    "class ToyTransformerTrainer:\n",
    "    def __init__(self, args, model, train_dataset, test_dataset):\n",
    "        self.model = model\n",
    "        self.args = args\n",
    "        self.optimizer = t.optim.AdamW(\n",
    "            self.model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
    "        )\n",
    "        self.step = 0\n",
    "        \n",
    "        # Simple dataloaders (no multiprocessing for faster startup)\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,  # No multiprocessing for speed\n",
    "        )\n",
    "        self.test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch: dict[str, Int[Tensor, \"batch seq\"]]) -> Float[Tensor, \"\"]:\n",
    "        \"\"\"\n",
    "        Calculates the loss on the tokens in the batch, performs a gradient update step, and logs the loss.\n",
    "        \"\"\"\n",
    "        # Extract tokens from batch\n",
    "        tokens = batch[\"tokens\"].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = self.model(tokens)  # Shape: [batch, seq, vocab]\n",
    "        \n",
    "        # Compute loss (predict next token at each position)\n",
    "        # Shift logits and tokens for next-token prediction\n",
    "        logits_flat = logits[:, :-1, :].reshape(-1, logits.shape[-1])  # [batch*(seq-1), vocab]\n",
    "        targets_flat = tokens[:, 1:].reshape(-1)  # [batch*(seq-1)]\n",
    "        \n",
    "        loss = t.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "        \n",
    "        # Backward pass\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        self.step += 1\n",
    "        \n",
    "        # Log to wandb if enabled\n",
    "        if self.args.wandb_project is not None:\n",
    "            wandb.log({\"train_loss\": loss.item(), \"step\": self.step})\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    @t.inference_mode()\n",
    "    def evaluate(self) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model on the test set and return the accuracy.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_correct = 0\n",
    "        total_tokens = 0\n",
    "        \n",
    "        for batch in self.test_loader:\n",
    "            tokens = batch[\"tokens\"].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = self.model(tokens)  # [batch, seq, vocab]\n",
    "            \n",
    "            # Calculate accuracy (next token prediction)\n",
    "            predictions = logits[:, :-1, :].argmax(dim=-1)  # [batch, seq-1]\n",
    "            targets = tokens[:, 1:]  # [batch, seq-1]\n",
    "            \n",
    "            correct = (predictions == targets).sum().item()\n",
    "            total_correct += correct\n",
    "            total_tokens += targets.numel()\n",
    "        \n",
    "        accuracy = total_correct / total_tokens if total_tokens > 0 else 0.0\n",
    "        \n",
    "        self.model.train()\n",
    "        return accuracy\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the model with minimal configuration for smoke testing.\n",
    "        \"\"\"\n",
    "        # Initialize wandb only if project name provided\n",
    "        if self.args.wandb_project is not None:\n",
    "            wandb.init(\n",
    "                project=self.args.wandb_project,\n",
    "                name=self.args.wandb_name,\n",
    "                config=vars(self.args)\n",
    "            )\n",
    "        \n",
    "        accuracy = 0.0\n",
    "        progress_bar = tqdm(total=self.args.max_steps_per_epoch * self.args.epochs)\n",
    "        \n",
    "        print(f\" Starting smoke test training...\")\n",
    "        print(f\"   Model params: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
    "        \n",
    "        for epoch in range(self.args.epochs):\n",
    "            epoch_losses = []\n",
    "            \n",
    "            for i, batch in enumerate(self.train_loader):\n",
    "                loss = self.training_step(batch)\n",
    "                epoch_losses.append(loss.item())\n",
    "                \n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description(\n",
    "                    f\"Epoch {epoch + 1}, loss: {loss.item():.4f}, acc: {accuracy:.4f}\"\n",
    "                )\n",
    "                \n",
    "                if i >= self.args.max_steps_per_epoch - 1:\n",
    "                    break\n",
    "            \n",
    "            # Evaluate after each epoch\n",
    "            accuracy = self.evaluate()\n",
    "            avg_loss = np.mean(epoch_losses)\n",
    "            \n",
    "            print(f\"\\n Epoch {epoch + 1} complete:\")\n",
    "            print(f\"   Avg Loss: {avg_loss:.4f}\")\n",
    "            print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        progress_bar.close()\n",
    "        \n",
    "        if self.args.wandb_project is not None:\n",
    "            wandb.finish()\n",
    "        \n",
    "        print(\"\\n Smoke test complete! No errors detected.\")\n",
    "        return accuracy\n",
    "\n",
    "# ============== RUN SMOKE TEST ==============\n",
    "# Create toy datasets\n",
    "print(\"Creating toy datasets...\")\n",
    "toy_train = create_toy_dataset(n_samples=50, seq_len=32)\n",
    "toy_test = create_toy_dataset(n_samples=20, seq_len=32)\n",
    "\n",
    "# Create tiny model\n",
    "print(\"Creating tiny model...\")\n",
    "toy_model = DemoTransformer(toy_model_cfg).to(device)\n",
    "\n",
    "# Create trainer\n",
    "print(\"Creating trainer...\")\n",
    "toy_args = ToyTrainingArgs()\n",
    "toy_trainer = ToyTransformerTrainer(toy_args, toy_model, toy_train, toy_test)\n",
    "\n",
    "# Run training (should complete in < 10 seconds)\n",
    "print(\"\\nRunning smoke test...\")\n",
    "final_accuracy = toy_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb95c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from silen_lib.utils import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c8b16",
   "metadata": {},
   "source": [
    "## The Problem with Left-to-Right Generation\n",
    "\n",
    "When GPT generates text, it's stuck with a fundamental constraint: **once you write a word, you can't go back**.\n",
    "\n",
    "Think about how *you* write. Do you write perfectly from left to right? Or do you:\n",
    "- Write a rough draft\n",
    "- Go back and fix awkward phrasing\n",
    "- Revise the beginning after you see where the argument goes\n",
    "- Polish iteratively?\n",
    "\n",
    "Autoregressive models can't do this. They commit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c735376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating autoregressive generation\n",
    "# Each token is committed forever once generated\n",
    "\n",
    "sentence = []\n",
    "tokens = [\"The\", \"quick\", \"brown\", \"fox\", \"jumps\"]\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    sentence.append(token)\n",
    "    print(f\"Step {i+1}: {' '.join(sentence)}\")\n",
    "    print(f\"         Can I change 'quick' to 'slow'? {' No - already committed!' if i > 1 else ' Not yet generated'}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b02e1d",
   "metadata": {},
   "source": [
    "### What if we could generate differently?\n",
    "\n",
    "**Diffusion idea**: Start with all positions as \"unknown\" (like `[MASK]`), then iteratively refine:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6247f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating diffusion-style generation\n",
    "# All positions exist simultaneously, refined over time\n",
    "\n",
    "steps = [\n",
    "    [\"[MASK]\", \"[MASK]\", \"[MASK]\", \"[MASK]\", \"[MASK]\"],  # Pure noise/unknown\n",
    "    [\"The\", \"[MASK]\", \"[MASK]\", \"[MASK]\", \"[MASK]\"],     # Some clarity\n",
    "    [\"The\", \"[MASK]\", \"brown\", \"[MASK]\", \"[MASK]\"],      # More clarity\n",
    "    [\"The\", \"quick\", \"brown\", \"[MASK]\", \"jumps\"],        # Almost there\n",
    "    [\"The\", \"quick\", \"brown\", \"fox\", \"jumps\"],           # Final\n",
    "]\n",
    "\n",
    "print(\"Diffusion-style generation (simplified):\\n\")\n",
    "for i, step in enumerate(steps):\n",
    "    print(f\"Step {i}: {' '.join(step)}\")\n",
    "    if i < len(steps) - 1:\n",
    "        print(f\"         Can still change ANY position in next step!\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94335d",
   "metadata": {},
   "source": [
    "### Why does this matter?\n",
    "\n",
    "Consider this practical problem: **Fill in the blank**\n",
    "\n",
    "> \"The ___ jumped over the lazy dog\"\n",
    "\n",
    "An autoregressive model would need to generate everything up to the blank first. But what if the blank is at the beginning? Or what if you want to edit just one word in a long document?\n",
    "\n",
    "Diffusion models can:\n",
    "1. **Generate all positions in parallel** (potentially faster)\n",
    "2. **Revise and refine** (like human editing)\n",
    "3. **Handle infilling naturally** (the blank problem)\n",
    "4. **Control generation** via guidance (steer toward desired properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e663c38e",
   "metadata": {},
   "source": [
    "## The Core Diffusion Intuition\n",
    "\n",
    "Before tackling text specifically, let's understand the fundamental mechanism of diffusion. We'll use a simple 2D example that you can *see*.\n",
    "\n",
    "**The key insight**: If you slowly corrupt data with noise, and learn to reverse each tiny corruption step, you can generate new data from pure noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some \"data\" - points that form a shape\n",
    "# Imagine these are embeddings of the words \"cat\", \"dog\", \"bird\"\n",
    "\n",
    "n_points = 300\n",
    "theta = torch.linspace(0, 2*np.pi, n_points)\n",
    "\n",
    "# Data forms a spiral (a recognizable pattern)\n",
    "data = torch.stack([\n",
    "    theta * torch.cos(theta) / 6,\n",
    "    theta * torch.sin(theta) / 6\n",
    "], dim=1)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(data[:, 0], data[:, 1], alpha=0.6, s=10)\n",
    "plt.title(\"Our 'data' - a spiral pattern\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5def9d",
   "metadata": {},
   "source": [
    "### The Forward Process: Data  Noise\n",
    "\n",
    "The forward process is simple: **gradually add Gaussian noise until the data becomes indistinguishable from random noise**.\n",
    "\n",
    "At each step $t$, we add a little bit of noise:\n",
    "$$x_t = \\sqrt{1-\\beta_t} \\cdot x_{t-1} + \\sqrt{\\beta_t} \\cdot \\epsilon$$\n",
    "\n",
    "where $\\beta_t$ is a small noise amount and $\\epsilon \\sim \\mathcal{N}(0, I)$\n",
    "\n",
    "#### Where does this equation come from?\n",
    "\n",
    "**The intuition**: We want to *interpolate* between data and noise. But we need to be careful about variance!\n",
    "\n",
    "If we just did $x_t = (1-\\beta_t) \\cdot x_{t-1} + \\beta_t \\cdot \\epsilon$, the variance would blow up over many steps.\n",
    "\n",
    "**The math**: We want $x_t$ to have the same variance as $x_{t-1}$ (assuming $x_0$ has unit variance). For independent random variables:\n",
    "\n",
    "$$\\text{Var}(aX + bY) = a^2\\text{Var}(X) + b^2\\text{Var}(Y)$$\n",
    "\n",
    "So if $\\text{Var}(x_{t-1}) = 1$ and $\\text{Var}(\\epsilon) = 1$, we need:\n",
    "$$(\\sqrt{1-\\beta_t})^2 \\cdot 1 + (\\sqrt{\\beta_t})^2 \\cdot 1 = (1-\\beta_t) + \\beta_t = 1 \\checkmark$$\n",
    "\n",
    "**That's why we use square roots!** It's not arbitrary - it preserves variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing variance preservation\n",
    "# Why do we need those square roots?\n",
    "\n",
    "# Wrong way: linear interpolation\n",
    "wrong_x = data.clone()\n",
    "wrong_variances = [wrong_x.var().item()]\n",
    "\n",
    "# Right way: square root coefficients  \n",
    "right_x = data.clone()\n",
    "right_variances = [right_x.var().item()]\n",
    "\n",
    "for t in range(num_steps):\n",
    "    # WRONG: variance explodes\n",
    "    wrong_noise = torch.randn_like(wrong_x)\n",
    "    wrong_x = (1 - beta[t]) * wrong_x + beta[t] * wrong_noise\n",
    "    wrong_variances.append(wrong_x.var().item())\n",
    "    \n",
    "    # RIGHT: variance stays stable\n",
    "    right_noise = torch.randn_like(right_x)\n",
    "    right_x = torch.sqrt(1 - beta[t]) * right_x + torch.sqrt(beta[t]) * right_noise\n",
    "    right_variances.append(right_x.var().item())\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(wrong_variances, label='Wrong: linear coefficients', color='red')\n",
    "plt.plot(right_variances, label='Right: sqrt coefficients', color='green')\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.title(\"Why sqrt? Variance preservation!\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(wrong_x[:, 0], wrong_x[:, 1], alpha=0.3, s=5, label='Wrong (variance exploded)')\n",
    "plt.scatter(right_x[:, 0], right_x[:, 1], alpha=0.3, s=5, label='Right (variance preserved)')\n",
    "plt.legend()\n",
    "plt.title(\"Final distributions\")\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd1cc8",
   "metadata": {},
   "source": [
    "#### The Magic Closed-Form: Skip to Any Timestep!\n",
    "\n",
    "Applying $x_t = \\sqrt{1-\\beta_t} \\cdot x_{t-1} + \\sqrt{\\beta_t} \\cdot \\epsilon$ step by step is slow. Can we jump directly from $x_0$ to any $x_t$?\n",
    "\n",
    "**Yes!** Here's the beautiful derivation:\n",
    "\n",
    "Define $\\alpha_t = 1 - \\beta_t$ and $\\bar{\\alpha}_t = \\prod_{i=1}^{t} \\alpha_i$ (cumulative product).\n",
    "\n",
    "Starting from $x_t = \\sqrt{\\alpha_t} x_{t-1} + \\sqrt{1-\\alpha_t}\\epsilon_t$ and recursively substituting:\n",
    "\n",
    "$$x_t = \\sqrt{\\alpha_t}(\\sqrt{\\alpha_{t-1}} x_{t-2} + \\sqrt{1-\\alpha_{t-1}}\\epsilon_{t-1}) + \\sqrt{1-\\alpha_t}\\epsilon_t$$\n",
    "\n",
    "After all the algebra (using the fact that sum of Gaussians is Gaussian), we get:\n",
    "\n",
    "$$\\boxed{x_t = \\sqrt{\\bar{\\alpha}_t} \\cdot x_0 + \\sqrt{1-\\bar{\\alpha}_t} \\cdot \\epsilon}$$\n",
    "\n",
    "where $\\epsilon \\sim \\mathcal{N}(0, I)$ is a **single** noise sample!\n",
    "\n",
    "**This is powerful**: We can sample any $x_t$ directly from $x_0$ without simulating all intermediate steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f17c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing alpha_bar: what does it mean?\n",
    "\n",
    "alpha = 1 - beta\n",
    "alpha_bar = torch.cumprod(alpha, dim=0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: alpha_bar over time\n",
    "axes[0].plot(alpha_bar, linewidth=2)\n",
    "axes[0].axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='50/50 signal/noise')\n",
    "axes[0].set_xlabel(\"Timestep t\")\n",
    "axes[0].set_ylabel(\"$\\\\bar{\\\\alpha}_t$\")\n",
    "axes[0].set_title(\"$\\\\bar{\\\\alpha}_t$ = how much signal remains\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: sqrt(alpha_bar) and sqrt(1-alpha_bar) - the actual coefficients\n",
    "axes[1].plot(torch.sqrt(alpha_bar), label='$\\\\sqrt{\\\\bar{\\\\alpha}_t}$ (signal coef)', linewidth=2)\n",
    "axes[1].plot(torch.sqrt(1 - alpha_bar), label='$\\\\sqrt{1-\\\\bar{\\\\alpha}_t}$ (noise coef)', linewidth=2)\n",
    "axes[1].set_xlabel(\"Timestep t\")\n",
    "axes[1].set_ylabel(\"Coefficient\")\n",
    "axes[1].set_title(\"Coefficients in $x_t = \\\\sqrt{\\\\bar{\\\\alpha}_t}x_0 + \\\\sqrt{1-\\\\bar{\\\\alpha}_t}\\\\epsilon$\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: SNR (signal-to-noise ratio)\n",
    "snr = alpha_bar / (1 - alpha_bar + 1e-8)\n",
    "axes[2].plot(snr, linewidth=2)\n",
    "axes[2].set_xlabel(\"Timestep t\")\n",
    "axes[2].set_ylabel(\"SNR (log scale)\")\n",
    "axes[2].set_title(\"Signal-to-Noise Ratio\")\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"At t=0:  {alpha_bar[0]:.3f} signal, {(1-alpha_bar[0]):.3f} noise  mostly data\")\n",
    "print(f\"At t=25: {alpha_bar[25]:.3f} signal, {(1-alpha_bar[25]):.3f} noise  mixed\")\n",
    "print(f\"At t=49: {alpha_bar[49]:.3f} signal, {(1-alpha_bar[49]):.3f} noise  mostly noise\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a81ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward diffusion: watch the spiral dissolve into noise\n",
    "\n",
    "num_steps = 50\n",
    "beta = torch.linspace(0.0001, 0.02, num_steps)  # Noise schedule\n",
    "\n",
    "# Store noisy versions at different timesteps\n",
    "noisy_data = [data.clone()]\n",
    "x = data.clone()\n",
    "\n",
    "for t in range(num_steps):\n",
    "    noise = torch.randn_like(x)\n",
    "    x = torch.sqrt(1 - beta[t]) * x + torch.sqrt(beta[t]) * noise\n",
    "    noisy_data.append(x.clone())\n",
    "\n",
    "# Visualize at key timesteps\n",
    "fig, axes = plt.subplots(1, 6, figsize=(18, 3))\n",
    "timesteps_to_show = [0, 10, 20, 30, 40, 50]\n",
    "\n",
    "for ax, t in zip(axes, timesteps_to_show):\n",
    "    ax.scatter(noisy_data[t][:, 0], noisy_data[t][:, 1], alpha=0.6, s=10)\n",
    "    ax.set_title(f\"t = {t}\")\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-3, 3)\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "plt.suptitle(\"Forward Process: Data  Noise\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc17d72a",
   "metadata": {},
   "source": [
    "**Key observation**: At the end (t=50), the points look like pure Gaussian noise. The spiral structure is completely destroyed.\n",
    "\n",
    "But here's the magic: **we can learn to reverse this!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe29377",
   "metadata": {},
   "source": [
    "### The Reverse Process: Noise  Data\n",
    "\n",
    "If we can learn to predict \"which way is the data?\" from any noisy point, we can reverse the process.\n",
    "\n",
    "Think of it like this: imagine you're lost in a foggy field. If at each step you knew which direction leads toward the path, you could find your way back. That's what the neural network learns: **the direction toward clean data**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96db075",
   "metadata": {},
   "source": [
    "### Score Functions: The Gradient Toward Data\n",
    "\n",
    "Before understanding the reverse process, we need a key concept: **the score function**.\n",
    "\n",
    "The **score** of a distribution $p(x)$ is its gradient with respect to $x$:\n",
    "\n",
    "$$s(x) = \\nabla_x \\log p(x)$$\n",
    "\n",
    "**Intuition**: The score points \"uphill\" toward higher probability regions. If you're in a low-density area, the score tells you which way to go to find data!\n",
    "\n",
    "For a Gaussian $\\mathcal{N}(\\mu, \\sigma^2)$, the score is:\n",
    "$$s(x) = \\nabla_x \\log p(x) = -\\frac{x - \\mu}{\\sigma^2}$$\n",
    "\n",
    "This points toward the mean $\\mu$ - exactly what we want for denoising!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3600f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the score function for a simple 2D distribution\n",
    "\n",
    "# Create a grid\n",
    "xx, yy = torch.meshgrid(torch.linspace(-3, 3, 20), torch.linspace(-3, 3, 20), indexing='ij')\n",
    "grid = torch.stack([xx.flatten(), yy.flatten()], dim=1)\n",
    "\n",
    "# For our spiral data, the score at each point roughly points toward the nearest data point\n",
    "# (This is a simplification - true score is more complex)\n",
    "def estimate_score(points, data, sigma=0.5):\n",
    "    \"\"\"Estimate score as weighted sum of directions to data points.\"\"\"\n",
    "    # For each point, compute gaussian-weighted direction to all data points\n",
    "    diffs = data.unsqueeze(0) - points.unsqueeze(1)  # [n_points, n_data, 2]\n",
    "    dists_sq = (diffs ** 2).sum(dim=-1)  # [n_points, n_data]\n",
    "    weights = torch.exp(-dists_sq / (2 * sigma**2))  # [n_points, n_data]\n",
    "    weights = weights / (weights.sum(dim=1, keepdim=True) + 1e-8)\n",
    "    score = (weights.unsqueeze(-1) * diffs).sum(dim=1)  # [n_points, 2]\n",
    "    return score / sigma**2\n",
    "\n",
    "scores = estimate_score(grid, data, sigma=0.3)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(data[:, 0], data[:, 1], alpha=0.3, s=20, label='Data')\n",
    "plt.quiver(grid[:, 0], grid[:, 1], scores[:, 0], scores[:, 1], \n",
    "           alpha=0.7, color='red', scale=50)\n",
    "plt.title(\"Score Function: Arrows Point Toward High-Density Regions\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"The score function is like a vector field that pushes you toward the data!\")\n",
    "print(\"If you follow the arrows, you'll end up on the spiral.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f8f61d",
   "metadata": {},
   "source": [
    "#### The Beautiful Connection: Score = Noise / \n",
    "\n",
    "Here's the key insight that makes diffusion work. At timestep $t$, we have:\n",
    "\n",
    "$$x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1-\\bar{\\alpha}_t} \\epsilon$$\n",
    "\n",
    "Given $x_t$, what's the score $\\nabla_{x_t} \\log p(x_t | x_0)$?\n",
    "\n",
    "Since $x_t | x_0 \\sim \\mathcal{N}(\\sqrt{\\bar{\\alpha}_t} x_0, (1-\\bar{\\alpha}_t)I)$, the score is:\n",
    "\n",
    "$$\\nabla_{x_t} \\log p(x_t | x_0) = -\\frac{x_t - \\sqrt{\\bar{\\alpha}_t} x_0}{1-\\bar{\\alpha}_t} = -\\frac{\\sqrt{1-\\bar{\\alpha}_t} \\epsilon}{1-\\bar{\\alpha}_t} = \\boxed{-\\frac{\\epsilon}{\\sqrt{1-\\bar{\\alpha}_t}}}$$\n",
    "\n",
    "**This is why predicting noise is equivalent to estimating the score!**\n",
    "\n",
    "$$\\epsilon_\\theta(x_t, t) \\approx \\epsilon \\implies s_\\theta(x_t, t) \\approx -\\frac{\\epsilon_\\theta}{\\sqrt{1-\\bar{\\alpha}_t}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e004f237",
   "metadata": {},
   "source": [
    "### Why Predict Noise? The ELBO Perspective\n",
    "\n",
    "You might wonder: why do we predict noise $\\epsilon$ instead of directly predicting $x_0$?\n",
    "\n",
    "The answer comes from the **Evidence Lower Bound (ELBO)** - but let's build intuition first.\n",
    "\n",
    "#### The Training Objective Derivation\n",
    "\n",
    "We want to maximize $\\log p(x_0)$ - the probability of real data under our model.\n",
    "\n",
    "Using variational inference, we get:\n",
    "$$\\log p(x_0) \\geq \\mathbb{E}_{q}\\left[ \\log \\frac{p(x_{0:T})}{q(x_{1:T}|x_0)} \\right] = \\text{ELBO}$$\n",
    "\n",
    "After lots of math (which we'll skip), this decomposes into:\n",
    "$$\\text{ELBO} = \\sum_{t=1}^{T} \\mathbb{E}_{q(x_t|x_0)} \\left[ D_{KL}(q(x_{t-1}|x_t, x_0) \\| p_\\theta(x_{t-1}|x_t)) \\right] + \\text{const}$$\n",
    "\n",
    "**The key insight**: Both distributions are Gaussian! The KL divergence between Gaussians is:\n",
    "$$D_{KL}(\\mathcal{N}(\\mu_1, \\sigma^2) \\| \\mathcal{N}(\\mu_2, \\sigma^2)) \\propto \\|\\mu_1 - \\mu_2\\|^2$$\n",
    "\n",
    "So we're just doing **MSE between means**!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea9b4b",
   "metadata": {},
   "source": [
    "#### From MSE on Means to MSE on Noise\n",
    "\n",
    "The true mean is (we derived this earlier):\n",
    "$$\\mu_{\\text{true}} = \\frac{1}{\\sqrt{\\alpha_t}}\\left(x_t - \\frac{1-\\alpha_t}{\\sqrt{1-\\bar\\alpha_t}}\\epsilon\\right)$$\n",
    "\n",
    "If we predict noise $\\epsilon_\\theta$, our predicted mean is:\n",
    "$$\\mu_{\\theta} = \\frac{1}{\\sqrt{\\alpha_t}}\\left(x_t - \\frac{1-\\alpha_t}{\\sqrt{1-\\bar\\alpha_t}}\\epsilon_\\theta\\right)$$\n",
    "\n",
    "The MSE between means becomes:\n",
    "$$\\|\\mu_{\\text{true}} - \\mu_\\theta\\|^2 \\propto \\|\\epsilon - \\epsilon_\\theta\\|^2$$\n",
    "\n",
    "**That's why we do MSE on noise!** It's equivalent to the theoretically justified objective, just simpler.\n",
    "\n",
    "#### Three Equivalent Objectives\n",
    "\n",
    "You can train by predicting:\n",
    "1. **Noise $\\epsilon$**: $\\mathcal{L} = \\|\\epsilon - \\epsilon_\\theta(x_t, t)\\|^2$  Most common\n",
    "2. **Clean data $x_0$**: $\\mathcal{L} = \\|x_0 - x_{0,\\theta}(x_t, t)\\|^2$\n",
    "3. **Score $\\nabla \\log p$**: $\\mathcal{L} = \\|s(x_t) - s_\\theta(x_t, t)\\|^2$\n",
    "\n",
    "All three are mathematically equivalent (up to constants)! Noise prediction is popular because:\n",
    "- Consistent magnitude across timesteps\n",
    "- Works well empirically\n",
    "- Easy to implement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f065261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing \"which way is the data?\"\n",
    "# At a moderately noisy timestep, we can still see the structure\n",
    "\n",
    "t = 20  # Moderately noisy\n",
    "noisy = noisy_data[t]\n",
    "\n",
    "# For each noisy point, the \"direction toward data\" is approximately \n",
    "# the vector from the noisy point toward the original point\n",
    "directions = data - noisy\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(noisy[:, 0], noisy[:, 1], alpha=0.4, s=20, label='Noisy points')\n",
    "\n",
    "# Show arrows for a subset of points\n",
    "subset = range(0, n_points, 15)\n",
    "for i in subset:\n",
    "    plt.arrow(noisy[i, 0], noisy[i, 1], \n",
    "              directions[i, 0]*0.5, directions[i, 1]*0.5,\n",
    "              head_width=0.08, head_length=0.04, fc='red', ec='red', alpha=0.6)\n",
    "\n",
    "plt.title(f\"At t={t}: Arrows point toward clean data\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba42fe6",
   "metadata": {},
   "source": [
    "### Training a Denoiser: Learning the Arrows\n",
    "\n",
    "The neural network's job: **given a noisy point and timestep t, predict the noise that was added** (equivalently, predict the direction back to clean data).\n",
    "\n",
    "Training is simple:\n",
    "1. Take clean data point $x_0$\n",
    "2. Sample a random timestep $t$  \n",
    "3. Add noise to get $x_t$\n",
    "4. Train network to predict the noise $\\epsilon$ that was added\n",
    "\n",
    "$$\\mathcal{L} = \\| \\epsilon - \\epsilon_\\theta(x_t, t) \\|^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d774a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple denoiser network for our 2D spiral\n",
    "# Input: noisy point (2D) + timestep (1D)  Output: predicted noise (2D)\n",
    "\n",
    "class SimpleDenoiser(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, hidden_dim),  # 2D point + 1D timestep\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2)   # predict 2D noise\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # t is normalized to [0, 1]\n",
    "        t_normalized = t.float() / num_steps\n",
    "        inputs = torch.cat([x, t_normalized.unsqueeze(-1)], dim=-1)\n",
    "        return self.net(inputs)\n",
    "\n",
    "denoiser = SimpleDenoiser().to(device)\n",
    "print(f\"Denoiser parameters: {sum(p.numel() for p in denoiser.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute alpha values for efficient noising\n",
    "# alpha_bar[t] = product of (1 - beta[i]) for i=0 to t\n",
    "alpha = 1 - beta\n",
    "alpha_bar = torch.cumprod(alpha, dim=0)\n",
    "\n",
    "print(\"alpha_bar at different timesteps:\")\n",
    "print(f\"  t=0:  {alpha_bar[0]:.4f}  (almost no noise)\")\n",
    "print(f\"  t=25: {alpha_bar[25]:.4f} (moderate noise)\")\n",
    "print(f\"  t=49: {alpha_bar[49]:.4f} (almost pure noise)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def forward_diffusion(x_0, t, alpha_bar):\n",
    "    \"\"\"\n",
    "    Add noise to x_0 at timestep t in one step.\n",
    "    \n",
    "    x_t = sqrt(alpha_bar[t]) * x_0 + sqrt(1 - alpha_bar[t]) * noise\n",
    "    \n",
    "    Returns: (noisy_x, noise)\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(x_0)\n",
    "    sqrt_alpha_bar = torch.sqrt(alpha_bar[t]).view(-1, 1)\n",
    "    sqrt_one_minus_alpha_bar = torch.sqrt(1 - alpha_bar[t]).view(-1, 1)\n",
    "    \n",
    "    x_t = sqrt_alpha_bar * x_0 + sqrt_one_minus_alpha_bar * noise\n",
    "    return x_t, noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the denoiser\n",
    "optimizer = torch.optim.Adam(denoiser.parameters(), lr=1e-3)\n",
    "data_device = data.to(device)\n",
    "alpha_bar_device = alpha_bar.to(device)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(2000):\n",
    "    # Sample random timesteps for each data point\n",
    "    t = torch.randint(0, num_steps, (n_points,), device=device)\n",
    "    \n",
    "    # Add noise\n",
    "    x_t, noise = forward_diffusion(data_device, t, alpha_bar_device)\n",
    "    \n",
    "    # Predict noise\n",
    "    predicted_noise = denoiser(x_t, t)\n",
    "    \n",
    "    # Loss: MSE between predicted and actual noise\n",
    "    loss = F.mse_loss(predicted_noise, noise)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    if epoch % 400 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10bd54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Denoiser Training Loss\")\n",
    "plt.yscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f96111",
   "metadata": {},
   "source": [
    "### Generation: Running the Reverse Process\n",
    "\n",
    "Now comes the magic. We want to reverse the forward process: go from noise back to data.\n",
    "\n",
    "#### Deriving the Reverse Process from Bayes\n",
    "\n",
    "The forward process is: $q(x_t | x_{t-1})$ - we know this exactly.\n",
    "\n",
    "We want the reverse: $q(x_{t-1} | x_t)$ - but this requires knowing $p(x_0)$, which we don't!\n",
    "\n",
    "**The key insight**: If we also condition on $x_0$, we CAN compute the reverse exactly:\n",
    "\n",
    "$$q(x_{t-1} | x_t, x_0) = \\mathcal{N}(x_{t-1}; \\tilde{\\mu}_t, \\tilde{\\beta}_t I)$$\n",
    "\n",
    "where (after some algebra with Bayes' theorem):\n",
    "\n",
    "$$\\tilde{\\mu}_t = \\frac{\\sqrt{\\bar{\\alpha}_{t-1}} \\beta_t}{1-\\bar{\\alpha}_t} x_0 + \\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t} x_t$$\n",
    "\n",
    "But we don't know $x_0$! That's where the neural network comes in. We predict:\n",
    "\n",
    "$$\\hat{x}_0 = \\frac{1}{\\sqrt{\\bar{\\alpha}_t}} \\left( x_t - \\sqrt{1-\\bar{\\alpha}_t} \\epsilon_\\theta(x_t, t) \\right)$$\n",
    "\n",
    "Substituting this estimate gives us:\n",
    "\n",
    "$$\\boxed{x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1-\\alpha_t}{\\sqrt{1-\\bar\\alpha_t}} \\epsilon_\\theta(x_t, t) \\right) + \\sigma_t z}$$\n",
    "\n",
    "where $z \\sim \\mathcal{N}(0, I)$ adds stochasticity (except at t=0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f03df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@torch.no_grad()\n",
    "def sample(model, n_samples, dim, num_steps, alpha, alpha_bar, device):\n",
    "    \"\"\"\n",
    "    Generate samples by running the reverse diffusion process.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Start from pure noise\n",
    "    x = torch.randn(n_samples, dim, device=device)\n",
    "    trajectory = [x.cpu().clone()]\n",
    "    \n",
    "    for t in reversed(range(num_steps)):\n",
    "        t_batch = torch.full((n_samples,), t, device=device)\n",
    "        \n",
    "        # Predict noise\n",
    "        predicted_noise = model(x, t_batch)\n",
    "        \n",
    "        # Compute x_{t-1}\n",
    "        alpha_t = alpha[t]\n",
    "        alpha_bar_t = alpha_bar[t]\n",
    "        \n",
    "        # Mean of the reverse distribution\n",
    "        coef1 = 1 / torch.sqrt(alpha_t)\n",
    "        coef2 = (1 - alpha_t) / torch.sqrt(1 - alpha_bar_t)\n",
    "        mean = coef1 * (x - coef2 * predicted_noise)\n",
    "        \n",
    "        # Add noise (except at t=0)\n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(x)\n",
    "            # Variance is beta_t (simplified)\n",
    "            sigma = torch.sqrt(1 - alpha_t)\n",
    "            x = mean + sigma * noise\n",
    "        else:\n",
    "            x = mean\n",
    "            \n",
    "        trajectory.append(x.cpu().clone())\n",
    "    \n",
    "    return x, trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new samples!\n",
    "generated, trajectory = sample(denoiser, 300, 2, num_steps, alpha.to(device), alpha_bar.to(device), device)\n",
    "generated = generated.cpu()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(data[:, 0], data[:, 1], alpha=0.6, s=10, label='Original data')\n",
    "plt.title(\"Original Spiral\")\n",
    "plt.axis('equal')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(generated[:, 0], generated[:, 1], alpha=0.6, s=10, c='orange', label='Generated')\n",
    "plt.title(\"Generated from Pure Noise!\")\n",
    "plt.axis('equal')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce292586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch the generation process unfold\n",
    "fig, axes = plt.subplots(1, 6, figsize=(18, 3))\n",
    "steps_to_show = [0, 10, 25, 40, 49, 50]  # 0 is pure noise, 50 is final\n",
    "\n",
    "for ax, s in zip(axes, steps_to_show):\n",
    "    ax.scatter(trajectory[s][:, 0], trajectory[s][:, 1], alpha=0.6, s=10)\n",
    "    ax.set_title(f\"Step {s}\" if s < 50 else \"Final\")\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-3, 3)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.suptitle(\"Reverse Process: Noise  Data (Generation)\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f499e6f1",
   "metadata": {},
   "source": [
    "### Summary: The Diffusion Recipe\n",
    "\n",
    "1. **Forward process**: Gradually add noise until data  pure noise\n",
    "2. **Training**: Teach a network to predict the noise at each step\n",
    "3. **Generation**: Start from noise, iteratively remove predicted noise\n",
    "\n",
    "That's it. That's diffusion. \n",
    "\n",
    "### Bonus: Faster Sampling with DDIM\n",
    "\n",
    "Our 50-step sampling is slow. **DDIM** (Denoising Diffusion Implicit Models) can speed this up!\n",
    "\n",
    "**The insight**: DDPM adds stochasticity at each step. But if we remove it, we get a **deterministic** mapping from noise to data - and we can skip steps!\n",
    "\n",
    "| Method | Steps Needed | Stochastic? | Quality |\n",
    "|--------|--------------|-------------|---------|\n",
    "| DDPM | All T steps | Yes | Best |\n",
    "| DDIM | 10-50 steps | No | Nearly as good |\n",
    "\n",
    "DDIM modifies the reverse step to:\n",
    "$$x_{t-1} = \\sqrt{\\bar\\alpha_{t-1}} \\hat{x}_0 + \\sqrt{1-\\bar\\alpha_{t-1}} \\cdot \\frac{x_t - \\sqrt{\\bar\\alpha_t}\\hat{x}_0}{\\sqrt{1-\\bar\\alpha_t}}$$\n",
    "\n",
    "No randomness added  can skip timesteps  5-10x faster sampling!\n",
    "\n",
    "**Now the question**: How do we apply this to *text*?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8991973f",
   "metadata": {},
   "source": [
    "## The Text Problem: Discrete vs Continuous\n",
    "\n",
    "Here's the fundamental challenge: **text is discrete**.\n",
    "\n",
    "In images, a pixel can smoothly transition: `[0.5, 0.5, 0.5]`  `[0.51, 0.49, 0.52]`\n",
    "\n",
    "In text, tokens are integers: \"cat\" is token `3784`. What's `3784 + 0.3`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The discrete problem illustrated\n",
    "\n",
    "vocab = {\"cat\": 0, \"dog\": 1, \"bird\": 2, \"fish\": 3}\n",
    "\n",
    "# This makes sense for images\n",
    "pixel = torch.tensor([0.5, 0.5, 0.5])\n",
    "noisy_pixel = pixel + 0.1 * torch.randn(3)\n",
    "print(f\"Image pixel:       {pixel}\")\n",
    "print(f\"Noisy image pixel: {noisy_pixel}\")\n",
    "print(f\"Still valid RGB?  Yes\\n\")\n",
    "\n",
    "# This doesn't make sense for tokens\n",
    "token_id = vocab[\"cat\"]  # = 0\n",
    "print(f\"Token 'cat' = {token_id}\")\n",
    "print(f\"'cat' + noise = {token_id + 0.3:.1f}\")\n",
    "print(f\"What word is 0.3?  Nonsense!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing continuous vs discrete: why text is harder\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Image: continuous space\n",
    "ax = axes[0]\n",
    "# Show color gradient\n",
    "gradient = np.linspace(0, 1, 100).reshape(1, -1)\n",
    "gradient = np.repeat(gradient, 20, axis=0)\n",
    "ax.imshow(gradient, aspect='auto', cmap='RdYlGn')\n",
    "ax.set_title(\"Image: Continuous\\n(infinite values between red and green)\", fontsize=11)\n",
    "ax.set_xticks([0, 50, 99])\n",
    "ax.set_xticklabels(['Red\\n(0.0)', 'Yellow\\n(0.5)', 'Green\\n(1.0)'])\n",
    "ax.set_yticks([])\n",
    "ax.annotate(\"\", xy=(60, 10), xytext=(40, 10), \n",
    "            arrowprops=dict(arrowstyle=\"<->\", lw=2))\n",
    "ax.text(50, 15, \"can smoothly\\ninterpolate\", ha='center', fontsize=9)\n",
    "\n",
    "# Text: discrete space\n",
    "ax = axes[1]\n",
    "words = ['cat', 'dog', 'bird', 'fish']\n",
    "for i, w in enumerate(words):\n",
    "    ax.scatter(i, 0, s=300, c='blue', zorder=5)\n",
    "    ax.annotate(w, (i, 0.1), ha='center', fontsize=11)\n",
    "ax.set_xlim(-0.5, 3.5)\n",
    "ax.set_ylim(-0.5, 0.5)\n",
    "ax.set_title(\"Text: Discrete\\n(only 4 valid values!)\", fontsize=11)\n",
    "ax.axhline(0, color='gray', linestyle='--', alpha=0.3)\n",
    "ax.scatter(0.5, 0, s=100, c='red', marker='x', linewidths=2, zorder=5)\n",
    "ax.annotate(\"??? (invalid!)\", (0.5, -0.2), ha='center', fontsize=9, color='red')\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "\n",
    "# The two solutions\n",
    "ax = axes[2]\n",
    "ax.text(0.5, 0.9, \"Two Solutions\", fontsize=14, ha='center', fontweight='bold', transform=ax.transAxes)\n",
    "ax.text(0.5, 0.7, \"1 Embedding Space\", fontsize=12, ha='center', transform=ax.transAxes)\n",
    "ax.text(0.5, 0.55, \"Map tokens  continuous vectors\\nDiffuse in vector space\\nRound back to tokens\", fontsize=10, ha='center', transform=ax.transAxes)\n",
    "ax.text(0.5, 0.35, \"2 Discrete Diffusion\", fontsize=12, ha='center', transform=ax.transAxes)\n",
    "ax.text(0.5, 0.2, \"Replace 'Gaussian noise' with\\n'random token substitution'\\nor 'masking'\", fontsize=10, ha='center', transform=ax.transAxes)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4546e",
   "metadata": {},
   "source": [
    "### Two Solutions to the Discrete Problem\n",
    "\n",
    "**Approach 1: Embedding Space Diffusion**\n",
    "- Map tokens to continuous embeddings\n",
    "- Diffuse in embedding space\n",
    "- Map back to tokens\n",
    "\n",
    "**Approach 2: Discrete Diffusion**  \n",
    "- Don't use Gaussian noise at all\n",
    "- Instead, *corrupt* by randomly replacing tokens\n",
    "- Often with a special `[MASK]` token\n",
    "\n",
    "Let's explore both.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f2796c",
   "metadata": {},
   "source": [
    "## Approach 1: Embedding Space Diffusion\n",
    "\n",
    "The idea: tokens live in discrete space, but their **embeddings** are continuous vectors. We can diffuse there!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef03c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing embedding space\n",
    "# Each word is a point in continuous space\n",
    "\n",
    "# Pretend embeddings for words (2D for visualization)\n",
    "word_embeddings = {\n",
    "    \"cat\": torch.tensor([1.0, 0.5]),\n",
    "    \"dog\": torch.tensor([1.2, 0.3]),\n",
    "    \"bird\": torch.tensor([-0.5, 1.0]),\n",
    "    \"fish\": torch.tensor([-0.3, -1.0]),\n",
    "    \"happy\": torch.tensor([2.0, 2.0]),\n",
    "    \"sad\": torch.tensor([2.2, -2.0]),\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for word, emb in word_embeddings.items():\n",
    "    plt.scatter(emb[0], emb[1], s=100)\n",
    "    plt.annotate(word, (emb[0]+0.1, emb[1]+0.1), fontsize=12)\n",
    "\n",
    "plt.axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "plt.axvline(x=0, color='gray', linestyle='--', alpha=0.3)\n",
    "plt.xlabel(\"Embedding Dimension 1\")\n",
    "plt.ylabel(\"Embedding Dimension 2\")\n",
    "plt.title(\"Words as Points in Continuous Embedding Space\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we CAN add noise to embeddings!\n",
    "cat_emb = word_embeddings[\"cat\"]\n",
    "noisy_cat = cat_emb + 0.3 * torch.randn(2)\n",
    "\n",
    "print(f\"'cat' embedding: {cat_emb}\")\n",
    "print(f\"Noisy 'cat':     {noisy_cat}\")\n",
    "print(f\"\\nThis is valid! It's a point in continuous space.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912edec1",
   "metadata": {},
   "source": [
    "### The Rounding Problem\n",
    "\n",
    "After diffusing, we need to get back to actual tokens. But what if our denoised embedding doesn't land exactly on a word?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rounding problem: what word is closest?\n",
    "\n",
    "def nearest_word(point, embeddings):\n",
    "    \"\"\"Find the nearest word to a point in embedding space.\"\"\"\n",
    "    min_dist = float('inf')\n",
    "    nearest = None\n",
    "    for word, emb in embeddings.items():\n",
    "        dist = torch.norm(point - emb)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            nearest = word\n",
    "    return nearest, min_dist\n",
    "\n",
    "# Suppose after denoising we land here:\n",
    "denoised_point = torch.tensor([0.8, 0.9])\n",
    "\n",
    "nearest, dist = nearest_word(denoised_point, word_embeddings)\n",
    "print(f\"Denoised embedding: {denoised_point}\")\n",
    "print(f\"Nearest word: '{nearest}' (distance: {dist:.2f})\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 6))\n",
    "for word, emb in word_embeddings.items():\n",
    "    plt.scatter(emb[0], emb[1], s=100, label=word)\n",
    "    plt.annotate(word, (emb[0]+0.1, emb[1]+0.1), fontsize=10)\n",
    "\n",
    "plt.scatter(denoised_point[0], denoised_point[1], s=200, c='red', marker='x', linewidths=3, label='Denoised point')\n",
    "plt.plot([denoised_point[0], word_embeddings[nearest][0]], \n",
    "         [denoised_point[1], word_embeddings[nearest][1]], 'r--', alpha=0.5)\n",
    "plt.title(f\"Rounding: denoised point  nearest word '{nearest}'\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc4c34",
   "metadata": {},
   "source": [
    "### Embedding Space Diffusion: Pros and Cons\n",
    "\n",
    "**Pros:**\n",
    "- We can reuse all the continuous diffusion machinery\n",
    "- Smooth gradients, well-understood math\n",
    "- This is what **Diffusion-LM** does (we'll explore it later)\n",
    "\n",
    "**Cons:**\n",
    "- Rounding errors accumulate\n",
    "- Generated embeddings might not match any real word well\n",
    "- Needs careful training to keep embeddings \"on manifold\"\n",
    "\n",
    "This is a valid approach and powers some influential models. But there's another way...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c6195",
   "metadata": {},
   "source": [
    "## Approach 2: Discrete Diffusion (The Modern Approach)\n",
    "\n",
    "What if we redefine \"noise\" entirely for discrete data?\n",
    "\n",
    "Instead of Gaussian noise, we use **token corruption**:\n",
    "- Replace tokens with `[MASK]` (absorbing diffusion)\n",
    "- Replace tokens with random tokens (uniform diffusion)\n",
    "\n",
    "The forward process becomes: gradually corrupt tokens until they're all `[MASK]` or random garbage.\n",
    "\n",
    "The reverse process: predict the original tokens from the corrupted ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31226cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrete \"noise\" = token replacement\n",
    "\n",
    "sentence = [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "MASK = \"[MASK]\"\n",
    "\n",
    "# Forward process: gradually replace tokens with [MASK]\n",
    "def corrupt_sentence(tokens, mask_prob):\n",
    "    \"\"\"Replace each token with [MASK] with probability mask_prob.\"\"\"\n",
    "    corrupted = []\n",
    "    for token in tokens:\n",
    "        if torch.rand(1).item() < mask_prob:\n",
    "            corrupted.append(MASK)\n",
    "        else:\n",
    "            corrupted.append(token)\n",
    "    return corrupted\n",
    "\n",
    "print(\"Forward process (discrete):\\n\")\n",
    "for prob in [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "    corrupted = corrupt_sentence(sentence, prob)\n",
    "    print(f\"mask_prob={prob:.1f}: {' '.join(corrupted)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df264cb",
   "metadata": {},
   "source": [
    "### Connection to BERT: MLM is One-Step Diffusion!\n",
    "\n",
    "If you know BERT, you already understand discrete diffusion:\n",
    "- BERT: mask 15% of tokens, predict them  **one step** of denoising\n",
    "- Discrete diffusion: mask variable %, predict them  **many steps** of denoising\n",
    "\n",
    "The key insight: diffusion is just BERT's masked language modeling, done *iteratively* with a *schedule*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780baa26",
   "metadata": {},
   "source": [
    "### Transition Matrices: Formalizing Discrete Noise\n",
    "\n",
    "In continuous diffusion, we had: $x_t = \\sqrt{1-\\beta_t} x_{t-1} + \\sqrt{\\beta_t} \\epsilon$\n",
    "\n",
    "In discrete diffusion, we use a **transition matrix** $Q_t$:\n",
    "- $Q_t[i,j]$ = probability of token $i$ becoming token $j$ at step $t$\n",
    "\n",
    "For absorbing (mask-based) diffusion with vocabulary of size $V$ plus `[MASK]`:\n",
    "\n",
    "$$Q_t = \\begin{bmatrix} 1-\\beta_t & 0 & \\cdots & \\beta_t \\\\ 0 & 1-\\beta_t & \\cdots & \\beta_t \\\\ \\vdots & & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & 1 \\end{bmatrix}$$\n",
    "\n",
    "The last column is the `[MASK]` token - once you're masked, you stay masked (absorbing state).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def make_absorbing_transition_matrix(vocab_size, beta):\n",
    "    \"\"\"\n",
    "    Create absorbing transition matrix.\n",
    "    vocab_size includes the MASK token as the last index.\n",
    "    \"\"\"\n",
    "    Q = torch.zeros(vocab_size, vocab_size)\n",
    "    \n",
    "    # Regular tokens: stay with prob (1-beta), go to MASK with prob beta\n",
    "    for i in range(vocab_size - 1):\n",
    "        Q[i, i] = 1 - beta\n",
    "        Q[i, vocab_size - 1] = beta\n",
    "    \n",
    "    # MASK token: always stays as MASK (absorbing)\n",
    "    Q[vocab_size - 1, vocab_size - 1] = 1.0\n",
    "    \n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533628ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a small transition matrix\n",
    "# Vocab: [cat, dog, bird, fish, MASK]\n",
    "small_vocab = [\"cat\", \"dog\", \"bird\", \"fish\", \"[MASK]\"]\n",
    "Q = make_absorbing_transition_matrix(5, beta=0.3)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(Q, cmap='Blues', vmin=0, vmax=1)\n",
    "plt.colorbar(label='Probability')\n",
    "plt.xticks(range(5), small_vocab, rotation=45)\n",
    "plt.yticks(range(5), small_vocab)\n",
    "plt.xlabel(\"To token\")\n",
    "plt.ylabel(\"From token\")\n",
    "plt.title(\"Absorbing Transition Matrix (=0.3)\")\n",
    "\n",
    "# Add probability values\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if Q[i,j] > 0.01:\n",
    "            plt.text(j, i, f'{Q[i,j]:.1f}', ha='center', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc5f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple steps compound: Q_bar = Q_1 @ Q_2 @ ... @ Q_t\n",
    "# After many steps, everything ends up as [MASK]\n",
    "\n",
    "Q_bar = torch.eye(5)\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "steps_to_show = [1, 5, 10, 20]\n",
    "\n",
    "for ax, num_steps in zip(axes, steps_to_show):\n",
    "    Q_bar = torch.eye(5)\n",
    "    for _ in range(num_steps):\n",
    "        Q_bar = Q_bar @ Q\n",
    "    \n",
    "    ax.imshow(Q_bar, cmap='Blues', vmin=0, vmax=1)\n",
    "    ax.set_xticks(range(5))\n",
    "    ax.set_xticklabels(small_vocab, rotation=45, fontsize=8)\n",
    "    ax.set_yticks(range(5))\n",
    "    ax.set_yticklabels(small_vocab, fontsize=8)\n",
    "    ax.set_title(f\"After {num_steps} steps\")\n",
    "\n",
    "plt.suptitle(\"Tokens gradually flow to [MASK]\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d592015a",
   "metadata": {},
   "source": [
    "### Alternative: Uniform Diffusion\n",
    "\n",
    "Instead of tokens  `[MASK]`, tokens can become *any* token:\n",
    "\n",
    "$$Q_t[i,j] = \\begin{cases} 1 - \\beta_t & \\text{if } i = j \\\\ \\beta_t / V & \\text{otherwise} \\end{cases}$$\n",
    "\n",
    "This is like adding \"discrete noise\" - tokens randomly flip to other tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13b0ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def make_uniform_transition_matrix(vocab_size, beta):\n",
    "    \"\"\"\n",
    "    Create uniform transition matrix.\n",
    "    Each token can become any other token with equal probability.\n",
    "    \"\"\"\n",
    "    # Off-diagonal: beta / (V-1)\n",
    "    Q = torch.full((vocab_size, vocab_size), beta / (vocab_size - 1))\n",
    "    # Diagonal: 1 - beta\n",
    "    Q.fill_diagonal_(1 - beta)\n",
    "    return Q\n",
    "\n",
    "Q_uniform = make_uniform_transition_matrix(4, beta=0.3)  # Just 4 regular tokens\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.imshow(Q_uniform, cmap='Blues', vmin=0, vmax=1)\n",
    "plt.colorbar(label='Probability')\n",
    "plt.xticks(range(4), [\"cat\", \"dog\", \"bird\", \"fish\"])\n",
    "plt.yticks(range(4), [\"cat\", \"dog\", \"bird\", \"fish\"])\n",
    "plt.xlabel(\"To token\")\n",
    "plt.ylabel(\"From token\")\n",
    "plt.title(\"Uniform Transition Matrix (=0.3)\")\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        plt.text(j, i, f'{Q_uniform[i,j]:.2f}', ha='center', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014356a",
   "metadata": {},
   "source": [
    "### Absorbing vs Uniform: Which to Use?\n",
    "\n",
    "| Approach | Forward Process | Pros | Cons |\n",
    "|----------|-----------------|------|------|\n",
    "| **Absorbing** | tokens  [MASK] | Simpler, fewer possibilities | Needs [MASK] token |\n",
    "| **Uniform** | tokens  any token | More gradual corruption | Harder to learn |\n",
    "\n",
    "**In practice**: Absorbing (mask-based) is more common and easier to train. We'll use it.\n",
    "\n",
    "---\n",
    "\n",
    "## Building a Discrete Diffusion Model\n",
    "\n",
    "Now let's build a working discrete diffusion model for text. We'll train it on a simple pattern to see it learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4549eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a simple dataset\n",
    "# We'll learn to generate short \"sentences\" with structure\n",
    "\n",
    "# Simple vocabulary\n",
    "VOCAB = [\"the\", \"a\", \"cat\", \"dog\", \"bird\", \"sat\", \"ran\", \"flew\", \"on\", \"in\", \"[MASK]\", \"[PAD]\"]\n",
    "VOCAB_SIZE = len(VOCAB)\n",
    "MASK_ID = VOCAB.index(\"[MASK]\")\n",
    "PAD_ID = VOCAB.index(\"[PAD]\")\n",
    "\n",
    "# Create word-to-id and id-to-word mappings\n",
    "word2id = {w: i for i, w in enumerate(VOCAB)}\n",
    "id2word = {i: w for w, i in word2id.items()}\n",
    "\n",
    "print(\"Vocabulary:\")\n",
    "for i, w in enumerate(VOCAB):\n",
    "    print(f\"  {i}: '{w}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8444dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data: simple structured sentences\n",
    "# Pattern: [article] [animal] [verb] [preposition] [article] [animal]\n",
    "\n",
    "def generate_sentence():\n",
    "    \"\"\"Generate a random structured sentence as token ids.\"\"\"\n",
    "    articles = [\"the\", \"a\"]\n",
    "    animals = [\"cat\", \"dog\", \"bird\"]\n",
    "    verbs = [\"sat\", \"ran\", \"flew\"]\n",
    "    preps = [\"on\", \"in\"]\n",
    "    \n",
    "    words = [\n",
    "        np.random.choice(articles),\n",
    "        np.random.choice(animals),\n",
    "        np.random.choice(verbs),\n",
    "        np.random.choice(preps),\n",
    "        np.random.choice(articles),\n",
    "        np.random.choice(animals),\n",
    "    ]\n",
    "    return torch.tensor([word2id[w] for w in words])\n",
    "\n",
    "# Generate some examples\n",
    "print(\"Sample training sentences:\")\n",
    "for _ in range(5):\n",
    "    ids = generate_sentence()\n",
    "    words = [id2word[i.item()] for i in ids]\n",
    "    print(f\"  {' '.join(words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ecb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training dataset\n",
    "SEQ_LEN = 6  # Our sentences are 6 tokens\n",
    "train_data = torch.stack([generate_sentence() for _ in range(1000)])\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"(1000 sentences, each 6 tokens)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a82c2d",
   "metadata": {},
   "source": [
    "### The Noise Schedule for Discrete Diffusion\n",
    "\n",
    "Just like continuous diffusion, we need a schedule that controls how fast tokens get masked.\n",
    "\n",
    "We'll use a **cosine schedule** - it's smoother than linear and works better in practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def cosine_schedule(num_steps, s=0.008):\n",
    "    \"\"\"\n",
    "    Cosine noise schedule.\n",
    "    Returns alpha_bar (cumulative product of 1-beta) at each timestep.\n",
    "    \"\"\"\n",
    "    t = torch.linspace(0, num_steps, num_steps + 1)\n",
    "    f_t = torch.cos((t / num_steps + s) / (1 + s) * np.pi / 2) ** 2\n",
    "    alpha_bar = f_t / f_t[0]\n",
    "    return alpha_bar[1:]  # Remove t=0\n",
    "\n",
    "NUM_DIFFUSION_STEPS = 100\n",
    "alpha_bar_discrete = cosine_schedule(NUM_DIFFUSION_STEPS)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(alpha_bar_discrete, label=' (prob of keeping original)')\n",
    "plt.plot(1 - alpha_bar_discrete, label='1- (prob of being masked)', linestyle='--')\n",
    "plt.xlabel(\"Timestep t\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"Cosine Noise Schedule\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"At t=0: {alpha_bar_discrete[0]:.3f} chance of keeping original (barely noisy)\")\n",
    "print(f\"At t=50: {alpha_bar_discrete[50]:.3f} chance of keeping original\")\n",
    "print(f\"At t=99: {alpha_bar_discrete[99]:.3f} chance of keeping original (almost all masked)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf557a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def discrete_forward_diffusion(x_0, t, alpha_bar, mask_id):\n",
    "    \"\"\"\n",
    "    Corrupt tokens by randomly replacing with [MASK].\n",
    "    \n",
    "    Args:\n",
    "        x_0: Original tokens [batch_size, seq_len]\n",
    "        t: Timestep for each sample [batch_size]\n",
    "        alpha_bar: Noise schedule [num_steps]\n",
    "        mask_id: ID of the [MASK] token\n",
    "    \n",
    "    Returns:\n",
    "        x_t: Corrupted tokens [batch_size, seq_len]\n",
    "    \"\"\"\n",
    "    # Get masking probability for each sample\n",
    "    mask_prob = 1 - alpha_bar[t]  # [batch_size]\n",
    "    \n",
    "    # Sample mask: which positions to corrupt\n",
    "    mask = torch.rand_like(x_0.float()) < mask_prob.unsqueeze(-1)\n",
    "    \n",
    "    # Apply mask\n",
    "    x_t = torch.where(mask, torch.full_like(x_0, mask_id), x_0)\n",
    "    \n",
    "    return x_t, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb114f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate discrete forward diffusion on a single sentence\n",
    "example = train_data[0:1]  # [1, 6]\n",
    "print(\"Original:\", ' '.join([id2word[i.item()] for i in example[0]]))\n",
    "print()\n",
    "\n",
    "for t_val in [0, 25, 50, 75, 99]:\n",
    "    t = torch.tensor([t_val])\n",
    "    corrupted, _ = discrete_forward_diffusion(example, t, alpha_bar_discrete, MASK_ID)\n",
    "    words = [id2word[i.item()] for i in corrupted[0]]\n",
    "    print(f\"t={t_val:2d}: {' '.join(words)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774c3612",
   "metadata": {},
   "source": [
    "### The Denoising Network\n",
    "\n",
    "The network takes:\n",
    "- Corrupted tokens $x_t$\n",
    "- Timestep $t$\n",
    "\n",
    "And predicts: **logits for each token position** (what should the original token be?)\n",
    "\n",
    "We'll use a simple Transformer - it needs to see all positions to make good predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe539ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    \"\"\"Sinusoidal position embedding for timesteps (from original diffusion paper).\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = np.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "# Demo: timestep embeddings are different for different t\n",
    "time_emb = SinusoidalPosEmb(32)\n",
    "t_examples = torch.tensor([0, 25, 50, 75, 99], dtype=torch.float)\n",
    "embeddings = time_emb(t_examples)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.imshow(embeddings.detach().numpy(), aspect='auto', cmap='RdBu')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Embedding dimension\")\n",
    "plt.ylabel(\"Timestep\")\n",
    "plt.yticks(range(5), ['t=0', 't=25', 't=50', 't=75', 't=99'])\n",
    "plt.title(\"Sinusoidal Timestep Embeddings\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class DiscreteTextDenoiser(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple Transformer-based denoiser for discrete text diffusion.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, max_seq_len=64):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Token embedding\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
    "        \n",
    "        # Position embedding\n",
    "        self.pos_emb = nn.Embedding(max_seq_len, d_model)\n",
    "        \n",
    "        # Timestep embedding\n",
    "        self.time_emb = nn.Sequential(\n",
    "            SinusoidalPosEmb(d_model),\n",
    "            nn.Linear(d_model, d_model * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "        )\n",
    "        \n",
    "        # Transformer encoder (bidirectional - can see all positions)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=d_model * 4,\n",
    "            batch_first=True,\n",
    "            norm_first=True,  # Pre-norm for stability\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output projection to vocabulary\n",
    "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Token ids [batch_size, seq_len]\n",
    "            t: Timesteps [batch_size]\n",
    "        Returns:\n",
    "            logits: [batch_size, seq_len, vocab_size]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.shape\n",
    "        \n",
    "        # Token + position embeddings\n",
    "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0)\n",
    "        h = self.token_emb(x) + self.pos_emb(positions)\n",
    "        \n",
    "        # Add timestep embedding to all positions\n",
    "        t_emb = self.time_emb(t.float())  # [batch_size, d_model]\n",
    "        h = h + t_emb.unsqueeze(1)\n",
    "        \n",
    "        # Transformer\n",
    "        h = self.transformer(h)\n",
    "        \n",
    "        # Project to vocabulary\n",
    "        logits = self.output_proj(h)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0114c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = DiscreteTextDenoiser(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    d_model=128,\n",
    "    nhead=4,\n",
    "    num_layers=2,\n",
    "    max_seq_len=SEQ_LEN\n",
    ").to(device)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {n_params:,}\")\n",
    "\n",
    "# Quick test\n",
    "test_x = train_data[:2].to(device)\n",
    "test_t = torch.tensor([10, 50], device=device)\n",
    "test_output = model(test_x, test_t)\n",
    "print(f\"Input shape: {test_x.shape}\")\n",
    "print(f\"Output shape: {test_output.shape}  (batch, seq_len, vocab_size)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6400b7",
   "metadata": {},
   "source": [
    "### Training: The Denoising Loss\n",
    "\n",
    "The loss is simple: **cross-entropy on the masked positions only**.\n",
    "\n",
    "We don't care about predicting tokens that weren't masked - we only train the model to \"fill in the blanks\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa7cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "train_data_device = train_data.to(device)\n",
    "alpha_bar_device = alpha_bar_discrete.to(device)\n",
    "\n",
    "batch_size = 64\n",
    "losses = []\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    \n",
    "    # Sample batch\n",
    "    idx = torch.randint(0, len(train_data), (batch_size,))\n",
    "    x_0 = train_data_device[idx]\n",
    "    \n",
    "    # Sample random timesteps\n",
    "    t = torch.randint(0, NUM_DIFFUSION_STEPS, (batch_size,), device=device)\n",
    "    \n",
    "    # Forward diffusion (add noise)\n",
    "    x_t, mask = discrete_forward_diffusion(x_0, t, alpha_bar_device, MASK_ID)\n",
    "    \n",
    "    # Predict logits\n",
    "    logits = model(x_t, t)\n",
    "    \n",
    "    # Loss: cross-entropy on masked positions only\n",
    "    # We use the original tokens as targets\n",
    "    loss = F.cross_entropy(\n",
    "        logits.view(-1, VOCAB_SIZE),\n",
    "        x_0.view(-1),\n",
    "        reduction='none'\n",
    "    )\n",
    "    \n",
    "    # Only count loss on masked positions\n",
    "    loss = (loss.view(batch_size, -1) * mask.float()).sum() / mask.float().sum()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Discrete Text Diffusion Training Loss\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a16186",
   "metadata": {},
   "source": [
    "### Generation: Iterative Unmasking\n",
    "\n",
    "To generate, we reverse the process:\n",
    "1. Start with all `[MASK]` tokens\n",
    "2. At each step, predict tokens for masked positions\n",
    "3. Unmask some positions based on confidence\n",
    "4. Repeat until all unmasked\n",
    "\n",
    "This is like BERT demasking, but done iteratively!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f7fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@torch.no_grad()\n",
    "def sample_discrete(model, seq_len, num_steps, alpha_bar, mask_id, vocab_size, device, n_samples=1):\n",
    "    \"\"\"\n",
    "    Generate text by iteratively unmasking.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Start with all masks\n",
    "    x = torch.full((n_samples, seq_len), mask_id, device=device)\n",
    "    trajectory = [x.cpu().clone()]\n",
    "    \n",
    "    for t in reversed(range(num_steps)):\n",
    "        t_batch = torch.full((n_samples,), t, device=device)\n",
    "        \n",
    "        # Predict logits for all positions\n",
    "        logits = model(x, t_batch)\n",
    "        \n",
    "        # Sample from predicted distribution (with temperature)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        predicted = torch.multinomial(probs.view(-1, vocab_size), 1).view(n_samples, seq_len)\n",
    "        \n",
    "        # Determine which positions should be unmasked at this step\n",
    "        # Use the schedule: prob of being unmasked = 1 - alpha_bar[t] going to 1 - alpha_bar[t-1]\n",
    "        if t > 0:\n",
    "            mask_prob_now = 1 - alpha_bar[t]\n",
    "            mask_prob_prev = 1 - alpha_bar[t-1]\n",
    "            # Unmask with probability (mask_prob_now - mask_prob_prev) / mask_prob_now\n",
    "            unmask_prob = (mask_prob_now - mask_prob_prev) / (mask_prob_now + 1e-8)\n",
    "            unmask = torch.rand_like(x.float()) < unmask_prob\n",
    "        else:\n",
    "            # Last step: unmask everything remaining\n",
    "            unmask = (x == mask_id)\n",
    "        \n",
    "        # Only unmask positions that are currently masked\n",
    "        unmask = unmask & (x == mask_id)\n",
    "        \n",
    "        # Apply predictions to unmasked positions\n",
    "        x = torch.where(unmask, predicted, x)\n",
    "        trajectory.append(x.cpu().clone())\n",
    "    \n",
    "    return x, trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae545c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some samples!\n",
    "generated, gen_trajectory = sample_discrete(\n",
    "    model, SEQ_LEN, NUM_DIFFUSION_STEPS, alpha_bar_device, MASK_ID, VOCAB_SIZE, device, n_samples=10\n",
    ")\n",
    "\n",
    "print(\"Generated sentences:\\n\")\n",
    "for i in range(10):\n",
    "    words = [id2word[tok.item()] for tok in generated[i]]\n",
    "    print(f\"  {' '.join(words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6623f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the generation process for one sample\n",
    "print(\"Generation process (one sample):\\n\")\n",
    "\n",
    "steps_to_show = [0, 25, 50, 75, 90, 100]\n",
    "for step in steps_to_show:\n",
    "    words = [id2word[tok.item()] for tok in gen_trajectory[step][0]]\n",
    "    n_masked = sum(1 for w in words if w == \"[MASK]\")\n",
    "    print(f\"Step {step:3d}: {' '.join(words):50s}  ({n_masked} masks remaining)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d91b17",
   "metadata": {},
   "source": [
    "### Test Problem: Confidence-Based Sampling\n",
    "\n",
    "Currently our sampler unmasks positions randomly. A better strategy: **unmask the most confident predictions first**.\n",
    "\n",
    "Fill in the function below to implement confidence-based sampling:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebecb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_confidence_based_unmask(logits, x, mask_id, n_to_unmask):\n",
    "    \"\"\"\n",
    "    Given logits and current tokens, return which positions to unmask.\n",
    "    \n",
    "    Args:\n",
    "        logits: [batch_size, seq_len, vocab_size]\n",
    "        x: Current token ids [batch_size, seq_len]  \n",
    "        mask_id: ID of [MASK] token\n",
    "        n_to_unmask: How many positions to unmask this step\n",
    "        \n",
    "    Returns:\n",
    "        unmask: Boolean tensor [batch_size, seq_len] of positions to unmask\n",
    "    \"\"\"\n",
    "    batch_size, seq_len, vocab_size = logits.shape\n",
    "    \n",
    "    # Get confidence (max probability) for each position\n",
    "    test_probs = F.softmax(logits, dim=-1)\n",
    "    test_confidence = test_probs.max(dim=-1).values  # [batch_size, seq_len]\n",
    "    \n",
    "    # Only consider masked positions\n",
    "    test_is_masked = (x == mask_id)\n",
    "    \n",
    "    # FILL IN: Set confidence of non-masked positions to -inf so they won't be selected\n",
    "    # test_confidence = ...\n",
    "    \n",
    "    # FILL IN: For each sample, find the top-k most confident masked positions\n",
    "    # Hint: use torch.topk\n",
    "    # test_top_indices = ...\n",
    "    \n",
    "    # FILL IN: Create boolean mask for positions to unmask\n",
    "    # test_unmask = ...\n",
    "    \n",
    "    return test_unmask\n",
    "\n",
    "# Test your implementation:\n",
    "# If correct, this should unmask the 2 most confident masked positions\n",
    "test_logits = torch.randn(1, 6, VOCAB_SIZE)\n",
    "test_x = torch.tensor([[MASK_ID, 2, MASK_ID, MASK_ID, 3, MASK_ID]])  # 4 masked positions\n",
    "# test_result = test_confidence_based_unmask(test_logits, test_x, MASK_ID, n_to_unmask=2)\n",
    "# assert test_result.sum() == 2, \"Should unmask exactly 2 positions\"\n",
    "# print(\"Test passed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a614596",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Connecting the Dots: Diffusion as Denoising Autoencoders\n",
    "\n",
    "Now that we've built and trained a working model, let's connect to a fundamental insight:\n",
    "\n",
    "> **\"A diffusion model is basically a denoising autoencoder trained in a very particular way, on a very extreme noise schedule, with a Markov chain structure.\"**\n",
    "\n",
    "Let's unpack this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d80c654",
   "metadata": {},
   "source": [
    "### What's a Denoising Autoencoder (DAE)?\n",
    "\n",
    "You know regular autoencoders: encode  bottleneck  decode to reconstruct input.\n",
    "\n",
    "A **Denoising Autoencoder** has one twist: \n",
    "- Input: **corrupted** data (add noise, mask parts, etc.)\n",
    "- Target: **original** clean data\n",
    "- The network learns to \"denoise\"\n",
    "\n",
    "Sound familiar? That's exactly what we just built!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393eda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DAE vs Diffusion: Side-by-Side Comparison\n",
    "\n",
    "| Aspect | **Denoising Autoencoder** | **Diffusion Model** |\n",
    "|--------|--------------------------|---------------------|\n",
    "| **Training** | 1. Take clean data $x$ | 1. Take clean data $x_0$ |\n",
    "| | 2. Corrupt once: $\\tilde{x} = \\text{corrupt}(x)$ | 2. Corrupt at MANY levels: $x_t = \\text{corrupt}(x_0, t)$ |\n",
    "| | 3. Train: $f(\\tilde{x}) \\to x$ | 3. Train: $f(x_t, t) \\to \\epsilon$ or $x_0$ |\n",
    "| **Corruption** | Single fixed level | Continuous spectrum from barely noisy  pure noise |\n",
    "| **Network awareness** | Doesn't know noise level | Receives timestep $t$ as input |\n",
    "| **Generation** |  Can't generate - only reconstructs |  Can generate from pure noise! |\n",
    "\n",
    "The key difference: **Diffusion learns to denoise from ALL noise levels**, including pure noise. This is what enables generation!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b9fc5",
   "metadata": {},
   "source": [
    "### The Three Key Differences\n",
    "\n",
    "**1. \"Very particular way\"** - Training on ALL noise levels\n",
    "- DAE: one fixed corruption level\n",
    "- Diffusion: trained on every noise level from barely noisy to pure noise\n",
    "\n",
    "**2. \"Extreme noise schedule\"** - We go all the way to pure noise\n",
    "- DAE: mild corruption (you can still see the original)\n",
    "- Diffusion: at t=T, data is completely destroyed\n",
    "\n",
    "**3. \"Markov chain structure\"** - Each step only depends on the previous\n",
    "- This lets us decompose the hard problem (noise  data) into many easy steps\n",
    "- Each step only needs to remove a tiny bit of noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b12b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Markov chain insight: breaking hard into easy\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Left: The impossible single-step problem\n",
    "ax = axes[0]\n",
    "ax.text(0.1, 0.8, \"Pure Noise\", fontsize=14, fontweight='bold')\n",
    "ax.text(0.1, 0.6, \"[MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\", fontsize=10, family='monospace')\n",
    "ax.annotate(\"\", xy=(0.9, 0.5), xytext=(0.1, 0.5),\n",
    "            arrowprops=dict(arrowstyle=\"->\", lw=3, color='red'))\n",
    "ax.text(0.5, 0.52, \"???\", fontsize=16, ha='center', color='red', fontweight='bold')\n",
    "ax.text(0.7, 0.8, \"Clean Data\", fontsize=14, fontweight='bold')\n",
    "ax.text(0.55, 0.6, \"the cat sat on the mat\", fontsize=10, family='monospace')\n",
    "ax.text(0.5, 0.2, \"ONE GIANT LEAP\\n(Impossible to learn!)\", fontsize=12, ha='center', color='red')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title(\" The Hard Way: One Step\", fontsize=14)\n",
    "\n",
    "# Right: The easy multi-step problem\n",
    "ax = axes[1]\n",
    "steps = [\n",
    "    \"[M] [M] [M] [M] [M] [M]\",\n",
    "    \"[M] [M] [M] [M] [M] mat\",\n",
    "    \"[M] [M] sat [M] [M] mat\",\n",
    "    \"the [M] sat [M] the mat\",\n",
    "    \"the cat sat on the mat\",\n",
    "]\n",
    "for i, step in enumerate(steps):\n",
    "    y = 0.85 - i * 0.17\n",
    "    ax.text(0.1, y, step, fontsize=9, family='monospace')\n",
    "    if i < len(steps) - 1:\n",
    "        ax.annotate(\"\", xy=(0.08, y - 0.05), xytext=(0.08, y - 0.12),\n",
    "                    arrowprops=dict(arrowstyle=\"->\", lw=1.5, color='green'))\n",
    "ax.text(0.5, 0.05, \"MANY SMALL STEPS\\n(Each step is easy!)\", fontsize=12, ha='center', color='green')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title(\" The Easy Way: Many Steps (Markov Chain)\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b92380b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Deep Dive: Production Text Diffusion Models\n",
    "\n",
    "Now let's look at real models. We'll progress through the evolution:\n",
    "\n",
    "1. **Diffusion-LM** (2022) - The foundational paper, continuous embeddings\n",
    "2. **DiffuSeq** (2023) - Seq2seq conditioning\n",
    "3. **MMDiT** (2024) - Modern transformer-based diffusion\n",
    "\n",
    "Let's start by loading Diffusion-LM and understanding its architecture.\n",
    "\n",
    "<!-- \n",
    "IMAGE REQUEST: Diffusion-LM architecture diagram\n",
    "URL: https://arxiv.org/abs/2205.14217 (Figure 1)\n",
    "Description: Shows the embedding diffusion process with encoder and decoder\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f38bbc",
   "metadata": {},
   "source": [
    "### Diffusion-LM: The Foundation (Deep Dive)\n",
    "\n",
    "**Paper**: \"Diffusion-LM Improves Controllable Text Generation\" (Li et al., 2022)\n",
    "\n",
    "#### Why Diffusion-LM Matters\n",
    "\n",
    "Diffusion-LM was the first to show diffusion could work for text generation. It solved the discretecontinuous problem elegantly and introduced key ideas that every subsequent model builds on.\n",
    "\n",
    "**What you'll learn here:**\n",
    "1. How to diffuse in embedding space (the continuous trick)\n",
    "2. Score matching for text - what does the score mean for embeddings?\n",
    "3. The rounding problem and how to solve it\n",
    "4. Classifier guidance - steering generation toward desired attributes\n",
    "5. Noise schedules tuned for text\n",
    "6. Sampling tradeoffs (steps vs quality)\n",
    "\n",
    "#### The Core Architecture\n",
    "\n",
    "```\n",
    "Text: \"The cat sat\"\n",
    "     Embedding Layer (LEARNED, not frozen!)\n",
    "Embeddings: [[0.2, -0.1, ...], [0.5, 0.3, ...], [0.1, 0.8, ...]]  \n",
    "     Add noise (standard Gaussian diffusion)\n",
    "Noisy Embeddings: [[0.3, 0.1, ...], [0.2, 0.5, ...], [0.4, 0.6, ...]]\n",
    "     Transformer Denoiser (with timestep conditioning)  \n",
    "Denoised Embeddings: [[0.19, -0.08, ...], [0.51, 0.29, ...], [0.12, 0.81, ...]]\n",
    "     Rounding (project to nearest token embedding)\n",
    "Text: \"The cat sat\"\n",
    "```\n",
    "\n",
    "#### Why Learned Embeddings?\n",
    "\n",
    "If we used frozen embeddings (like Word2Vec or frozen BERT):\n",
    "- Embeddings are clustered in complex manifolds\n",
    "- Diffusion would push points off the manifold\n",
    "- Hard to round back to valid tokens\n",
    "\n",
    "With **learned embeddings**:\n",
    "- The model can shape the embedding space for diffusion\n",
    "- Embeddings spread out to make denoising easier\n",
    "- Trained end-to-end with the diffusion objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea01b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing embedding space diffusion vs discrete diffusion\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Left: Token space (discrete)\n",
    "ax = axes[0]\n",
    "tokens = ['cat', 'dog', 'bird', 'fish', 'run', 'fly']\n",
    "for i, tok in enumerate(tokens):\n",
    "    ax.scatter(i, 0, s=200, c='blue')\n",
    "    ax.annotate(tok, (i, 0.05), ha='center', fontsize=10)\n",
    "ax.set_xlim(-1, 6)\n",
    "ax.set_ylim(-0.5, 0.5)\n",
    "ax.set_title(\"Discrete Token Space\\n(Can't interpolate!)\")\n",
    "ax.axhline(0, color='gray', linestyle='--', alpha=0.3)\n",
    "ax.set_yticks([])\n",
    "ax.text(2.5, -0.3, \"What's between 'cat' and 'dog'? Nothing!\", ha='center', fontsize=9)\n",
    "\n",
    "# Middle: Learned embedding space\n",
    "ax = axes[1]\n",
    "# Pretend embeddings arranged nicely for diffusion\n",
    "emb_positions = {\n",
    "    'cat': (0, 0), 'dog': (0.5, 0.2), 'mouse': (-0.2, -0.3),\n",
    "    'run': (1.5, 0), 'walk': (1.3, 0.3), 'fly': (1.7, -0.2),\n",
    "}\n",
    "for word, (x, y) in emb_positions.items():\n",
    "    ax.scatter(x, y, s=100, c='green')\n",
    "    ax.annotate(word, (x+0.05, y+0.05), fontsize=9)\n",
    "# Show a noisy point in between\n",
    "ax.scatter(0.2, 0.1, s=100, c='red', marker='x', linewidths=2)\n",
    "ax.annotate(\"noisy\\npoint\", (0.25, 0.15), fontsize=8, color='red')\n",
    "ax.set_title(\"Learned Embedding Space\\n(Continuous - can interpolate!)\")\n",
    "ax.set_xlim(-0.5, 2)\n",
    "ax.set_ylim(-0.5, 0.5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: The advantage\n",
    "ax = axes[2]\n",
    "ax.text(0.5, 0.8, \"Why Embedding Space?\", fontsize=14, ha='center', fontweight='bold', transform=ax.transAxes)\n",
    "ax.text(0.1, 0.6, \" Can add Gaussian noise\", fontsize=11, transform=ax.transAxes)\n",
    "ax.text(0.1, 0.5, \" Smooth gradients\", fontsize=11, transform=ax.transAxes)\n",
    "ax.text(0.1, 0.4, \" Standard diffusion math works\", fontsize=11, transform=ax.transAxes)\n",
    "ax.text(0.1, 0.25, \" Must 'round' back to tokens\", fontsize=11, transform=ax.transAxes, color='orange')\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57281701",
   "metadata": {},
   "source": [
    "#### Classifier Guidance: Steering Generation\n",
    "\n",
    "One of Diffusion-LM's killer features: **controllable generation**.\n",
    "\n",
    "**The Problem**: You want to generate text with specific properties (positive sentiment, formal style, about cats, etc.)\n",
    "\n",
    "**The Solution**: Train a classifier on noisy embeddings, then use its gradients to steer!\n",
    "\n",
    "**The Math**:\n",
    "At each denoising step, instead of just following the score, we add the classifier gradient:\n",
    "\n",
    "$$\\nabla_{x_t} \\log p(x_{t-1}|x_t, y) \\propto \\nabla_{x_t} \\log p(x_{t-1}|x_t) + \\gamma \\cdot \\nabla_{x_t} \\log p(y|x_t)$$\n",
    "\n",
    "where:\n",
    "- $\\nabla_{x_t} \\log p(x_{t-1}|x_t)$ = the diffusion model's denoising direction\n",
    "- $\\nabla_{x_t} \\log p(y|x_t)$ = the classifier's \"this is class y\" direction\n",
    "- $\\gamma$ = guidance strength (how hard to steer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing classifier guidance\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Setup: imagine 2D embedding space with \"positive\" and \"negative\" regions\n",
    "np.random.seed(42)\n",
    "positive_center = np.array([1.5, 1.0])\n",
    "negative_center = np.array([-1.0, -0.5])\n",
    "\n",
    "# Left: Unguided sampling\n",
    "ax = axes[0]\n",
    "# Show trajectory without guidance\n",
    "trajectory_unguided = [np.array([0, 0])]\n",
    "for i in range(5):\n",
    "    next_point = trajectory_unguided[-1] + np.random.randn(2) * 0.3\n",
    "    trajectory_unguided.append(next_point)\n",
    "trajectory_unguided = np.array(trajectory_unguided)\n",
    "\n",
    "ax.scatter(*positive_center, s=300, c='green', marker='*', label='Positive region')\n",
    "ax.scatter(*negative_center, s=300, c='red', marker='*', label='Negative region')\n",
    "ax.plot(trajectory_unguided[:, 0], trajectory_unguided[:, 1], 'b-o', linewidth=2, markersize=8, label='Sampling path')\n",
    "ax.scatter(0, 0, s=100, c='gray', marker='s', zorder=5, label='Start (noise)')\n",
    "ax.set_title(\"Without Guidance\\n(Random walk)\")\n",
    "ax.legend(loc='lower right', fontsize=8)\n",
    "ax.set_xlim(-2.5, 2.5)\n",
    "ax.set_ylim(-2, 2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Middle: Guided toward positive\n",
    "ax = axes[1]\n",
    "trajectory_guided = [np.array([0, 0])]\n",
    "for i in range(5):\n",
    "    # Guidance: pull toward positive center\n",
    "    direction_to_positive = positive_center - trajectory_guided[-1]\n",
    "    guidance = 0.3 * direction_to_positive / (np.linalg.norm(direction_to_positive) + 0.1)\n",
    "    next_point = trajectory_guided[-1] + np.random.randn(2) * 0.2 + guidance\n",
    "    trajectory_guided.append(next_point)\n",
    "trajectory_guided = np.array(trajectory_guided)\n",
    "\n",
    "ax.scatter(*positive_center, s=300, c='green', marker='*', label='Positive region')\n",
    "ax.scatter(*negative_center, s=300, c='red', marker='*', label='Negative region')\n",
    "ax.plot(trajectory_guided[:, 0], trajectory_guided[:, 1], 'g-o', linewidth=2, markersize=8, label='Guided path')\n",
    "ax.scatter(0, 0, s=100, c='gray', marker='s', zorder=5, label='Start (noise)')\n",
    "ax.set_title(\"With Classifier Guidance\\n(Steered toward positive)\")\n",
    "ax.legend(loc='lower right', fontsize=8)\n",
    "ax.set_xlim(-2.5, 2.5)\n",
    "ax.set_ylim(-2, 2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: The formula\n",
    "ax = axes[2]\n",
    "ax.text(0.5, 0.85, \"Guided Score\", fontsize=14, ha='center', fontweight='bold', transform=ax.transAxes)\n",
    "ax.text(0.5, 0.65, r\"$\\nabla \\log p(x_{t-1}|x_t, y)$\", fontsize=14, ha='center', transform=ax.transAxes)\n",
    "ax.text(0.5, 0.45, \"=\", fontsize=14, ha='center', transform=ax.transAxes)\n",
    "ax.text(0.5, 0.30, r\"$\\underbrace{\\nabla \\log p(x_{t-1}|x_t)}_{\\text{diffusion}}$\", fontsize=12, ha='center', transform=ax.transAxes)\n",
    "ax.text(0.5, 0.12, r\"$+ \\gamma \\cdot \\underbrace{\\nabla \\log p(y|x_t)}_{\\text{classifier}}$\", fontsize=12, ha='center', transform=ax.transAxes)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The classifier gradient 'nudges' the sampling trajectory toward regions\")\n",
    "print(\"that the classifier associates with the target class!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone Diffusion-LM repository (if not already cloned)\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "DIFFUSION_LM_DIR = \"diffusion_lm_repo\"\n",
    "\n",
    "if not os.path.exists(DIFFUSION_LM_DIR):\n",
    "    print(\"Cloning Diffusion-LM repository...\")\n",
    "    subprocess.run([\n",
    "        \"git\", \"clone\", \n",
    "        \"https://github.com/XiangLi1999/Diffusion-LM.git\",\n",
    "        DIFFUSION_LM_DIR\n",
    "    ], check=True)\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    print(f\"Repository already exists at {DIFFUSION_LM_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30bf541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the key files in Diffusion-LM\n",
    "import sys\n",
    "sys.path.insert(0, DIFFUSION_LM_DIR)\n",
    "\n",
    "# List the main components\n",
    "print(\"Key components in Diffusion-LM:\\n\")\n",
    "for root, dirs, files in os.walk(DIFFUSION_LM_DIR):\n",
    "    # Only show top-level python files\n",
    "    if root == DIFFUSION_LM_DIR:\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]  # Skip hidden dirs\n",
    "        for f in sorted(files):\n",
    "            if f.endswith('.py'):\n",
    "                print(f\"  {f}\")\n",
    "        print(\"\\n  Subdirectories:\")\n",
    "        for d in sorted(dirs)[:5]:\n",
    "            print(f\"    {d}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17294fc",
   "metadata": {},
   "source": [
    "### Diffusion-LM Architecture Dissection\n",
    "\n",
    "The key components of Diffusion-LM:\n",
    "\n",
    "1. **Embedding Layer**: Maps discrete tokens  continuous vectors\n",
    "2. **Transformer Backbone**: Processes noisy embeddings with timestep conditioning\n",
    "3. **Rounding Layer**: Maps continuous vectors  discrete tokens\n",
    "4. **Classifier Guidance**: Controls generation toward desired attributes\n",
    "\n",
    "Let's examine each:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the core model structure\n",
    "# The main model is in improved-diffusion/improved_diffusion/\n",
    "\n",
    "import inspect\n",
    "\n",
    "# Read the key model file\n",
    "model_file = os.path.join(DIFFUSION_LM_DIR, \"improved-diffusion\", \"improved_diffusion\", \"transformer_model2.py\")\n",
    "\n",
    "if os.path.exists(model_file):\n",
    "    with open(model_file, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Find the main model class\n",
    "    print(\"Key classes in transformer_model2.py:\\n\")\n",
    "    for line in content.split('\\n'):\n",
    "        if line.strip().startswith('class ') and '(' in line:\n",
    "            print(f\"  {line.strip()}\")\n",
    "else:\n",
    "    print(f\"File not found: {model_file}\")\n",
    "    print(\"Structure may have changed. Let's find the model files...\")\n",
    "    for root, dirs, files in os.walk(DIFFUSION_LM_DIR):\n",
    "        for f in files:\n",
    "            if 'model' in f.lower() and f.endswith('.py'):\n",
    "                print(f\"  {os.path.join(root, f)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6917fad",
   "metadata": {},
   "source": [
    "### Loading Diffusion-LM Pretrained Weights\n",
    "\n",
    "The authors provide pretrained checkpoints. Let's download and inspect one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained checkpoint\n",
    "# The authors host checkpoints on Google Drive\n",
    "# We'll use a smaller checkpoint for exploration\n",
    "\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "CHECKPOINT_DIR = \"diffusion_lm_checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Note: You may need to manually download from:\n",
    "# https://github.com/XiangLi1999/Diffusion-LM#download-checkpoints\n",
    "# \n",
    "# The checkpoints are hosted on Google Drive:\n",
    "# - e2e-tgt: for E2E dataset\n",
    "# - roc: for ROCStories dataset\n",
    "\n",
    "print(\"Diffusion-LM checkpoints need to be downloaded from Google Drive.\")\n",
    "print(\"See: https://github.com/XiangLi1999/Diffusion-LM#download-checkpoints\")\n",
    "print()\n",
    "print(\"For now, let's understand the architecture by examining the code...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48581fc2",
   "metadata": {},
   "source": [
    "### Key Insights from Diffusion-LM\n",
    "\n",
    "**1. The Embedding Trick**\n",
    "- Use learned embeddings, not frozen ones\n",
    "- Embeddings are trained jointly with the diffusion model\n",
    "- This creates a \"latent space\" optimized for diffusion\n",
    "\n",
    "**2. The Rounding Problem Solution**\n",
    "- Soft rounding during training: gradually push embeddings toward token embeddings\n",
    "- Clamping trick: project back to nearest embedding periodically\n",
    "\n",
    "**3. Classifier Guidance**\n",
    "- Train a classifier on noisy embeddings\n",
    "- At generation time, use classifier gradient to steer toward desired properties\n",
    "- Example: generate text with positive sentiment\n",
    "\n",
    "**4. Limitations**\n",
    "- Slow sampling (many denoising steps)\n",
    "- Rounding errors accumulate\n",
    "- Not as fluent as autoregressive models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48667fe3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### DiffuSeq: Conditioning for Seq2Seq (Deep Dive)\n",
    "\n",
    "**Paper**: \"DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models\" (Gong et al., 2023)\n",
    "\n",
    "#### Why DiffuSeq Matters\n",
    "\n",
    "Diffusion-LM showed diffusion can generate text. But real NLP tasks need **conditioning**:\n",
    "- Translation: English  French\n",
    "- Summarization: Long article  Short summary\n",
    "- QA: Question  Answer\n",
    "\n",
    "DiffuSeq answers: **How does diffusion replace the autoregressive decoder in seq2seq?**\n",
    "\n",
    "#### The Conditioning Problem\n",
    "\n",
    "In autoregressive seq2seq (like T5):\n",
    "```\n",
    "Encoder: \"The cat sat\"  hidden states\n",
    "Decoder: Generates \"Le chat...\" token by token, attending to encoder\n",
    "```\n",
    "\n",
    "In diffusion, we generate all at once. How do we condition on the source?\n",
    "\n",
    "#### The DiffuSeq Solution: Partial Noising\n",
    "\n",
    "```\n",
    "Input:  [source tokens] | [target tokens]\n",
    "        [The] [cat] [sat] | [Le] [chat] [assis]\n",
    "                          \n",
    "Forward: Only noise the TARGET portion!\n",
    "        [The] [cat] [sat] | [MASK] [MASK] [MASK]  (t=T)\n",
    "        \n",
    "Reverse: Denoise target while attending to source\n",
    "        [The] [cat] [sat] | [Le] [chat] [assis]   (t=0)\n",
    "```\n",
    "\n",
    "The source tokens stay clean throughout - the model can always \"look\" at them!\n",
    "\n",
    "#### Why This Works\n",
    "\n",
    "1. **Self-attention across concatenated sequence**: Target attends to source\n",
    "2. **Source provides context**: Even at high noise, model knows what to generate about\n",
    "3. **No separate encoder needed**: Single transformer does everything\n",
    "4. **Natural for seq2seq**: Directly maps inputoutput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28bdebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing DiffuSeq's partial noising strategy\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 6))\n",
    "\n",
    "source = [\"The\", \"cat\", \"sat\"]\n",
    "target_clean = [\"Le\", \"chat\", \"assis\"]\n",
    "\n",
    "# Different timesteps showing the denoising\n",
    "timesteps = [100, 75, 50, 0]\n",
    "target_at_t = [\n",
    "    [\"[M]\", \"[M]\", \"[M]\"],\n",
    "    [\"[M]\", \"chat\", \"[M]\"],\n",
    "    [\"Le\", \"chat\", \"[M]\"],\n",
    "    [\"Le\", \"chat\", \"assis\"],\n",
    "]\n",
    "\n",
    "for i, (t, tgt) in enumerate(zip(timesteps, target_at_t)):\n",
    "    ax = axes[0, i]\n",
    "    # Draw source (always clean)\n",
    "    for j, tok in enumerate(source):\n",
    "        ax.add_patch(plt.Rectangle((j*1.2, 0.5), 1, 0.4, color='lightgreen', ec='green', lw=2))\n",
    "        ax.text(j*1.2 + 0.5, 0.7, tok, ha='center', va='center', fontsize=10)\n",
    "    # Draw target\n",
    "    for j, tok in enumerate(tgt):\n",
    "        color = 'lightgray' if tok == \"[M]\" else 'lightblue'\n",
    "        ax.add_patch(plt.Rectangle((j*1.2 + 4, 0.5), 1, 0.4, color=color, ec='blue', lw=2))\n",
    "        ax.text(j*1.2 + 4.5, 0.7, tok, ha='center', va='center', fontsize=10)\n",
    "    ax.set_xlim(-0.5, 8)\n",
    "    ax.set_ylim(0, 1.5)\n",
    "    ax.set_title(f\"t = {t}\" + (\" (noise)\" if t == 100 else \" (clean)\" if t == 0 else \"\"))\n",
    "    ax.axis('off')\n",
    "    # Labels\n",
    "    if i == 0:\n",
    "        ax.text(1.5, 1.2, \"Source\\n(always clean)\", ha='center', fontsize=9, color='green')\n",
    "        ax.text(5.5, 1.2, \"Target\\n(denoising)\", ha='center', fontsize=9, color='blue')\n",
    "\n",
    "# Bottom row: attention pattern\n",
    "ax = axes[1, 0]\n",
    "ax.text(0.5, 0.5, \"Self-Attention Pattern\", ha='center', va='center', fontsize=12, fontweight='bold', transform=ax.transAxes)\n",
    "ax.axis('off')\n",
    "\n",
    "ax = axes[1, 1]\n",
    "# Show attention matrix\n",
    "attn = np.zeros((6, 6))\n",
    "attn[:3, :3] = 0.3  # Source attends to source\n",
    "attn[3:, :3] = 0.8  # Target attends to source (key!)\n",
    "attn[3:, 3:] = 0.5  # Target attends to target\n",
    "ax.imshow(attn, cmap='Blues', vmin=0, vmax=1)\n",
    "ax.set_xticks(range(6))\n",
    "ax.set_xticklabels(['The', 'cat', 'sat', 'Le', 'chat', 'assis'], fontsize=8)\n",
    "ax.set_yticks(range(6))\n",
    "ax.set_yticklabels(['The', 'cat', 'sat', 'Le', 'chat', 'assis'], fontsize=8)\n",
    "ax.set_title(\"Attention weights\", fontsize=10)\n",
    "ax.set_xlabel(\"Keys (what we attend TO)\")\n",
    "ax.set_ylabel(\"Queries (who is attending)\")\n",
    "\n",
    "ax = axes[1, 2]\n",
    "ax.text(0.5, 0.7, \"Key Insight:\", ha='center', fontsize=11, fontweight='bold', transform=ax.transAxes)\n",
    "ax.text(0.5, 0.45, \"Target tokens attend to\\nsource tokens even when\\ntarget is fully masked!\", ha='center', fontsize=10, transform=ax.transAxes)\n",
    "ax.axis('off')\n",
    "\n",
    "ax = axes[1, 3]\n",
    "ax.text(0.5, 0.8, \"Advantages:\", ha='center', fontsize=11, fontweight='bold', transform=ax.transAxes)\n",
    "ax.text(0.1, 0.55, \" Single unified model\", fontsize=10, transform=ax.transAxes)\n",
    "ax.text(0.1, 0.40, \" No encoder-decoder split\", fontsize=10, transform=ax.transAxes)\n",
    "ax.text(0.1, 0.25, \" Easy to implement\", fontsize=10, transform=ax.transAxes)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8368fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DiffuSeq conditioning concept (simplified)\n",
    "\n",
    "def diffuseq_forward(source_tokens, target_tokens, t, alpha_bar, mask_id):\n",
    "    \"\"\"\n",
    "    Only apply noise to target, keep source fixed.\n",
    "    \"\"\"\n",
    "    # Source stays clean\n",
    "    source_noisy = source_tokens.clone()\n",
    "    \n",
    "    # Target gets noised\n",
    "    target_noisy, mask = discrete_forward_diffusion(\n",
    "        target_tokens.unsqueeze(0), \n",
    "        torch.tensor([t]), \n",
    "        alpha_bar, \n",
    "        mask_id\n",
    "    )\n",
    "    \n",
    "    # Concatenate\n",
    "    combined = torch.cat([source_noisy.unsqueeze(0), target_noisy], dim=1)\n",
    "    return combined.squeeze(0)\n",
    "\n",
    "# Demo\n",
    "source = torch.tensor([word2id[\"the\"], word2id[\"cat\"], word2id[\"sat\"]])  # Source: \"the cat sat\"\n",
    "target = torch.tensor([word2id[\"on\"], word2id[\"the\"], word2id[\"mat\"]])    # Target: \"on the mat\"\n",
    "\n",
    "print(\"DiffuSeq-style conditioning:\\n\")\n",
    "print(f\"Source (clean): {' '.join([id2word[i.item()] for i in source])}\")\n",
    "print(f\"Target (clean): {' '.join([id2word[i.item()] for i in target])}\")\n",
    "print()\n",
    "\n",
    "for t in [0, 50, 99]:\n",
    "    combined = diffuseq_forward(source, target, t, alpha_bar_discrete, MASK_ID)\n",
    "    src_part = ' '.join([id2word[i.item()] for i in combined[:3]])\n",
    "    tgt_part = ' '.join([id2word[i.item()] for i in combined[3:]])\n",
    "    print(f\"t={t:2d}: [{src_part}] | [{tgt_part}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a002261b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### MMDiT: Modern Transformer Diffusion (Deep Dive)\n",
    "\n",
    "**Architecture**: Multimodal Diffusion Transformer (MMDiT) - the architecture behind Stable Diffusion 3\n",
    "\n",
    "#### The Evolution: How MMDiT Builds on Previous Work\n",
    "\n",
    "| Model | Year | Key Innovation | Limitation Solved |\n",
    "|-------|------|----------------|-------------------|\n",
    "| **Diffusion-LM** | 2022 | Embedding-space diffusion | Discretecontinuous |\n",
    "| **DiffuSeq** | 2023 | Partial noising for conditioning | Seq2seq tasks |\n",
    "| **MMDiT** | 2024 | Pure transformer, AdaLN, latent space | Scalability, multimodal |\n",
    "\n",
    "#### Why MMDiT is the Future\n",
    "\n",
    "**1. Transformers Replace UNets**\n",
    "- UNets were designed for images (locality bias)\n",
    "- Transformers scale better and are more flexible\n",
    "- Same architecture works for text, images, audio, video\n",
    "\n",
    "**2. Latent Space Diffusion**\n",
    "- Don't diffuse raw tokens/pixels - too expensive\n",
    "- First compress to latent space (VAE/tokenizer)\n",
    "- Diffuse in compressed space\n",
    "- Decode final output\n",
    "\n",
    "**3. AdaLN: Elegant Timestep Conditioning**\n",
    "Instead of awkward timestep addition, modulate the LayerNorm:\n",
    "$$\\text{AdaLN}(x, t) = \\gamma(t) \\cdot \\text{LayerNorm}(x) + \\beta(t)$$\n",
    "\n",
    "**4. Classifier-Free Guidance (CFG)**\n",
    "- No separate classifier needed\n",
    "- Train with condition dropout\n",
    "- At inference: $\\epsilon = \\epsilon_{\\text{uncond}} + \\gamma(\\epsilon_{\\text{cond}} - \\epsilon_{\\text{uncond}})$\n",
    "\n",
    "<!-- \n",
    "IMAGE REQUEST: MMDiT architecture diagram\n",
    "URL: Stable Diffusion 3 paper or OpenMMDiT repo\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the evolution: Diffusion-LM  DiffuSeq  MMDiT\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Diffusion-LM\n",
    "ax = axes[0]\n",
    "ax.set_title(\"Diffusion-LM (2022)\", fontsize=12, fontweight='bold')\n",
    "boxes = [\n",
    "    (\"Tokens\", 0.1, 0.8, 'lightblue'),\n",
    "    (\"Learned\\nEmbeddings\", 0.1, 0.6, 'lightgreen'),\n",
    "    (\"Gaussian\\nDiffusion\", 0.1, 0.4, 'lightyellow'),\n",
    "    (\"Transformer\\nDenoiser\", 0.1, 0.2, 'lightcoral'),\n",
    "    (\"Round to\\nTokens\", 0.1, 0.0, 'lightblue'),\n",
    "]\n",
    "for label, x, y, color in boxes:\n",
    "    ax.add_patch(plt.Rectangle((x, y), 0.8, 0.15, color=color, ec='black'))\n",
    "    ax.text(0.5, y + 0.075, label, ha='center', va='center', fontsize=9)\n",
    "    if y > 0:\n",
    "        ax.annotate(\"\", xy=(0.5, y), xytext=(0.5, y + 0.02),\n",
    "                    arrowprops=dict(arrowstyle=\"->\", color='gray'))\n",
    "ax.text(0.5, -0.15, \"Unconditional\\n+ Classifier Guidance\", ha='center', fontsize=9, style='italic')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(-0.2, 1)\n",
    "ax.axis('off')\n",
    "\n",
    "# DiffuSeq\n",
    "ax = axes[1]\n",
    "ax.set_title(\"DiffuSeq (2023)\", fontsize=12, fontweight='bold')\n",
    "# Source + Target concatenation\n",
    "ax.add_patch(plt.Rectangle((0.05, 0.8), 0.4, 0.15, color='lightgreen', ec='green', lw=2))\n",
    "ax.text(0.25, 0.875, \"Source\", ha='center', va='center', fontsize=9)\n",
    "ax.add_patch(plt.Rectangle((0.55, 0.8), 0.4, 0.15, color='lightblue', ec='blue', lw=2))\n",
    "ax.text(0.75, 0.875, \"Target\", ha='center', va='center', fontsize=9)\n",
    "ax.add_patch(plt.Rectangle((0.1, 0.5), 0.8, 0.2, color='lightyellow', ec='black'))\n",
    "ax.text(0.5, 0.6, \"Partial Noising\\n(only target)\", ha='center', va='center', fontsize=9)\n",
    "ax.add_patch(plt.Rectangle((0.1, 0.2), 0.8, 0.2, color='lightcoral', ec='black'))\n",
    "ax.text(0.5, 0.3, \"Transformer\\n(bidirectional)\", ha='center', va='center', fontsize=9)\n",
    "ax.annotate(\"\", xy=(0.5, 0.5), xytext=(0.5, 0.75), arrowprops=dict(arrowstyle=\"->\", color='gray'))\n",
    "ax.annotate(\"\", xy=(0.5, 0.2), xytext=(0.5, 0.45), arrowprops=dict(arrowstyle=\"->\", color='gray'))\n",
    "ax.text(0.5, -0.05, \"Conditional\\n(seq2seq tasks)\", ha='center', fontsize=9, style='italic')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(-0.2, 1)\n",
    "ax.axis('off')\n",
    "\n",
    "# MMDiT\n",
    "ax = axes[2]\n",
    "ax.set_title(\"MMDiT (2024)\", fontsize=12, fontweight='bold')\n",
    "ax.add_patch(plt.Rectangle((0.1, 0.75), 0.35, 0.15, color='lightblue', ec='blue'))\n",
    "ax.text(0.275, 0.825, \"Noisy\\nLatent\", ha='center', va='center', fontsize=8)\n",
    "ax.add_patch(plt.Rectangle((0.55, 0.75), 0.35, 0.15, color='lightgreen', ec='green'))\n",
    "ax.text(0.725, 0.825, \"Condition\\nLatent\", ha='center', va='center', fontsize=8)\n",
    "# DiT blocks\n",
    "for i, y in enumerate([0.55, 0.35, 0.15]):\n",
    "    ax.add_patch(plt.Rectangle((0.1, y), 0.8, 0.12, color='lightcoral', ec='black'))\n",
    "    ax.text(0.5, y + 0.06, f\"DiT Block (AdaLN + Attn)\", ha='center', va='center', fontsize=8)\n",
    "ax.add_patch(plt.Rectangle((0.1, -0.05), 0.8, 0.12, color='lightyellow', ec='black'))\n",
    "ax.text(0.5, 0.01, \"Output Projection\", ha='center', va='center', fontsize=8)\n",
    "ax.text(0.92, 0.4, \"+t\", fontsize=10, color='purple', fontweight='bold')\n",
    "ax.annotate(\"\", xy=(0.5, 0.55), xytext=(0.5, 0.7), arrowprops=dict(arrowstyle=\"->\", color='gray'))\n",
    "ax.text(0.5, -0.18, \"Multimodal + Scalable\\n(SOTA)\", ha='center', fontsize=9, style='italic')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(-0.25, 1)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Evolution: simpler  more general  more scalable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f93b7",
   "metadata": {},
   "source": [
    "#### AdaLN: Why Modulate Instead of Add?\n",
    "\n",
    "**The Old Way (Diffusion-LM style)**:\n",
    "```python\n",
    "h = h + timestep_embedding  # Add timestep to hidden states\n",
    "```\n",
    "Problem: timestep just gets \"mixed in\" - network must learn to disentangle\n",
    "\n",
    "**The New Way (AdaLN)**:\n",
    "```python\n",
    "h = LayerNorm(h) * (1 + scale(t)) + shift(t)  # MODULATE the normalization\n",
    "```\n",
    "\n",
    "**Why is modulation better?**\n",
    "\n",
    "Think of LayerNorm as \"resetting\" the scale of activations. AdaLN says:\n",
    "- \"At timestep $t$, activations should be scaled by $\\gamma(t)$\"\n",
    "- \"At timestep $t$, activations should be shifted by $\\beta(t)$\"\n",
    "\n",
    "It's like telling each layer \"how much to react\" based on the noise level.\n",
    "\n",
    "**Intuition**: At high noise ($t$ large), you want big, coarse changes. At low noise ($t$ small), you want fine, subtle changes. AdaLN can express this naturally through scale!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0afbed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class AdaLN(nn.Module):\n",
    "    \"\"\"\n",
    "    Adaptive Layer Normalization - the key timestep conditioning mechanism in modern diffusion.\n",
    "    \n",
    "    Instead of adding timestep embedding, we use it to modulate the LayerNorm:\n",
    "    output = (x - mean) / std * (1 + scale) + shift\n",
    "    \n",
    "    where scale and shift come from the timestep embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, time_dim):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model, elementwise_affine=False)\n",
    "        self.modulation = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim, 2 * d_model)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, time_emb):\n",
    "        \"\"\"\n",
    "        x: [batch, seq_len, d_model]\n",
    "        time_emb: [batch, time_dim]\n",
    "        \"\"\"\n",
    "        # Get scale and shift from time embedding\n",
    "        scale_shift = self.modulation(time_emb)  # [batch, 2*d_model]\n",
    "        scale, shift = scale_shift.chunk(2, dim=-1)\n",
    "        \n",
    "        # Normalize then modulate\n",
    "        x = self.norm(x)\n",
    "        x = x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "# Demo\n",
    "adaln = AdaLN(d_model=64, time_dim=64)\n",
    "x = torch.randn(2, 10, 64)  # [batch=2, seq_len=10, d_model=64]\n",
    "t_emb = torch.randn(2, 64)  # [batch=2, time_dim=64]\n",
    "out = adaln(x, t_emb)\n",
    "print(f\"AdaLN: input {x.shape}  output {out.shape}\")\n",
    "print(\"Timestep modulates the normalization scale and shift!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb08749",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Building a SOTA-Shaped Text Diffusion Model\n",
    "\n",
    "Now let's build a proper, scalable text diffusion model. We'll:\n",
    "\n",
    "1. Use discrete diffusion (more practical for text)\n",
    "2. Implement AdaLN for timestep conditioning\n",
    "3. Add self-conditioning (a key trick)\n",
    "4. Design for ~100-200M parameters\n",
    "5. Train on a real dataset\n",
    "\n",
    "### Architecture Design\n",
    "\n",
    "Target specs for training on 2x T4 GPUs:\n",
    "- **d_model**: 768\n",
    "- **n_heads**: 12  \n",
    "- **n_layers**: 12\n",
    "- **vocab_size**: ~30K (using a pretrained tokenizer)\n",
    "- **max_seq_len**: 256\n",
    "- **Parameters**: ~125M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470afedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class DiTBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Diffusion Transformer block with AdaLN conditioning.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 4, d_model),\n",
    "        )\n",
    "        self.adaln1 = AdaLN(d_model, d_model)\n",
    "        self.adaln2 = AdaLN(d_model, d_model)\n",
    "        \n",
    "    def forward(self, x, t_emb):\n",
    "        # Pre-norm with AdaLN\n",
    "        x_norm = self.adaln1(x, t_emb)\n",
    "        x = x + self.attn(x_norm, x_norm, x_norm, need_weights=False)[0]\n",
    "        \n",
    "        x_norm = self.adaln2(x, t_emb)\n",
    "        x = x + self.mlp(x_norm)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d8de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class TextDiT(nn.Module):\n",
    "    \"\"\"\n",
    "    Text Diffusion Transformer - a SOTA-shaped discrete text diffusion model.\n",
    "    \n",
    "    Features:\n",
    "    - Discrete diffusion (mask-based)\n",
    "    - AdaLN timestep conditioning\n",
    "    - Self-conditioning (optional)\n",
    "    - Bidirectional attention (can see all positions)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        d_model=768,\n",
    "        n_heads=12,\n",
    "        n_layers=12,\n",
    "        max_seq_len=256,\n",
    "        dropout=0.0,\n",
    "        self_condition=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.self_condition = self_condition\n",
    "        \n",
    "        # Token embedding\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
    "        \n",
    "        # Position embedding\n",
    "        self.pos_emb = nn.Embedding(max_seq_len, d_model)\n",
    "        \n",
    "        # Timestep embedding\n",
    "        self.time_emb = nn.Sequential(\n",
    "            SinusoidalPosEmb(d_model),\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 4, d_model),\n",
    "        )\n",
    "        \n",
    "        # Self-conditioning: embed previous prediction\n",
    "        if self_condition:\n",
    "            self.self_cond_proj = nn.Linear(vocab_size, d_model)\n",
    "        \n",
    "        # Transformer blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            DiTBlock(d_model, n_heads, dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        # Final norm and output\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "        # Initialize output projection to small values\n",
    "        nn.init.zeros_(self.output_proj.weight)\n",
    "        nn.init.zeros_(self.output_proj.bias)\n",
    "        \n",
    "    def forward(self, x, t, self_cond=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Token ids [batch, seq_len]\n",
    "            t: Timesteps [batch]\n",
    "            self_cond: Previous logits prediction [batch, seq_len, vocab_size] (optional)\n",
    "        Returns:\n",
    "            logits: [batch, seq_len, vocab_size]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.shape\n",
    "        device = x.device\n",
    "        \n",
    "        # Embeddings\n",
    "        positions = torch.arange(seq_len, device=device)\n",
    "        h = self.token_emb(x) + self.pos_emb(positions)\n",
    "        \n",
    "        # Add self-conditioning if provided\n",
    "        if self.self_condition and self_cond is not None:\n",
    "            h = h + self.self_cond_proj(self_cond)\n",
    "        \n",
    "        # Timestep embedding\n",
    "        t_emb = self.time_emb(t.float())\n",
    "        \n",
    "        # Transformer blocks\n",
    "        for block in self.blocks:\n",
    "            h = block(h, t_emb)\n",
    "        \n",
    "        # Output\n",
    "        h = self.final_norm(h)\n",
    "        logits = self.output_proj(h)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SOTA-shaped model and check parameter count\n",
    "# We'll use a tokenizer from transformers for real vocab\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "real_vocab_size = len(tokenizer)\n",
    "\n",
    "# Create model at target scale\n",
    "sota_model = TextDiT(\n",
    "    vocab_size=real_vocab_size,\n",
    "    d_model=768,\n",
    "    n_heads=12,\n",
    "    n_layers=12,\n",
    "    max_seq_len=256,\n",
    "    self_condition=True,\n",
    ")\n",
    "\n",
    "n_params = sum(p.numel() for p in sota_model.parameters())\n",
    "print(f\"Vocabulary size: {real_vocab_size:,}\")\n",
    "print(f\"Model parameters: {n_params:,}\")\n",
    "print(f\"Model size: ~{n_params / 1e6:.1f}M parameters\")\n",
    "print()\n",
    "\n",
    "# Breakdown by component\n",
    "print(\"Parameter breakdown:\")\n",
    "for name, module in sota_model.named_children():\n",
    "    params = sum(p.numel() for p in module.parameters())\n",
    "    print(f\"  {name}: {params:,} ({params/n_params*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78e710d",
   "metadata": {},
   "source": [
    "### Dataset: TinyStories\n",
    "\n",
    "For training, we'll use **TinyStories** - a dataset of simple stories generated by GPT-3.5/4, designed for training small language models.\n",
    "\n",
    "**Why TinyStories?**\n",
    "- Clean, coherent text\n",
    "- Simple patterns that small models can learn\n",
    "- Manageable size for quick experiments\n",
    "- Good for seeing if diffusion can generate coherent text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fc1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TinyStories dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load a subset for faster experimentation\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train[:50000]\")\n",
    "print(f\"Dataset size: {len(dataset):,} stories\")\n",
    "print()\n",
    "\n",
    "# Preview a sample\n",
    "print(\"Sample story:\")\n",
    "print(\"-\" * 40)\n",
    "print(dataset[0][\"text\"][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991bfd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize dataset\n",
    "MAX_LEN = 128  # Shorter for faster training\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize and truncate/pad\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# Process in batches\n",
    "tokenized = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing\"\n",
    ")\n",
    "\n",
    "print(f\"Tokenized {len(tokenized):,} examples\")\n",
    "print(f\"Each example: {MAX_LEN} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized,\n",
    "    batch_size=32,  # Adjust based on GPU memory\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# Test batch\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Batch shape: {batch['input_ids'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892da860",
   "metadata": {},
   "source": [
    "### Training with Weights & Biases\n",
    "\n",
    "We'll use WandB to log:\n",
    "- Loss curves (overall and by timestep)\n",
    "- Sample generations during training\n",
    "- Gradient norms\n",
    "- Learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ea604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize WandB\n",
    "wandb.init(\n",
    "    project=\"text-diffusion\",\n",
    "    config={\n",
    "        \"d_model\": 768,\n",
    "        \"n_heads\": 12,\n",
    "        \"n_layers\": 12,\n",
    "        \"max_seq_len\": MAX_LEN,\n",
    "        \"batch_size\": 32,\n",
    "        \"lr\": 1e-4,\n",
    "        \"num_steps\": 1000,\n",
    "        \"dataset\": \"tinystories\",\n",
    "        \"self_condition\": True,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238803d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def train_step(model, batch, optimizer, num_steps, alpha_bar, mask_token_id, device, self_cond_prob=0.5):\n",
    "    \"\"\"\n",
    "    Single training step with self-conditioning.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    x_0 = batch[\"input_ids\"].to(device)\n",
    "    batch_size = x_0.shape[0]\n",
    "    \n",
    "    # Sample random timesteps\n",
    "    t = torch.randint(0, num_steps, (batch_size,), device=device)\n",
    "    \n",
    "    # Forward diffusion\n",
    "    x_t, mask = discrete_forward_diffusion(x_0, t, alpha_bar.to(device), mask_token_id)\n",
    "    \n",
    "    # Self-conditioning: 50% of time, use previous prediction\n",
    "    self_cond = None\n",
    "    if model.self_condition and torch.rand(1).item() < self_cond_prob:\n",
    "        with torch.no_grad():\n",
    "            self_cond = model(x_t, t, self_cond=None)\n",
    "            self_cond = F.softmax(self_cond, dim=-1)\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = model(x_t, t, self_cond=self_cond)\n",
    "    \n",
    "    # Loss: cross-entropy on all positions\n",
    "    # (For simplicity we compute on all, but weight masked more)\n",
    "    loss = F.cross_entropy(\n",
    "        logits.view(-1, logits.size(-1)),\n",
    "        x_0.view(-1),\n",
    "        reduction='none'\n",
    "    )\n",
    "    \n",
    "    # Weight masked positions more heavily\n",
    "    mask_weight = mask.float() * 2.0 + 1.0  # masked: 3x, unmasked: 1x\n",
    "    loss = (loss.view(batch_size, -1) * mask_weight).mean()\n",
    "    \n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Gradient clipping\n",
    "    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item(), grad_norm.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883228c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for training\n",
    "# Use smaller model for demo (full model needs more GPU memory)\n",
    "demo_model = TextDiT(\n",
    "    vocab_size=real_vocab_size,\n",
    "    d_model=256,\n",
    "    n_heads=4,\n",
    "    n_layers=4,\n",
    "    max_seq_len=MAX_LEN,\n",
    "    self_condition=True,\n",
    ").to(device)\n",
    "\n",
    "demo_params = sum(p.numel() for p in demo_model.parameters())\n",
    "print(f\"Demo model: {demo_params:,} parameters (~{demo_params/1e6:.1f}M)\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(demo_model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "\n",
    "# Noise schedule\n",
    "NUM_TRAIN_STEPS = 1000\n",
    "train_alpha_bar = cosine_schedule(NUM_TRAIN_STEPS)\n",
    "\n",
    "# MASK token for GPT-2 tokenizer (we'll add one)\n",
    "MASK_TOKEN_ID = tokenizer.encode(\"[MASK]\", add_special_tokens=False)[0] if \"[MASK]\" in tokenizer.vocab else tokenizer.eos_token_id\n",
    "print(f\"Using MASK token ID: {MASK_TOKEN_ID}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "NUM_EPOCHS = 2  # Increase for better results\n",
    "LOG_INTERVAL = 100\n",
    "SAMPLE_INTERVAL = 500\n",
    "\n",
    "global_step = 0\n",
    "losses_list = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_losses = []\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    for batch in pbar:\n",
    "        loss, grad_norm = train_step(\n",
    "            demo_model, batch, optimizer, \n",
    "            NUM_TRAIN_STEPS, train_alpha_bar, \n",
    "            MASK_TOKEN_ID, device\n",
    "        )\n",
    "        \n",
    "        epoch_losses.append(loss)\n",
    "        losses_list.append(loss)\n",
    "        global_step += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\"loss\": f\"{loss:.4f}\", \"grad_norm\": f\"{grad_norm:.2f}\"})\n",
    "        \n",
    "        # Log to wandb\n",
    "        if global_step % LOG_INTERVAL == 0:\n",
    "            wandb.log({\n",
    "                \"loss\": loss,\n",
    "                \"grad_norm\": grad_norm,\n",
    "                \"epoch\": epoch,\n",
    "                \"step\": global_step,\n",
    "            })\n",
    "        \n",
    "        # Generate samples periodically\n",
    "        if global_step % SAMPLE_INTERVAL == 0:\n",
    "            demo_model.eval()\n",
    "            with torch.no_grad():\n",
    "                # Generate from all masks\n",
    "                gen_input = torch.full((1, MAX_LEN), MASK_TOKEN_ID, device=device)\n",
    "                gen_t = torch.tensor([NUM_TRAIN_STEPS-1], device=device)\n",
    "                gen_output = demo_model(gen_input, gen_t)\n",
    "                gen_tokens = gen_output.argmax(dim=-1)\n",
    "                gen_text = tokenizer.decode(gen_tokens[0], skip_special_tokens=True)\n",
    "                print(f\"\\n[Step {global_step}] Sample: {gen_text[:100]}...\")\n",
    "            demo_model.train()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} avg loss: {sum(epoch_losses)/len(epoch_losses):.4f}\")\n",
    "\n",
    "wandb.finish()\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf8293",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Production Diagnostics: What's Different from Transformers?\n",
    "\n",
    "When training text diffusion models, there are specific things to monitor that differ from standard transformers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8577c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Key Differences: Transformer vs Diffusion Training\n",
    "\n",
    "| Aspect | **Autoregressive Transformer** | **Diffusion Model** |\n",
    "|--------|-------------------------------|---------------------|\n",
    "| **Loss** | Single loss (next-token CE) | Loss varies by timestep! Early (high $t$) is easy, late (low $t$) is hard |\n",
    "| **What to monitor** | Overall loss curve | **Loss per timestep bucket** - crucial for debugging |\n",
    "| **Gradients** | Single objective | Mixed from different timesteps - some dominate |\n",
    "| **Gradient fix** | Standard clipping | Loss weighting or importance sampling by $t$ |\n",
    "| **Quality metrics** | Perplexity (well-defined) | No clean PPL - use BLEU, MAUVE, diversity |\n",
    "| **EMA** | Helps | **Almost required** for stable sampling |\n",
    "\n",
    "#### Why Timestep-Specific Monitoring Matters\n",
    "\n",
    "In diffusion:\n",
    "- **High $t$ (noisy)**: Easy to learn - just predict \"it's noise\"\n",
    "- **Low $t$ (clean)**: Hard - need to predict fine details\n",
    "- **If loss only drops at high $t$**: Model learned nothing useful!\n",
    "\n",
    "This is very different from transformers where a single loss tells the whole story.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e8139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def compute_loss_by_timestep(model, dataloader, num_steps, alpha_bar, mask_id, device, n_buckets=10):\n",
    "    \"\"\"\n",
    "    Compute loss broken down by timestep buckets.\n",
    "    Useful for understanding where the model struggles.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    bucket_size = num_steps // n_buckets\n",
    "    bucket_losses = [[] for _ in range(n_buckets)]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x_0 = batch[\"input_ids\"].to(device)\n",
    "            \n",
    "            # Test each bucket\n",
    "            for bucket_idx in range(n_buckets):\n",
    "                t_low = bucket_idx * bucket_size\n",
    "                t_high = (bucket_idx + 1) * bucket_size\n",
    "                t = torch.randint(t_low, t_high, (x_0.shape[0],), device=device)\n",
    "                \n",
    "                x_t, mask = discrete_forward_diffusion(x_0, t, alpha_bar.to(device), mask_id)\n",
    "                logits = model(x_t, t)\n",
    "                \n",
    "                loss = F.cross_entropy(\n",
    "                    logits.view(-1, logits.size(-1)),\n",
    "                    x_0.view(-1)\n",
    "                )\n",
    "                bucket_losses[bucket_idx].append(loss.item())\n",
    "    \n",
    "    return [sum(b)/len(b) if b else 0 for b in bucket_losses]\n",
    "\n",
    "# Demo: analyze loss by timestep (using small sample)\n",
    "small_loader = DataLoader(tokenized.select(range(100)), batch_size=10)\n",
    "bucket_losses = compute_loss_by_timestep(\n",
    "    demo_model, small_loader, NUM_TRAIN_STEPS, \n",
    "    train_alpha_bar, MASK_TOKEN_ID, device, n_buckets=10\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(10), bucket_losses)\n",
    "plt.xlabel(\"Timestep bucket (0=clean, 9=noisy)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss by Timestep: Where Does the Model Struggle?\")\n",
    "plt.xticks(range(10), [f\"{i*100}-{(i+1)*100}\" for i in range(10)])\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Higher loss at low timesteps = model struggles with fine details\")\n",
    "print(\"Higher loss at high timesteps = model struggles with global structure\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bcce19",
   "metadata": {},
   "source": [
    "### Diffusion-Specific Tricks\n",
    "\n",
    "These are techniques that are unique or especially important for diffusion models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75920090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class EMAModel:\n",
    "    \"\"\"\n",
    "    Exponential Moving Average of model weights.\n",
    "    Critical for stable diffusion sampling.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, decay=0.9999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "    \n",
    "    def update(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = (\n",
    "                    self.decay * self.shadow[name] + \n",
    "                    (1 - self.decay) * param.data\n",
    "                )\n",
    "    \n",
    "    def apply(self, model):\n",
    "        \"\"\"Apply EMA weights to model (for sampling).\"\"\"\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data.copy_(self.shadow[name])\n",
    "\n",
    "print(\"1. EMA (Exponential Moving Average)\")\n",
    "print(\"   - Keeps smoothed version of weights\")\n",
    "print(\"   - Use EMA weights for sampling, not training weights\")\n",
    "print(\"   - Decay typically 0.9999\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07845bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2. SELF-CONDITIONING\")\n",
    "print(\"   - Feed previous prediction back as input\")\n",
    "print(\"   - During training: 50% use self-cond, 50% don't\")\n",
    "print(\"   - During sampling: always use self-cond\")\n",
    "print(\"   - Improves sample quality significantly\")\n",
    "print()\n",
    "\n",
    "print(\"3. NOISE SCHEDULE TUNING\")\n",
    "print(\"   - Cosine schedule > linear schedule\")\n",
    "print(\"   - May need to adjust for text vs images\")\n",
    "print(\"   - More aggressive schedule for shorter sequences\")\n",
    "print()\n",
    "\n",
    "print(\"4. CLASSIFIER-FREE GUIDANCE\")\n",
    "print(\"   - Drop conditioning during training with some probability\")\n",
    "print(\"   - At inference, interpolate between conditional and unconditional\")\n",
    "print(\"   - Controls diversity vs fidelity tradeoff\")\n",
    "print()\n",
    "\n",
    "print(\"5. TIMESTEP IMPORTANCE SAMPLING\")\n",
    "print(\"   - Some timesteps are more informative\")\n",
    "print(\"   - Sample harder timesteps more often\")\n",
    "print(\"   - Or use loss-weighted sampling\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92830b50",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: What We've Learned\n",
    "\n",
    "### The Core Idea\n",
    "Diffusion = **iteratively refine from noise to data**. For text:\n",
    "- Either diffuse in embedding space (Diffusion-LM style)\n",
    "- Or use discrete masking (modern MDLM/SEDD style)\n",
    "\n",
    "### The Key Components\n",
    "1. **Forward process**: Corrupt data with noise/masks\n",
    "2. **Denoising network**: Predict clean data from noisy\n",
    "3. **Noise schedule**: Control corruption rate (cosine works well)\n",
    "4. **Reverse process**: Iteratively denoise to generate\n",
    "\n",
    "### Evolution of Text Diffusion\n",
    "1. **Diffusion-LM** (2022): Continuous embeddings, classifier guidance\n",
    "2. **DiffuSeq** (2023): Seq2seq conditioning\n",
    "3. **MDLM/SEDD** (2024): Discrete diffusion, better discrete math\n",
    "4. **MMDiT** (2024+): Transformer-native diffusion\n",
    "\n",
    "### When to Use Text Diffusion vs Autoregressive\n",
    "| Use Case | Best Approach |\n",
    "|----------|--------------|\n",
    "| General text generation | Autoregressive (GPT) |\n",
    "| Controllable generation | Diffusion (guidance) |\n",
    "| Infilling / editing | Diffusion |\n",
    "| Speed-critical | Autoregressive |\n",
    "| Parallel generation | Diffusion |\n",
    "\n",
    "### Resources for Further Learning\n",
    "- **Papers**: \"Diffusion-LM\", \"MDLM\", \"Score Entropy Discrete Diffusion\"\n",
    "- **Repos**: [Diffusion-LM](https://github.com/XiangLi1999/Diffusion-LM), [DiffuSeq](https://github.com/Shark-NLP/DiffuSeq)\n",
    "- **Active area**: Watch for new discrete diffusion methods!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117aaccd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbf54d56",
   "metadata": {},
   "source": [
    "## The Text Problem: Discrete vs Continuous\n",
    "\n",
    "Here's the fundamental challenge: **text is discrete**.\n",
    "\n",
    "In images, a pixel can smoothly transition: `[0.5, 0.5, 0.5]`  `[0.51, 0.49, 0.52]`\n",
    "\n",
    "In text, tokens are integers: \"cat\" is token `3784`. What's `3784 + 0.3`?\n",
    "vide way s and "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2bc37",
   "metadata": {},
   "source": [
    "## The Text Problem: Discrete vs Continuous\n",
    "\n",
    "Here's the fundamental challenge: **text is discrete**.\n",
    "\n",
    "In images, a pixel can smoothly transition: `[0.5, 0.5, 0.5]`  `[0.51, 0.49, 0.52]`\n",
    "\n",
    "In text, tokens are integers: \"cat\" is token `3784`. What's `3784 + 0.3`?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
