{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e699b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import torch\n",
    "from torch import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caff4685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "einsum(equation, *operands) -> Tensor\n",
      "\n",
      "Sums the product of the elements of the input :attr:`operands` along dimensions specified using a notation\n",
      "based on the Einstein summation convention.\n",
      "\n",
      "Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\n",
      "in a short-hand format based on the Einstein summation convention, given by :attr:`equation`. The details of\n",
      "this format are described below, but the general idea is to label every dimension of the input :attr:`operands`\n",
      "with some subscript and define which subscripts are part of the output. The output is then computed by summing\n",
      "the product of the elements of the :attr:`operands` along the dimensions whose subscripts are not part of the\n",
      "output. For example, matrix multiplication can be computed using einsum as `torch.einsum(\"ij,jk->ik\", A, B)`.\n",
      "Here, j is the summation subscript and i and k the output subscripts (see section below for more details on why).\n",
      "\n",
      "Equation:\n",
      "\n",
      "    The :attr:`equation` string specifies the subscripts (letters in `[a-zA-Z]`) for each dimension of\n",
      "    the input :attr:`operands` in the same order as the dimensions, separating subscripts for each operand by a\n",
      "    comma (','), e.g. `'ij,jk'` specify subscripts for two 2D operands. The dimensions labeled with the same subscript\n",
      "    must be broadcastable, that is, their size must either match or be `1`. The exception is if a subscript is\n",
      "    repeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\n",
      "    must match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\n",
      "    appear exactly once in the :attr:`equation` will be part of the output, sorted in increasing alphabetical order.\n",
      "    The output is computed by multiplying the input :attr:`operands` element-wise, with their dimensions aligned based\n",
      "    on the subscripts, and then summing out the dimensions whose subscripts are not part of the output.\n",
      "\n",
      "    Optionally, the output subscripts can be explicitly defined by adding an arrow ('->') at the end of the equation\n",
      "    followed by the subscripts for the output. For instance, the following equation computes the transpose of a\n",
      "    matrix multiplication: 'ij,jk->ki'. The output subscripts must appear at least once for some input operand and\n",
      "    at most once for the output.\n",
      "\n",
      "    Ellipsis ('...') can be used in place of subscripts to broadcast the dimensions covered by the ellipsis.\n",
      "    Each input operand may contain at most one ellipsis which will cover the dimensions not covered by subscripts,\n",
      "    e.g. for an input operand with 5 dimensions, the ellipsis in the equation `'ab...c'` cover the third and fourth\n",
      "    dimensions. The ellipsis does not need to cover the same number of dimensions across the :attr:`operands` but the\n",
      "    'shape' of the ellipsis (the size of the dimensions covered by them) must broadcast together. If the output is not\n",
      "    explicitly defined with the arrow ('->') notation, the ellipsis will come first in the output (left-most dimensions),\n",
      "    before the subscript labels that appear exactly once for the input operands. e.g. the following equation implements\n",
      "    batch matrix multiplication `'...ij,...jk'`.\n",
      "\n",
      "    A few final notes: the equation may contain whitespaces between the different elements (subscripts, ellipsis,\n",
      "    arrow and comma) but something like `'. . .'` is not valid. An empty string `''` is valid for scalar operands.\n",
      "\n",
      ".. note::\n",
      "\n",
      "    ``torch.einsum`` handles ellipsis ('...') differently from NumPy in that it allows dimensions\n",
      "    covered by the ellipsis to be summed over, that is, ellipsis are not required to be part of the output.\n",
      "\n",
      ".. note::\n",
      "\n",
      "    Please install opt-einsum (https://optimized-einsum.readthedocs.io/en/stable/) in order to enroll into a more\n",
      "    performant einsum. You can install when installing torch like so: `pip install torch[opt-einsum]` or by itself\n",
      "    with `pip install opt-einsum`.\n",
      "\n",
      "    If opt-einsum is available, this function will automatically speed up computation and/or consume less memory\n",
      "    by optimizing contraction order through our opt_einsum backend :mod:`torch.backends.opt_einsum` (The _ vs - is\n",
      "    confusing, I know). This optimization occurs when there are at least three inputs, since the order does not matter\n",
      "    otherwise. Note that finding `the` optimal path is an NP-hard problem, thus, opt-einsum relies on different\n",
      "    heuristics to achieve near-optimal results. If opt-einsum is not available, the default order is to contract\n",
      "    from left to right.\n",
      "\n",
      "    To bypass this default behavior, add the following to disable opt_einsum and skip path calculation:\n",
      "    ``torch.backends.opt_einsum.enabled = False``\n",
      "\n",
      "    To specify which strategy you'd like for opt_einsum to compute the contraction path, add the following line:\n",
      "    ``torch.backends.opt_einsum.strategy = 'auto'``. The default strategy is 'auto', and we also support 'greedy' and\n",
      "    'optimal'. Disclaimer that the runtime of 'optimal' is factorial in the number of inputs! See more details in\n",
      "    the opt_einsum documentation (https://optimized-einsum.readthedocs.io/en/stable/path_finding.html).\n",
      "\n",
      ".. note::\n",
      "\n",
      "    As of PyTorch 1.10 :func:`torch.einsum` also supports the sublist format (see examples below). In this format,\n",
      "    subscripts for each operand are specified by sublists, list of integers in the range [0, 52). These sublists\n",
      "    follow their operands, and an extra sublist can appear at the end of the input to specify the output's\n",
      "    subscripts., e.g. `torch.einsum(op1, sublist1, op2, sublist2, ..., [subslist_out])`. Python's `Ellipsis` object\n",
      "    may be provided in a sublist to enable broadcasting as described in the Equation section above.\n",
      "\n",
      "Args:\n",
      "    equation (str): The subscripts for the Einstein summation.\n",
      "    operands (List[Tensor]): The tensors to compute the Einstein summation of.\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      "    >>> # trace\n",
      "    >>> torch.einsum('ii', torch.randn(4, 4))\n",
      "    tensor(-1.2104)\n",
      "\n",
      "    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      "    >>> # diagonal\n",
      "    >>> torch.einsum('ii->i', torch.randn(4, 4))\n",
      "    tensor([-0.1034,  0.7952, -0.2433,  0.4545])\n",
      "\n",
      "    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      "    >>> # outer product\n",
      "    >>> x = torch.randn(5)\n",
      "    >>> y = torch.randn(4)\n",
      "    >>> torch.einsum('i,j->ij', x, y)\n",
      "    tensor([[ 0.1156, -0.2897, -0.3918,  0.4963],\n",
      "            [-0.3744,  0.9381,  1.2685, -1.6070],\n",
      "            [ 0.7208, -1.8058, -2.4419,  3.0936],\n",
      "            [ 0.1713, -0.4291, -0.5802,  0.7350],\n",
      "            [ 0.5704, -1.4290, -1.9323,  2.4480]])\n",
      "\n",
      "    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      "    >>> # batch matrix multiplication\n",
      "    >>> As = torch.randn(3, 2, 5)\n",
      "    >>> Bs = torch.randn(3, 5, 4)\n",
      "    >>> torch.einsum('bij,bjk->bik', As, Bs)\n",
      "    tensor([[[-1.0564, -1.5904,  3.2023,  3.1271],\n",
      "            [-1.6706, -0.8097, -0.8025, -2.1183]],\n",
      "\n",
      "            [[ 4.2239,  0.3107, -0.5756, -0.2354],\n",
      "            [-1.4558, -0.3460,  1.5087, -0.8530]],\n",
      "\n",
      "            [[ 2.8153,  1.8787, -4.3839, -1.2112],\n",
      "            [ 0.3728, -2.1131,  0.0921,  0.8305]]])\n",
      "\n",
      "    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      "    >>> # with sublist format and ellipsis\n",
      "    >>> torch.einsum(As, [..., 0, 1], Bs, [..., 1, 2], [..., 0, 2])\n",
      "    tensor([[[-1.0564, -1.5904,  3.2023,  3.1271],\n",
      "            [-1.6706, -0.8097, -0.8025, -2.1183]],\n",
      "\n",
      "            [[ 4.2239,  0.3107, -0.5756, -0.2354],\n",
      "            [-1.4558, -0.3460,  1.5087, -0.8530]],\n",
      "\n",
      "            [[ 2.8153,  1.8787, -4.3839, -1.2112],\n",
      "            [ 0.3728, -2.1131,  0.0921,  0.8305]]])\n",
      "\n",
      "    >>> # batch permute\n",
      "    >>> A = torch.randn(2, 3, 4, 5)\n",
      "    >>> torch.einsum('...ij->...ji', A).shape\n",
      "    torch.Size([2, 3, 5, 4])\n",
      "\n",
      "    >>> # equivalent to torch.nn.functional.bilinear\n",
      "    >>> A = torch.randn(3, 5, 4)\n",
      "    >>> l = torch.randn(2, 5)\n",
      "    >>> r = torch.randn(2, 4)\n",
      "    >>> torch.einsum('bn,anm,bm->ba', l, A, r)\n",
      "    tensor([[-0.3430, -5.2405,  0.4494],\n",
      "            [ 0.3311,  5.5201, -3.0356]])\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.11/site-packages/torch/functional.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "einsum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e524da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpattern\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "einops.rearrange is a reader-friendly smart element reordering for multidimensional tensors.\n",
      "This operation includes functionality of transpose (axes permutation), reshape (view), squeeze, unsqueeze,\n",
      "stack, concatenate and other operations.\n",
      "\n",
      "Examples:\n",
      "\n",
      "```python\n",
      "# suppose we have a set of 32 images in \"h w c\" format (height-width-channel)\n",
      ">>> images = [np.random.randn(30, 40, 3) for _ in range(32)]\n",
      "\n",
      "# stack along first (batch) axis, output is a single array\n",
      ">>> rearrange(images, 'b h w c -> b h w c').shape\n",
      "(32, 30, 40, 3)\n",
      "\n",
      "# stacked and reordered axes to \"b c h w\" format\n",
      ">>> rearrange(images, 'b h w c -> b c h w').shape\n",
      "(32, 3, 30, 40)\n",
      "\n",
      "# concatenate images along height (vertical axis), 960 = 32 * 30\n",
      ">>> rearrange(images, 'b h w c -> (b h) w c').shape\n",
      "(960, 40, 3)\n",
      "\n",
      "# concatenated images along horizontal axis, 1280 = 32 * 40\n",
      ">>> rearrange(images, 'b h w c -> h (b w) c').shape\n",
      "(30, 1280, 3)\n",
      "\n",
      "# flattened each image into a vector, 3600 = 30 * 40 * 3\n",
      ">>> rearrange(images, 'b h w c -> b (c h w)').shape\n",
      "(32, 3600)\n",
      "\n",
      "# split each image into 4 smaller (top-left, top-right, bottom-left, bottom-right), 128 = 32 * 2 * 2\n",
      ">>> rearrange(images, 'b (h1 h) (w1 w) c -> (b h1 w1) h w c', h1=2, w1=2).shape\n",
      "(128, 15, 20, 3)\n",
      "\n",
      "# space-to-depth operation\n",
      ">>> rearrange(images, 'b (h h1) (w w1) c -> b h w (c h1 w1)', h1=2, w1=2).shape\n",
      "(32, 15, 20, 12)\n",
      "\n",
      "```\n",
      "\n",
      "When composing axes, C-order enumeration used (consecutive elements have different last axis).\n",
      "Find more examples in einops tutorial.\n",
      "\n",
      "Parameters:\n",
      "    tensor: tensor of any supported library (e.g. numpy.ndarray, tensorflow, pytorch).\n",
      "            list of tensors is also accepted, those should be of the same type and shape\n",
      "    pattern: string, rearrangement pattern\n",
      "    axes_lengths: any additional specifications for dimensions\n",
      "\n",
      "Returns:\n",
      "    tensor of the same type as input. If possible, a view to the original tensor is returned.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.11/site-packages/einops/einops.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "rearrange?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80981b19",
   "metadata": {},
   "source": [
    "# Einstein Operations: Making Tensor Math Readable\n",
    "\n",
    "Tensor operations are everywhere in deep learning. But writing them with standard PyTorch/NumPy can be confusing:\n",
    "\n",
    "```python\n",
    "# What does this do?\n",
    "result = torch.bmm(x.transpose(1, 2), y).sum(dim=-1)\n",
    "```\n",
    "\n",
    "This notebook builds intuition for **einsum** and **einops** — two tools that make tensor operations readable and less error-prone. We'll start from explicit loops and see how these tools emerge naturally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de9b4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10, 4)\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99cad4c",
   "metadata": {},
   "source": [
    "## Our Toy Example\n",
    "\n",
    "Let's create small matrices we can trace through by hand. This makes it easy to verify that our operations are doing what we think.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "871193cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A (2×3):\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Matrix B (3×2):\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# A simple 2x3 matrix\n",
    "A = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# A 3x2 matrix  \n",
    "B = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "print(\"Matrix A (2×3):\")\n",
    "print(A)\n",
    "print(\"\\nMatrix B (3×2):\")\n",
    "print(B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d087a2f",
   "metadata": {},
   "source": [
    "## The Problem: Loops Are Verbose and Error-Prone\n",
    "\n",
    "Let's implement some common operations with explicit loops to see the pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82e0a16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape (I, J): torch.Size([2, 3])\n",
      "B.shape (J2, K): torch.Size([3, 2])\n",
      "i: 0\n",
      "  k: 0\n",
      "    j: 0 A[i, j]: tensor(1.) B[j, k]: tensor(1.)\n",
      "    j: 1 A[i, j]: tensor(2.) B[j, k]: tensor(3.)\n",
      "    j: 2 A[i, j]: tensor(3.) B[j, k]: tensor(5.)\n",
      "  k: 1\n",
      "    j: 0 A[i, j]: tensor(1.) B[j, k]: tensor(2.)\n",
      "    j: 1 A[i, j]: tensor(2.) B[j, k]: tensor(4.)\n",
      "    j: 2 A[i, j]: tensor(3.) B[j, k]: tensor(6.)\n",
      "i: 1\n",
      "  k: 0\n",
      "    j: 0 A[i, j]: tensor(4.) B[j, k]: tensor(1.)\n",
      "    j: 1 A[i, j]: tensor(5.) B[j, k]: tensor(3.)\n",
      "    j: 2 A[i, j]: tensor(6.) B[j, k]: tensor(5.)\n",
      "  k: 1\n",
      "    j: 0 A[i, j]: tensor(4.) B[j, k]: tensor(2.)\n",
      "    j: 1 A[i, j]: tensor(5.) B[j, k]: tensor(4.)\n",
      "    j: 2 A[i, j]: tensor(6.) B[j, k]: tensor(6.)\n",
      "A @ B with loops:\n",
      "tensor([[22., 28.],\n",
      "        [49., 64.]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication with explicit loops\n",
    "# C[i,k] = sum over j of A[i,j] * B[j,k]\n",
    "\n",
    "def matmul_loops(A, B):\n",
    "    \"\"\"Matrix multiplication using explicit loops\"\"\"\n",
    "    I, J = A.shape\n",
    "    J2, K = B.shape\n",
    "    assert J == J2, \"Inner dimensions must match\"\n",
    "    \n",
    "    print(f\"A.shape (I, J): {A.shape}\")\n",
    "    print(f\"B.shape (J2, K): {B.shape}\")\n",
    "    \n",
    "    C = torch.zeros(I, K)\n",
    "    for i in range(I):\n",
    "        # import pdb; pdb.set_trace()\n",
    "        print(f\"i: {i}\")\n",
    "        for k in range(K):\n",
    "            print(f\"  k: {k}\")\n",
    "            for j in range(J):\n",
    "                print(f\"    j: {j}\", \"A[i, j]:\", A[i, j], \"B[j, k]:\", B[j, k])\n",
    "                C[i, k] += A[i, j] * B[j, k]\n",
    "    return C\n",
    "\n",
    "result_loops = matmul_loops(A, B)\n",
    "print(\"A @ B with loops:\")\n",
    "print(result_loops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d03cb7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A @ B with torch:\n",
      "tensor([[22., 28.],\n",
      "        [49., 64.]])\n",
      "\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# Verify: this matches torch's built-in\n",
    "result_torch = A @ B\n",
    "print(\"A @ B with torch:\")\n",
    "print(result_torch)\n",
    "print(f\"\\nMatch: {torch.allclose(result_loops, result_torch)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa557fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing C[0,0]:\n",
      "  A[0,:] = [1.0, 2.0, 3.0]\n",
      "  B[:,0] = [1.0, 3.0, 5.0]\n",
      "  A[0,0]*B[0,0] + A[0,1]*B[1,0] + A[0,2]*B[2,0]\n",
      "  = 1.0*1.0 + 2.0*3.0 + 3.0*5.0\n",
      "  = 1.0 + 6.0 + 15.0\n",
      "  = 22.0\n",
      "\n",
      "C[0,0] in result: 22.0\n"
     ]
    }
   ],
   "source": [
    "# Let's trace through one element to understand\n",
    "# C[0, 0] = A[0,0]*B[0,0] + A[0,1]*B[1,0] + A[0,2]*B[2,0]\n",
    "#         = 1*1 + 2*3 + 3*5 = 1 + 6 + 15 = 22\n",
    "\n",
    "print(\"Tracing C[0,0]:\")\n",
    "print(f\"  A[0,:] = {A[0,:].tolist()}\")\n",
    "print(f\"  B[:,0] = {B[:,0].tolist()}\")\n",
    "print(f\"  A[0,0]*B[0,0] + A[0,1]*B[1,0] + A[0,2]*B[2,0]\")\n",
    "print(f\"  = {A[0,0]}*{B[0,0]} + {A[0,1]}*{B[1,0]} + {A[0,2]}*{B[2,0]}\")\n",
    "print(f\"  = {A[0,0]*B[0,0]} + {A[0,1]*B[1,0]} + {A[0,2]*B[2,0]}\")\n",
    "print(f\"  = {A[0,0]*B[0,0] + A[0,1]*B[1,0] + A[0,2]*B[2,0]}\")\n",
    "print(f\"\\nC[0,0] in result: {result_torch[0,0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89abaa",
   "metadata": {},
   "source": [
    "## The Pattern: Indices and Summation\n",
    "\n",
    "Look at what we're doing in matrix multiplication:\n",
    "\n",
    "```\n",
    "C[i, k] = Σⱼ A[i, j] × B[j, k]\n",
    "```\n",
    "\n",
    "The pattern is:\n",
    "1. **Label each dimension** with a letter (i, j, k)\n",
    "2. **Multiply** corresponding elements\n",
    "3. **Sum** over indices that don't appear in the output (j disappears)\n",
    "\n",
    "This is exactly what **einsum** notation captures!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94da8688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A @ B with einsum('ij,jk->ik', A, B):\n",
      "tensor([[22., 28.],\n",
      "        [49., 64.]])\n",
      "\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# einsum: express the SAME operation in one line\n",
    "# \"ij,jk->ik\" means:\n",
    "#   - A has dimensions [i, j]\n",
    "#   - B has dimensions [j, k]  \n",
    "#   - Output has dimensions [i, k]\n",
    "#   - j appears in both inputs but not output → sum over j\n",
    "\n",
    "result_einsum = einsum('ij,jk->ik', A, B)\n",
    "print(\"A @ B with einsum('ij,jk->ik', A, B):\")\n",
    "print(result_einsum)\n",
    "print(f\"\\nMatch: {torch.allclose(result_einsum, result_torch)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54a487",
   "metadata": {},
   "source": [
    "**Reading einsum notation**: `'ij,jk->ik'`\n",
    "\n",
    "| Part | Meaning |\n",
    "|------|---------|\n",
    "| `ij` | First tensor has dimensions i (rows) and j (cols) |\n",
    "| `,` | Separator between tensors |\n",
    "| `jk` | Second tensor has dimensions j (rows) and k (cols) |\n",
    "| `->` | \"produces\" |\n",
    "| `ik` | Output has dimensions i and k |\n",
    "| (j missing from output) | Sum over j |\n",
    "\n",
    "The beauty: **the notation directly describes the math!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a3c81",
   "metadata": {},
   "source": [
    "## Building Up: Simple Operations First\n",
    "\n",
    "Let's see how simpler operations work in einsum, then build up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "844c0bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Sum all elements:\n",
      "  Loop: 21.0\n",
      "  torch.sum: 21.0\n",
      "  einsum('ij->', A): 21.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Sum all elements\n",
    "# Loop version:\n",
    "total_loop = 0\n",
    "for i in range(A.shape[0]):\n",
    "    for j in range(A.shape[1]):\n",
    "        total_loop += A[i, j]\n",
    "\n",
    "print(\"A:\")\n",
    "print(A)\n",
    "print(f\"\\nSum all elements:\")\n",
    "print(f\"  Loop: {total_loop}\")\n",
    "print(f\"  torch.sum: {A.sum()}\")\n",
    "print(f\"  einsum('ij->', A): {einsum('ij->', A)}\")  # no output indices = sum everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f54545e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Sum along rows (for each column):\n",
      "  Loop: tensor([0., 0.])\n",
      "  torch.sum(dim=0): tensor([5., 7., 9.])\n",
      "  einsum('ij->j', A): tensor([5., 7., 9.])\n",
      "\n",
      "Sum along columns (for each row):\n",
      "  Loop: tensor([0., 0.])\n",
      "  torch.sum(dim=1): tensor([ 6., 15.])\n",
      "  einsum('ij->i', A): tensor([ 6., 15.])\n"
     ]
    }
   ],
   "source": [
    "# 2. Sum along rows (keep columns)\n",
    "# For each column j, sum over all rows i\n",
    "row_sums_loop = torch.zeros(A.shape[1])\n",
    "for j in range(A.shape[1]):\n",
    "    for i in range(A.shape[0]):\n",
    "        row_sums_loop[j] += A[i, j]\n",
    "\n",
    "col_sums_loop = torch.zeros(A.shape[0])\n",
    "for i in range(A.shape[0]):\n",
    "    for j in range(A.shape[1]):\n",
    "        row_sums_loop[i] += A[i, j]\n",
    "\n",
    "print(\"A:\")\n",
    "print(A)\n",
    "print(f\"\\nSum along rows (for each column):\")\n",
    "print(f\"  Loop: {col_sums_loop}\")\n",
    "print(f\"  torch.sum(dim=0): {A.sum(dim=0)}\")\n",
    "print(f\"  einsum('ij->j', A): {einsum('ij->j', A)}\")  # i not in output = sum over i\n",
    "print()\n",
    "print(f\"Sum along columns (for each row):\")\n",
    "print(f\"  Loop: {col_sums_loop}\")\n",
    "print(f\"  torch.sum(dim=1): {A.sum(dim=1)}\")\n",
    "print(f\"  einsum('ij->i', A): {einsum('ij->i', A)}\")  # j not in output = sum over j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab6b1424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "A.shape: torch.Size([2, 3])\n",
      "A_T_loop.shape: torch.Size([3, 2])\n",
      "\n",
      "i: 0\n",
      "  j: 0 A[i, j]: tensor(1.)\n",
      "  j: 1 A[i, j]: tensor(2.)\n",
      "  j: 2 A[i, j]: tensor(3.)\n",
      "i: 1\n",
      "  j: 0 A[i, j]: tensor(4.)\n",
      "  j: 1 A[i, j]: tensor(5.)\n",
      "  j: 2 A[i, j]: tensor(6.)\n",
      "\n",
      "Transpose (swap i and j):\n",
      "  Loop:\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "  A.T:\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "\n",
      "  einsum('ij->ji', A):\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# 3. Transpose\n",
    "# Just swap the order of indices in the output!\n",
    "\n",
    "print(\"A:\")\n",
    "print(A)\n",
    "print(f\"A.shape: {A.shape}\")\n",
    "\n",
    "# Loop version\n",
    "A_T_loop = torch.zeros(A.shape[1], A.shape[0], dtype=A.dtype)\n",
    "print(f\"A_T_loop.shape: {A_T_loop.shape}\")\n",
    "print()\n",
    "for i in range(A.shape[0]):\n",
    "    print(f\"i: {i}\")\n",
    "    for j in range(A.shape[1]):\n",
    "        print(f\"  j: {j}\", \"A[i, j]:\", A[i, j])\n",
    "        A_T_loop[j, i] = A[i, j]\n",
    "\n",
    "print(f\"\\nTranspose (swap i and j):\")\n",
    "print(f\"  Loop:\\n{A_T_loop}\")\n",
    "print(f\"  A.T:\\n{A.T}\")\n",
    "print()\n",
    "print(f\"  einsum('ij->ji', A):\\n{einsum('ij->ji', A)}\")  # swap output order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "958d4945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: [1.0, 2.0, 3.0]\n",
      "v2: [4.0, 5.0, 6.0]\n",
      "\n",
      "Dot product (v1 · v2):\n",
      "  Loop: 32.0\n",
      "  torch.dot: 32.0\n",
      "  einsum('i,i->', v1, v2): 32.0\n"
     ]
    }
   ],
   "source": [
    "# 4. Dot product (inner product) of two vectors\n",
    "v1 = torch.tensor([1., 2., 3.])\n",
    "v2 = torch.tensor([4., 5., 6.])\n",
    "\n",
    "# Loop version\n",
    "dot_loop = 0\n",
    "for i in range(len(v1)):\n",
    "    dot_loop += v1[i] * v2[i]\n",
    "\n",
    "print(f\"v1: {v1.tolist()}\")\n",
    "print(f\"v2: {v2.tolist()}\")\n",
    "print(f\"\\nDot product (v1 · v2):\")\n",
    "print(f\"  Loop: {dot_loop}\")\n",
    "print(f\"  torch.dot: {torch.dot(v1, v2)}\")\n",
    "print(f\"  einsum('i,i->', v1, v2): {einsum('i,i->', v1, v2)}\")  # same index, no output = sum products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a1945d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: [1.0, 2.0, 3.0]\n",
      "v2: [4.0, 5.0, 6.0]\n",
      "\n",
      "Outer product (v1 ⊗ v2):\n",
      "  Loop:\n",
      "tensor([[ 4.,  5.,  6.],\n",
      "        [ 8., 10., 12.],\n",
      "        [12., 15., 18.]])\n",
      "\n",
      "  torch.outer:\n",
      "tensor([[ 4.,  5.,  6.],\n",
      "        [ 8., 10., 12.],\n",
      "        [12., 15., 18.]])\n",
      "\n",
      "  einsum('i,j->ij', v1, v2):\n",
      "tensor([[ 4.,  5.,  6.],\n",
      "        [ 8., 10., 12.],\n",
      "        [12., 15., 18.]])\n"
     ]
    }
   ],
   "source": [
    "# 5. Outer product: every element of v1 times every element of v2\n",
    "# Result[i,j] = v1[i] * v2[j]\n",
    "\n",
    "outer_loop = torch.zeros(len(v1), len(v2))\n",
    "for i in range(len(v1)):\n",
    "    for j in range(len(v2)):\n",
    "        outer_loop[i, j] = v1[i] * v2[j]\n",
    "\n",
    "print(f\"v1: {v1.tolist()}\")\n",
    "print(f\"v2: {v2.tolist()}\")\n",
    "print(f\"\\nOuter product (v1 ⊗ v2):\")\n",
    "print(f\"  Loop:\\n{outer_loop}\")\n",
    "print()\n",
    "print(f\"  torch.outer:\\n{torch.outer(v1, v2)}\")\n",
    "print()\n",
    "print(f\"  einsum('i,j->ij', v1, v2):\\n{einsum('i,j->ij', v1, v2)}\")  # different indices = keep both\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24aaead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: [1.0, 2.0]\n",
      "v: [3.0, 4.0, 5.0]\n",
      "w: [6.0, 7.0]\n",
      "\n",
      "3-way Outer product (u ⊗ v ⊗ w):\n",
      "  Loop:\n",
      "tensor([[[18., 21.],\n",
      "         [24., 28.],\n",
      "         [30., 35.]],\n",
      "\n",
      "        [[36., 42.],\n",
      "         [48., 56.],\n",
      "         [60., 70.]]])\n",
      "\n",
      "  Using einsum('i,j,k->ijk', u, v, w):\n",
      "tensor([[[18., 21.],\n",
      "         [24., 28.],\n",
      "         [30., 35.]],\n",
      "\n",
      "        [[36., 42.],\n",
      "         [48., 56.],\n",
      "         [60., 70.]]])\n"
     ]
    }
   ],
   "source": [
    "# Harder outer product example: 3 vectors, result is a rank-3 tensor\n",
    "\n",
    "u = torch.tensor([1., 2.])\n",
    "v = torch.tensor([3., 4., 5.])\n",
    "w = torch.tensor([6., 7.])\n",
    "\n",
    "# Loop version for 3-way outer product: Result[i,j,k] = u[i] * v[j] * w[k]\n",
    "outer3_loop = torch.zeros(len(u), len(v), len(w))\n",
    "for i in range(len(u)):\n",
    "    for j in range(len(v)):\n",
    "        for k in range(len(w)):\n",
    "            outer3_loop[i, j, k] = u[i] * v[j] * w[k]\n",
    "\n",
    "print(f\"u: {u.tolist()}\")\n",
    "print(f\"v: {v.tolist()}\")\n",
    "print(f\"w: {w.tolist()}\")\n",
    "print(\"\\n3-way Outer product (u ⊗ v ⊗ w):\")\n",
    "print(f\"  Loop:\\n{outer3_loop}\")\n",
    "print()\n",
    "print(\"  Using einsum('i,j,k->ijk', u, v, w):\")\n",
    "print(einsum('i,j,k->ijk', u, v, w))  # three different indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2836fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [1.0, 2.0]\n",
      "b: [3.0, 4.0]  # This will be summed out in final result\n",
      "c:\n",
      "tensor([[2., 1.],\n",
      "        [3., 2.],\n",
      "        [4., 3.]])\n",
      "d: [1.0, 2.0]\n",
      "\n",
      "Step 0: Full 5-loop implementation (i, k, l, m, j)\n",
      "  Result.shape = (2, 3, 2, 2)\n",
      "tensor([[[[ 14.,  28.],\n",
      "          [  7.,  14.]],\n",
      "\n",
      "         [[ 21.,  42.],\n",
      "          [ 14.,  28.]],\n",
      "\n",
      "         [[ 28.,  56.],\n",
      "          [ 21.,  42.]]],\n",
      "\n",
      "\n",
      "        [[[ 28.,  56.],\n",
      "          [ 14.,  28.]],\n",
      "\n",
      "         [[ 42.,  84.],\n",
      "          [ 28.,  56.]],\n",
      "\n",
      "         [[ 56., 112.],\n",
      "          [ 42.,  84.]]]])\n",
      "\n",
      "Step 1: Removed the 'j' loop (now 4 loops: i, k, l, m)\n",
      "  Max difference vs Step 0: 0.0\n",
      "\n",
      "Step 2: Removed the 'm' loop (now 3 loops: i, k, l)\n",
      "  Max difference vs Step 0: 0.0\n",
      "\n",
      "Step 3: Removed the 'l' loop (now 2 loops: i, k)\n",
      "  Max difference vs Step 0: 0.0\n",
      "\n",
      "Step 4: Removed the 'k' loop (now 1 loop: i)\n",
      "  Max difference vs Step 0: 0.0\n",
      "\n",
      "Step 5: No Python loops, just broadcasting\n",
      "  Max difference vs Step 0: 0.0\n",
      "\n",
      "Step 6: Single einsum call\n",
      "  Max difference vs Step 0: 0.0\n",
      "\n",
      "Final einsum result:\n",
      "tensor([[[[ 14.,  28.],\n",
      "          [  7.,  14.]],\n",
      "\n",
      "         [[ 21.,  42.],\n",
      "          [ 14.,  28.]],\n",
      "\n",
      "         [[ 28.,  56.],\n",
      "          [ 21.,  42.]]],\n",
      "\n",
      "\n",
      "        [[[ 28.,  56.],\n",
      "          [ 14.,  28.]],\n",
      "\n",
      "         [[ 42.,  84.],\n",
      "          [ 28.,  56.]],\n",
      "\n",
      "         [[ 56., 112.],\n",
      "          [ 42.,  84.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Challenging heterogeneous outer product example:\n",
    "# Make one input a matrix (rank-2), and ignore one vector in the output (trace it out / sum over it).\n",
    "\n",
    "# a: shape (2,), b: shape (2,), c: shape (3, 2) [matrix!], d: shape (2,)\n",
    "a = torch.tensor([1., 2.])\n",
    "b = torch.tensor([3., 4.])\n",
    "c = torch.tensor([[2., 1.], [3., 2.], [4., 3.]])  # 3x2 matrix\n",
    "d = torch.tensor([1., 2.])\n",
    "\n",
    "print(f\"a: {a.tolist()}\")\n",
    "print(f\"b: {b.tolist()}  # This will be summed out in final result\")\n",
    "print(f\"c:\\n{c}\")\n",
    "print(f\"d: {d.tolist()}\")\n",
    "print()\n",
    "\n",
    "# Compute: Outer over a (i), b (j), c (k,l), d (m)\n",
    "# But sum out b -- i.e., Result[i, k, l, m] = sum_j a[i] * b[j] * c[k, l] * d[m]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Step 0: Full explicit nested loops (reference implementation)\n",
    "# ---------------------------------------------------------------------\n",
    "outer_step0 = torch.zeros(len(a), c.shape[0], c.shape[1], len(d))\n",
    "\n",
    "for i in range(len(a)):\n",
    "    for k in range(c.shape[0]):\n",
    "        for l in range(c.shape[1]):\n",
    "            for m in range(len(d)):\n",
    "                s = 0.\n",
    "                for j in range(len(b)):\n",
    "                    s += a[i] * b[j] * c[k, l] * d[m]\n",
    "                outer_step0[i, k, l, m] = s\n",
    "\n",
    "print(\"Step 0: Full 5-loop implementation (i, k, l, m, j)\")\n",
    "print(\"  Result.shape =\", tuple(outer_step0.shape))\n",
    "print(outer_step0)\n",
    "print()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Step 1: Remove the innermost 'j' loop by summing b explicitly\n",
    "#   sum_j a[i]*b[j]*c[k,l]*d[m] = a[i] * (sum_j b[j]) * c[k,l] * d[m]\n",
    "# ---------------------------------------------------------------------\n",
    "sum_b = b.sum()\n",
    "outer_step1 = torch.zeros_like(outer_step0)\n",
    "\n",
    "for i in range(len(a)):\n",
    "    for k in range(c.shape[0]):\n",
    "        for l in range(c.shape[1]):\n",
    "            for m in range(len(d)):\n",
    "                outer_step1[i, k, l, m] = a[i] * sum_b * c[k, l] * d[m]\n",
    "\n",
    "print(\"Step 1: Removed the 'j' loop (now 4 loops: i, k, l, m)\")\n",
    "print(\"  Max difference vs Step 0:\", (outer_step1 - outer_step0).abs().max().item())\n",
    "print()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Step 2: Remove the 'm' loop by vectorizing over d\n",
    "#   For fixed i,k,l, the whole d-dimension is just scaled by a[i]*sum_b*c[k,l]\n",
    "# ---------------------------------------------------------------------\n",
    "outer_step2 = torch.zeros_like(outer_step0)\n",
    "\n",
    "for i in range(len(a)):\n",
    "    for k in range(c.shape[0]):\n",
    "        for l in range(c.shape[1]):\n",
    "            # This fills the entire m-axis at once\n",
    "            outer_step2[i, k, l, :] = a[i] * sum_b * c[k, l] * d\n",
    "\n",
    "print(\"Step 2: Removed the 'm' loop (now 3 loops: i, k, l)\")\n",
    "print(\"  Max difference vs Step 0:\", (outer_step2 - outer_step0).abs().max().item())\n",
    "print()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Step 3: Remove the 'l' loop by vectorizing over c's second dimension\n",
    "#   For fixed i,k, we want a[i]*sum_b * c[k, :] (length-2) outer d (length-2)\n",
    "#   That gives a 2x2 block over (l, m).\n",
    "# ---------------------------------------------------------------------\n",
    "outer_step3 = torch.zeros_like(outer_step0)\n",
    "\n",
    "for i in range(len(a)):\n",
    "    for k in range(c.shape[0]):\n",
    "        # c[k] has shape (2,), we make it (2,1) so it can broadcast with d (2,)\n",
    "        # Result is shape (2,2) filling (l,m).\n",
    "        outer_step3[i, k, :, :] = a[i] * sum_b * c[k].unsqueeze(-1) * d\n",
    "\n",
    "print(\"Step 3: Removed the 'l' loop (now 2 loops: i, k)\")\n",
    "print(\"  Max difference vs Step 0:\", (outer_step3 - outer_step0).abs().max().item())\n",
    "print()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Step 4: Remove the 'k' loop by vectorizing over the whole matrix c\n",
    "#   For fixed i, we want a[i]*sum_b * c (3x2), and then an extra outer with d (length-2)\n",
    "#   c has shape (3,2). We lift it to (3,2,1) and multiply with d (2,) -> (3,2,2)\n",
    "# ---------------------------------------------------------------------\n",
    "outer_step4 = torch.zeros_like(outer_step0)\n",
    "\n",
    "for i in range(len(a)):\n",
    "    # c.unsqueeze(-1): (3,2,1)\n",
    "    # d: (2,) broadcasts to (1,1,2)\n",
    "    # => result (3,2,2) over (k,l,m)\n",
    "    outer_step4[i, :, :, :] = a[i] * sum_b * c.unsqueeze(-1) * d\n",
    "\n",
    "print(\"Step 4: Removed the 'k' loop (now 1 loop: i)\")\n",
    "print(\"  Max difference vs Step 0:\", (outer_step4 - outer_step0).abs().max().item())\n",
    "print()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Step 5: Remove the final 'i' loop by full broadcasting\n",
    "#   Now we let all dimensions broadcast:\n",
    "#   - a: (2,)      -> (2,1,1,1)\n",
    "#   - c: (3,2)     -> (1,3,2,1)\n",
    "#   - d: (2,)      -> (1,1,1,2)\n",
    "#   And sum_b is a scalar.\n",
    "# ---------------------------------------------------------------------\n",
    "outer_step5 = (\n",
    "    a[:, None, None, None] *   # shape (2,1,1,1)\n",
    "    sum_b *                    # scalar\n",
    "    c[None, :, :, None] *      # shape (1,3,2,1)\n",
    "    d[None, None, None, :]     # shape (1,1,1,2)\n",
    ")\n",
    "\n",
    "print(\"Step 5: No Python loops, just broadcasting\")\n",
    "print(\"  Max difference vs Step 0:\", (outer_step5 - outer_step0).abs().max().item())\n",
    "print()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Step 6: Replace explicit broadcasting with a single einsum\n",
    "#\n",
    "# Recall the mathematical definition:\n",
    "#   Result[i, k, l, m] = sum_j a[i] * b[j] * c[k, l] * d[m]\n",
    "#\n",
    "# Map to einsum indices:\n",
    "#   a: (2,)    -> 'i'\n",
    "#   b: (2,)    -> 'j'   (summed out)\n",
    "#   c: (3,2)   -> 'kl'\n",
    "#   d: (2,)    -> 'm'\n",
    "#\n",
    "# We want output indices i,k,l,m and to sum over j:\n",
    "#   'i,j,kl,m -> iklm'\n",
    "# ---------------------------------------------------------------------\n",
    "einsum_result = torch.einsum('i,j,kl,m->iklm', a, b, c, d)\n",
    "\n",
    "print(\"Step 6: Single einsum call\")\n",
    "print(\"  Max difference vs Step 0:\", (einsum_result - outer_step0).abs().max().item())\n",
    "print()\n",
    "print(\"Final einsum result:\")\n",
    "print(einsum_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff960599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Now we'll start from the final einsum result and work backwards to the nested loops.\n",
    "# Make one input a matrix (rank-2), and ignore one vector in the output (trace it out / sum over it).\n",
    "\n",
    "# Math we want:\n",
    "#   Result[i, k, l, m] = sum_j a[i] * b[j] * c[k, l] * d[m]\n",
    "#\n",
    "# Index mapping for einsum:\n",
    "#   a: (2,)    -> 'i'\n",
    "#   b: (2,)    -> 'j'\n",
    "#   c: (3,2)   -> 'kl'\n",
    "#   d: (2,)    -> 'm'\n",
    "#\n",
    "# We want output indices i,k,l,m and to sum over j:\n",
    "#   'i,j,kl,m -> iklm'\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Step 0: Fully vectorized einsum reminder (no Python loops)\n",
    "# ---------------------------------------------------------------------\n",
    "result_step0 = torch.einsum('i,j,kl,m->iklm', a, b, c, d)\n",
    "\n",
    "print(\"Step 0: Full einsum with no Python loops\")\n",
    "print(\"  Result.shape =\", tuple(result_step0.shape))\n",
    "print(result_step0)\n",
    "print()\n",
    "\n",
    "# We'll treat this as our reference \"ground truth\" for all later steps.\n",
    "ref = result_step0\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Step 1: Add a loop over l (split c into columns)\n",
    "#\n",
    "# Idea:\n",
    "#   - Keep c as (3,2) but handle each column l separately.\n",
    "#   - For a fixed l, c[:, l] has shape (3,) and we treat it as a vector with index 'k'.\n",
    "#   - Use einsum over a (i), b (j), c[:, l] (k), d (m):\n",
    "#       'i,j,k,m -> ikm'\n",
    "#   - Then place that into the l-th slice of the result.\n",
    "# ---------------------------------------------------------------------\n",
    "result_step1 = torch.zeros_like(ref)\n",
    "\n",
    "for l in range(c.shape[1]):\n",
    "    # einsum over: a[i], b[j], c[:,l] (k), d[m]\n",
    "    # This sums out j and produces shape (i,k,m)\n",
    "    einsum_res_l = torch.einsum('i,j,k,m->ikm', a, b, c[:, l], d)\n",
    "    # Insert along l dimension\n",
    "    result_step1[:, :, l, :] = einsum_res_l\n",
    "\n",
    "print(\"Step 1: One Python loop (over l), everything else in einsum\")\n",
    "print(\"  Max difference vs Step 0:\", (result_step1 - ref).abs().max().item())\n",
    "print()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Step 2: Add loops over k and l\n",
    "#\n",
    "# Idea:\n",
    "#   - Now we peel off both k and l as explicit loops.\n",
    "#   - For each (k, l) pair, c[k, l] is a scalar.\n",
    "#   - The rest is an einsum over a (i), b (j), d (m):\n",
    "#       'i,j,m -> im'\n",
    "#   - Then we scale by c[k, l] and write into [i, k, l, m].\n",
    "# ---------------------------------------------------------------------\n",
    "result_step2 = torch.zeros_like(ref)\n",
    "\n",
    "for k in range(c.shape[0]):\n",
    "    for l in range(c.shape[1]):\n",
    "        # Base (i,m) tensor from a, b, d:\n",
    "        #   sum_j a[i] * b[j] * d[m]  (j is summed out)\n",
    "        base_im = torch.einsum('i,j,m->im', a, b, d)\n",
    "        # Scale by the scalar c[k, l] and store at this (k,l)\n",
    "        result_step2[:, k, l, :] = base_im * c[k, l]\n",
    "\n",
    "print(\"Step 2: Two Python loops (over k, l), contractions in einsum\")\n",
    "print(\"  Max difference vs Step 0:\", (result_step2 - ref).abs().max().item())\n",
    "print()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Step 3: Add loops over i, k, l\n",
    "#\n",
    "# Idea:\n",
    "#   - Now i, k, l are all handled in Python.\n",
    "#   - For each fixed (i, k, l), we want the m-dimension:\n",
    "#       Result[i, k, l, m] = a[i] * c[k, l] * sum_j b[j] * d[m]\n",
    "#   - The part that depends on j and m is:\n",
    "#       sum_j b[j] * d[m]   -> einsum 'j,m -> m'\n",
    "#   - Then we just scale by a[i] and c[k, l].\n",
    "# ---------------------------------------------------------------------\n",
    "result_step3 = torch.zeros_like(ref)\n",
    "\n",
    "for i in range(len(a)):\n",
    "    for k in range(c.shape[0]):\n",
    "        for l in range(c.shape[1]):\n",
    "            # This vector has shape (m,):\n",
    "            #   sum_j b[j] * d[m]\n",
    "            base_m = torch.einsum('j,m->m', b, d)\n",
    "            result_step3[i, k, l, :] = a[i] * c[k, l] * base_m\n",
    "\n",
    "print(\"Step 3: Three Python loops (over i, k, l), einsum handles j,m\")\n",
    "print(\"  Max difference vs Step 0:\", (result_step3 - ref).abs().max().item())\n",
    "print()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Step 4: Add loops over i, k, l, m\n",
    "#\n",
    "# Idea:\n",
    "#   - Now i, k, l, m are all explicit loops.\n",
    "#   - For each fixed (i, k, l, m), we want a single scalar:\n",
    "#       Result[i, k, l, m] = a[i] * c[k, l] * d[m] * sum_j b[j]\n",
    "#   - The only contraction left is the sum over j:\n",
    "#       sum_j b[j]           -> einsum 'j ->'\n",
    "#   - We precompute this once (still with einsum) and reuse it.\n",
    "# ---------------------------------------------------------------------\n",
    "sum_b = torch.einsum('j->', b)  # scalar = sum_j b[j]\n",
    "\n",
    "result_step4 = torch.zeros_like(ref)\n",
    "\n",
    "for i in range(len(a)):\n",
    "    for k in range(c.shape[0]):\n",
    "        for l in range(c.shape[1]):\n",
    "            for m in range(len(d)):\n",
    "                result_step4[i, k, l, m] = a[i] * c[k, l] * d[m] * sum_b\n",
    "\n",
    "print(\"Step 4: Four Python loops (over i, k, l, m), einsum only for sum over j\")\n",
    "print(\"  Max difference vs Step 0:\", (result_step4 - ref).abs().max().item())\n",
    "print()\n",
    "\n",
    "# If we went one step further (5 loops), we'd explicitly loop over j as well and\n",
    "# manually do the sum, which would just replicate what einsum already does internally.\n",
    "# So we stop here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef6a4928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([2, 3, 4, 5])\n",
      "Y shape: torch.Size([1, 4, 5])\n",
      "\n",
      "Step 0: Full 5-loop implementation (i, j, k, m, l)\n",
      "  Result shape: torch.Size([2, 3, 4, 1])\n",
      "tensor([[[[  30.],\n",
      "          [ 255.],\n",
      "          [ 730.],\n",
      "          [1455.]],\n",
      "\n",
      "         [[ 230.],\n",
      "          [ 955.],\n",
      "          [1930.],\n",
      "          [3155.]],\n",
      "\n",
      "         [[ 430.],\n",
      "          [1655.],\n",
      "          [3130.],\n",
      "          [4855.]]],\n",
      "\n",
      "\n",
      "        [[[ 630.],\n",
      "          [2355.],\n",
      "          [4330.],\n",
      "          [6555.]],\n",
      "\n",
      "         [[ 830.],\n",
      "          [3055.],\n",
      "          [5530.],\n",
      "          [8255.]],\n",
      "\n",
      "         [[1030.],\n",
      "          [3755.],\n",
      "          [6730.],\n",
      "          [9955.]]]])\n",
      "\n",
      "Step 1: 4 loops (i, j, k, m), l handled by .sum over the last dim\n",
      "  Max difference vs Step 0: 0.0\n",
      "\n",
      "Step 2: 3 loops (i, j, k), m absorbed by using Y[0, k, :]\n",
      "  Max difference vs Step 0: 0.0\n",
      "\n",
      "Step 3: 2 loops (i, j), k and l handled by tensor ops\n",
      "  Max difference vs Step 0: 0.0\n",
      "\n",
      "Step 4: 1 loop (i), j,k,l handled by tensor ops\n",
      "  Max difference vs Step 0: 0.0\n",
      "\n",
      "Step 5: 0 loops, pure broadcasting + sum\n",
      "  broadcast_result shape: torch.Size([2, 3, 4, 1])\n",
      "  Max difference vs Step 0: 0.0\n",
      "\n",
      "Einsum version: einsum('ijkl,mkl->ijkm', X, Y)\n",
      "  einsum_result shape: torch.Size([2, 3, 4, 1])\n",
      "tensor([[[[  30.],\n",
      "          [ 255.],\n",
      "          [ 730.],\n",
      "          [1455.]],\n",
      "\n",
      "         [[ 230.],\n",
      "          [ 955.],\n",
      "          [1930.],\n",
      "          [3155.]],\n",
      "\n",
      "         [[ 430.],\n",
      "          [1655.],\n",
      "          [3130.],\n",
      "          [4855.]]],\n",
      "\n",
      "\n",
      "        [[[ 630.],\n",
      "          [2355.],\n",
      "          [4330.],\n",
      "          [6555.]],\n",
      "\n",
      "         [[ 830.],\n",
      "          [3055.],\n",
      "          [5530.],\n",
      "          [8255.]],\n",
      "\n",
      "         [[1030.],\n",
      "          [3755.],\n",
      "          [6730.],\n",
      "          [9955.]]]])\n",
      "\n",
      "Difference between einsum and full_loop (should be 0): 0.0\n",
      "\n",
      "Step E0: No loops, einsum only (same as ref)\n",
      "  Max difference vs ref: 0.0\n",
      "\n",
      "Step E1: 1 loop (m), einsum handles (i,j,k,l)\n",
      "  Max difference vs ref: 0.0\n",
      "\n",
      "Step E2: 2 loops (k, m), einsum handles (i,j,l)\n",
      "  Max difference vs ref: 0.0\n",
      "\n",
      "Step E3: 3 loops (j, k, m), einsum handles (i,l)\n",
      "  Max difference vs ref: 0.0\n",
      "\n",
      "Step E4: 4 loops (i, j, k, m), einsum only does 1D dot 'l,l->'\n",
      "  Max difference vs ref: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Matmul of a 4d tensor (X) with a 3d tensor (Y) that needs to be broadcast\n",
    "\n",
    "# Let's define a 4d tensor X of shape (2, 3, 4, 5)\n",
    "X = torch.arange(2*3*4*5, dtype=torch.float32).reshape(2, 3, 4, 5)\n",
    "\n",
    "# And a 3d tensor Y of shape (1, 4, 5), which will be broadcast across the first dimension\n",
    "Y = torch.arange(4*5, dtype=torch.float32).reshape(1, 4, 5)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "print()\n",
    "\n",
    "# We want a \"batched matmul\" over the last axis (size 5), for each X[i,j,k,:] and Y[m,k,:].\n",
    "# Result index structure:\n",
    "#   i in [0, 2)\n",
    "#   j in [0, 3)\n",
    "#   k in [0, 4)\n",
    "#   m in [0, 1)\n",
    "#\n",
    "# Mathematically:\n",
    "#   result[i, j, k, m] = sum_l X[i, j, k, l] * Y[m, k, l]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# PART 1: From all loops down to no loops (NO einsum)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# Step 0: Full explicit loops, including the inner l loop\n",
    "full_loop = torch.zeros(X.shape[0], X.shape[1], X.shape[2], Y.shape[0])\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        for k in range(X.shape[2]):\n",
    "            for m in range(Y.shape[0]):\n",
    "                s = 0.0\n",
    "                for l in range(X.shape[3]):  # inner dot-product over l\n",
    "                    s += X[i, j, k, l] * Y[m, k, l]\n",
    "                full_loop[i, j, k, m] = s\n",
    "\n",
    "print(\"Step 0: Full 5-loop implementation (i, j, k, m, l)\")\n",
    "print(\"  Result shape:\", full_loop.shape)\n",
    "print(full_loop)\n",
    "print()\n",
    "\n",
    "\n",
    "# Step 1: Remove the l loop by using vectorized dot-product (still 4 loops)\n",
    "step1 = torch.zeros_like(full_loop)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        for k in range(X.shape[2]):\n",
    "            for m in range(Y.shape[0]):\n",
    "                # Now we let PyTorch do the l-sum:\n",
    "                step1[i, j, k, m] = (X[i, j, k, :] * Y[m, k, :]).sum()\n",
    "\n",
    "print(\"Step 1: 4 loops (i, j, k, m), l handled by .sum over the last dim\")\n",
    "print(\"  Max difference vs Step 0:\", (step1 - full_loop).abs().max().item())\n",
    "print()\n",
    "\n",
    "\n",
    "# Step 2: Remove the m loop (remember Y has shape (1, 4, 5), so m is size 1)\n",
    "#         We can just use Y[0, k, :] everywhere.\n",
    "step2 = torch.zeros_like(full_loop)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        for k in range(X.shape[2]):\n",
    "            # Dot-product of X[i,j,k,:] with Y[0,k,:], then stored at m=0\n",
    "            step2[i, j, k, 0] = (X[i, j, k, :] * Y[0, k, :]).sum()\n",
    "\n",
    "print(\"Step 2: 3 loops (i, j, k), m absorbed by using Y[0, k, :]\")\n",
    "print(\"  Max difference vs Step 0:\", (step2 - full_loop).abs().max().item())\n",
    "print()\n",
    "\n",
    "\n",
    "# Step 3: Remove the k loop by vectorizing over k as well\n",
    "#         For fixed (i, j), we want all k:\n",
    "#           result[i, j, k, 0] = sum_l X[i,j,k,l] * Y[0,k,l]\n",
    "#         This is just a batched dot over the last dim.\n",
    "step3 = torch.zeros_like(full_loop)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        # X[i, j, :, :] has shape (4, 5)\n",
    "        # Y[0, :, :] has shape (4, 5)\n",
    "        # Elementwise multiply and sum over last dim -> shape (4,)\n",
    "        step3[i, j, :, 0] = (X[i, j, :, :] * Y[0, :, :]).sum(dim=-1)\n",
    "\n",
    "print(\"Step 3: 2 loops (i, j), k and l handled by tensor ops\")\n",
    "print(\"  Max difference vs Step 0:\", (step3 - full_loop).abs().max().item())\n",
    "print()\n",
    "\n",
    "\n",
    "# Step 4: Remove the j loop by vectorizing over j\n",
    "#         For fixed i, X[i] has shape (3, 4, 5), Y[0] has shape (4, 5).\n",
    "#         We want:\n",
    "#           result[i, j, k, 0] = sum_l X[i,j,k,l] * Y[0,k,l]\n",
    "#         We can broadcast Y[0] onto X[i] and sum over the last dim.\n",
    "step4 = torch.zeros_like(full_loop)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    # X[i] shape: (3, 4, 5)\n",
    "    # Y[0] shape: (4, 5) -> broadcast to (1, 4, 5) then (3, 4, 5)\n",
    "    prod = X[i] * Y[0]   # shape (3, 4, 5)\n",
    "    # sum over l to get (3, 4)\n",
    "    step4[i, :, :, 0] = prod.sum(dim=-1)\n",
    "\n",
    "print(\"Step 4: 1 loop (i), j,k,l handled by tensor ops\")\n",
    "print(\"  Max difference vs Step 0:\", (step4 - full_loop).abs().max().item())\n",
    "print()\n",
    "\n",
    "\n",
    "# Step 5: No loops at all: fully broadcasted tensor operation\n",
    "#         X: (2, 3, 4, 5)\n",
    "#         Y: (1, 4, 5) -> broadcast to (2, 1, 4, 5) -> (2, 3, 4, 5)\n",
    "#         Then sum over last dim (l=5) and keep a singleton dim for m.\n",
    "broadcast_result = (X * Y.unsqueeze(1)).sum(dim=-1, keepdim=True)\n",
    "# Y.unsqueeze(1): (1,1,4,5) -> (2,3,4,5) by broadcasting\n",
    "\n",
    "print(\"Step 5: 0 loops, pure broadcasting + sum\")\n",
    "print(\"  broadcast_result shape:\", broadcast_result.shape)\n",
    "print(\"  Max difference vs Step 0:\", (broadcast_result - full_loop).abs().max().item())\n",
    "print()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# PART 2: Einsum version (also no loops)\n",
    "# ---------------------------------------------------------------------\n",
    "einsum_result = torch.einsum('ijkl,mkl->ijkm', X, Y)\n",
    "\n",
    "print(\"Einsum version: einsum('ijkl,mkl->ijkm', X, Y)\")\n",
    "print(\"  einsum_result shape:\", einsum_result.shape)\n",
    "print(einsum_result)\n",
    "print()\n",
    "print(\"Difference between einsum and full_loop (should be 0):\",\n",
    "      (einsum_result - full_loop).abs().max().item())\n",
    "print()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# PART 3: Build back up using ONLY einsum (no manual .sum)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "ref = einsum_result  # treat einsum_result as the ground truth for this part\n",
    "\n",
    "\n",
    "# Step E0: Reference, no loops\n",
    "stepE0 = torch.einsum('ijkl,mkl->ijkm', X, Y)\n",
    "\n",
    "print(\"Step E0: No loops, einsum only (same as ref)\")\n",
    "print(\"  Max difference vs ref:\", (stepE0 - ref).abs().max().item())\n",
    "print()\n",
    "\n",
    "\n",
    "# Step E1: Add a loop over m, einsum handles i,j,k,l\n",
    "#   For fixed m, we contract:\n",
    "#     result[:, :, :, m] = sum_l X[i,j,k,l] * Y[m,k,l]\n",
    "#   Einsum: 'ijkl,kl->ijk'\n",
    "stepE1 = torch.zeros_like(ref)\n",
    "\n",
    "for m in range(Y.shape[0]):\n",
    "    stepE1[:, :, :, m] = torch.einsum('ijkl,kl->ijk', X, Y[m])\n",
    "\n",
    "print(\"Step E1: 1 loop (m), einsum handles (i,j,k,l)\")\n",
    "print(\"  Max difference vs ref:\", (stepE1 - ref).abs().max().item())\n",
    "print()\n",
    "\n",
    "\n",
    "# Step E2: Add loops over k and m, einsum handles i,j,l\n",
    "#   For fixed (k, m):\n",
    "#     result[:, :, k, m] = sum_l X[i,j,k,l] * Y[m,k,l]\n",
    "#   Einsum: 'ijl,l->ij'\n",
    "stepE2 = torch.zeros_like(ref)\n",
    "\n",
    "for m in range(Y.shape[0]):\n",
    "    for k in range(X.shape[2]):\n",
    "        stepE2[:, :, k, m] = torch.einsum('ijl,l->ij', X[:, :, k, :], Y[m, k, :])\n",
    "\n",
    "print(\"Step E2: 2 loops (k, m), einsum handles (i,j,l)\")\n",
    "print(\"  Max difference vs ref:\", (stepE2 - ref).abs().max().item())\n",
    "print()\n",
    "\n",
    "\n",
    "# Step E3: Add loops over j, k, m, einsum handles i,l\n",
    "#   For fixed (j, k, m):\n",
    "#     result[:, j, k, m] = sum_l X[i,j,k,l] * Y[m,k,l]\n",
    "#   Einsum: 'il,l->i'\n",
    "stepE3 = torch.zeros_like(ref)\n",
    "\n",
    "for m in range(Y.shape[0]):\n",
    "    for k in range(X.shape[2]):\n",
    "        for j in range(X.shape[1]):\n",
    "            stepE3[:, j, k, m] = torch.einsum('il,l->i', X[:, j, k, :], Y[m, k, :])\n",
    "\n",
    "print(\"Step E3: 3 loops (j, k, m), einsum handles (i,l)\")\n",
    "print(\"  Max difference vs ref:\", (stepE3 - ref).abs().max().item())\n",
    "print()\n",
    "\n",
    "\n",
    "# Step E4: Add loops over i, j, k, m, einsum only does the final scalar dot over l\n",
    "#   For fixed (i, j, k, m):\n",
    "#     result[i, j, k, m] = sum_l X[i,j,k,l] * Y[m,k,l]\n",
    "#   Einsum: 'l,l->'\n",
    "stepE4 = torch.zeros_like(ref)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        for k in range(X.shape[2]):\n",
    "            for m in range(Y.shape[0]):\n",
    "                stepE4[i, j, k, m] = torch.einsum('l,l->', X[i, j, k, :], Y[m, k, :])\n",
    "\n",
    "print(\"Step E4: 4 loops (i, j, k, m), einsum only does 1D dot 'l,l->'\")\n",
    "print(\"  Max difference vs ref:\", (stepE4 - ref).abs().max().item())\n",
    "print()\n",
    "\n",
    "# If we went one step further (5 loops), we'd also manually loop over l and\n",
    "# sum up X[i,j,k,l] * Y[m,k,l], which would replicate what einsum is doing\n",
    "# internally in 'l,l->'. So we stop here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a92702c",
   "metadata": {},
   "source": [
    "## The Einsum Rules\n",
    "\n",
    "Now we can see the pattern:\n",
    "\n",
    "| Rule | What happens |\n",
    "|------|--------------|\n",
    "| Index in output | Keep that dimension |\n",
    "| Index NOT in output | Sum over it |\n",
    "| Same index in multiple tensors | Those dimensions are \"aligned\" (multiplied element-wise) |\n",
    "| Different indices | Creates all combinations (like nested loops) |\n",
    "\n",
    "**Einsum = \"for each combination of indices, multiply and optionally sum\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5a7106",
   "metadata": {},
   "source": [
    "## Batched Operations\n",
    "\n",
    "In deep learning, we often have batches. Einsum handles this naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbcee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch of 2 matrices, each 2x3\n",
    "batch_A = torch.tensor([\n",
    "    [[1, 2, 3],    # batch 0\n",
    "     [4, 5, 6]],\n",
    "    [[7, 8, 9],    # batch 1\n",
    "     [10, 11, 12]]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Batch of 2 matrices, each 3x2\n",
    "batch_B = torch.tensor([\n",
    "    [[1, 0],       # batch 0\n",
    "     [0, 1],\n",
    "     [1, 1]],\n",
    "    [[1, 1],       # batch 1\n",
    "     [1, 0],\n",
    "     [0, 1]]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "print(f\"batch_A shape: {batch_A.shape}  (batch, rows, cols)\")\n",
    "print(f\"batch_B shape: {batch_B.shape}  (batch, rows, cols)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbdae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch matrix multiplication: for each batch, multiply corresponding matrices\n",
    "# C[b, i, k] = Σⱼ A[b, i, j] × B[b, j, k]\n",
    "\n",
    "# Loop version - notice how many loops!\n",
    "B_size, I, J = batch_A.shape\n",
    "_, J2, K = batch_B.shape\n",
    "\n",
    "result_loop = torch.zeros(B_size, I, K)\n",
    "for b in range(B_size):\n",
    "    for i in range(I):\n",
    "        for k in range(K):\n",
    "            for j in range(J):\n",
    "                result_loop[b, i, k] += batch_A[b, i, j] * batch_B[b, j, k]\n",
    "\n",
    "print(\"Batch matmul with loops:\")\n",
    "print(result_loop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362493e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With einsum: just add 'b' to the front!\n",
    "result_einsum = einsum('bij,bjk->bik', batch_A, batch_B)\n",
    "\n",
    "print(\"Batch matmul with einsum('bij,bjk->bik'):\")\n",
    "print(result_einsum)\n",
    "print(f\"\\nMatch: {torch.allclose(result_loop, result_einsum)}\")\n",
    "\n",
    "# Compare with torch.bmm\n",
    "print(f\"\\ntorch.bmm match: {torch.allclose(torch.bmm(batch_A, batch_B), result_einsum)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ec614",
   "metadata": {},
   "source": [
    "## Real Example: Attention Scores\n",
    "\n",
    "In transformers, we compute attention scores: `Q @ K.T` for queries and keys.\n",
    "\n",
    "Let's see how einsum makes this clearer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e278a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention setup\n",
    "# batch=2, seq_len=3, d_model=4\n",
    "batch, seq_len, d_model = 2, 3, 4\n",
    "\n",
    "torch.manual_seed(42)\n",
    "Q = torch.randn(batch, seq_len, d_model)  # queries\n",
    "K = torch.randn(batch, seq_len, d_model)  # keys\n",
    "\n",
    "print(f\"Q shape: {Q.shape}  (batch, seq_len, d_model)\")\n",
    "print(f\"K shape: {K.shape}  (batch, seq_len, d_model)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97795ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention scores: for each query position, dot product with each key position\n",
    "# scores[b, i, j] = Σ_d Q[b, i, d] * K[b, j, d]\n",
    "\n",
    "# Standard PyTorch way - need to transpose K\n",
    "scores_torch = torch.bmm(Q, K.transpose(1, 2))\n",
    "print(f\"scores shape: {scores_torch.shape}  (batch, query_pos, key_pos)\")\n",
    "\n",
    "# Einsum way - much clearer what's happening!\n",
    "# b=batch, i=query position, j=key position, d=dimension (summed over)\n",
    "scores_einsum = einsum('bid,bjd->bij', Q, K)\n",
    "\n",
    "print(f\"\\nUsing torch.bmm(Q, K.transpose(1,2)):\")\n",
    "print(scores_torch[0])  # first batch\n",
    "\n",
    "print(f\"\\nUsing einsum('bid,bjd->bij', Q, K):\")\n",
    "print(scores_einsum[0])\n",
    "\n",
    "print(f\"\\nMatch: {torch.allclose(scores_torch, scores_einsum)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d40a676",
   "metadata": {},
   "source": [
    "## The Next Problem: Reshape and Permute Are Confusing\n",
    "\n",
    "Einsum handles computation. But what about just rearranging tensor shapes?\n",
    "\n",
    "PyTorch has `reshape`, `permute`, `view`, `transpose`... and they're often combined in confusing ways.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd16019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: we have an image batch in NHWC format (batch, height, width, channels)\n",
    "# and need to convert to NCHW format (what PyTorch expects)\n",
    "\n",
    "# Fake image batch: 2 images, 4x4 pixels, 3 channels\n",
    "images_nhwc = torch.arange(2 * 4 * 4 * 3).reshape(2, 4, 4, 3).float()\n",
    "print(f\"Original shape (NHWC): {images_nhwc.shape}\")\n",
    "print(f\"  N={images_nhwc.shape[0]}, H={images_nhwc.shape[1]}, W={images_nhwc.shape[2]}, C={images_nhwc.shape[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0dfb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch way: permute with dimension indices\n",
    "# NHWC -> NCHW means: dim 0 stays, dim 3 moves to 1, dim 1 moves to 2, dim 2 moves to 3\n",
    "# So permute(0, 3, 1, 2)\n",
    "\n",
    "images_nchw_torch = images_nhwc.permute(0, 3, 1, 2)\n",
    "print(f\"After permute(0, 3, 1, 2): {images_nchw_torch.shape}\")\n",
    "\n",
    "# Quick, what does permute(0, 2, 1, 3) do? \n",
    "# Hard to tell without thinking carefully about indices!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fbf402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# einops way: use NAMES, not numbers!\n",
    "images_nchw_einops = rearrange(images_nhwc, 'n h w c -> n c h w')\n",
    "print(f\"After rearrange('n h w c -> n c h w'): {images_nchw_einops.shape}\")\n",
    "\n",
    "print(f\"\\nMatch: {torch.allclose(images_nchw_torch, images_nchw_einops)}\")\n",
    "print(\"\\n→ The einops version is SELF-DOCUMENTING!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af973750",
   "metadata": {},
   "source": [
    "## Einops Power: Splitting and Merging Dimensions\n",
    "\n",
    "Einops can also split one dimension into multiple, or merge multiple into one. This is incredibly useful for multi-head attention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c81d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dimensions: flatten image to vector\n",
    "# (batch, height, width, channels) -> (batch, height*width*channels)\n",
    "\n",
    "images = torch.arange(2 * 4 * 4 * 3).reshape(2, 4, 4, 3).float()\n",
    "print(f\"Original: {images.shape}\")\n",
    "\n",
    "# PyTorch way - need to calculate the size\n",
    "flat_torch = images.reshape(2, -1)  # or images.view(2, 4*4*3)\n",
    "print(f\"PyTorch reshape: {flat_torch.shape}\")\n",
    "\n",
    "# Einops way - parentheses merge dimensions\n",
    "flat_einops = rearrange(images, 'b h w c -> b (h w c)')\n",
    "print(f\"Einops 'b h w c -> b (h w c)': {flat_einops.shape}\")\n",
    "\n",
    "print(f\"\\nMatch: {torch.allclose(flat_torch, flat_einops)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dimensions: for multi-head attention\n",
    "# We have (batch, seq_len, d_model) and want (batch, heads, seq_len, d_head)\n",
    "# where d_model = heads * d_head\n",
    "\n",
    "batch, seq_len, d_model = 2, 5, 12\n",
    "heads = 3  # so d_head = 12/3 = 4\n",
    "\n",
    "x = torch.randn(batch, seq_len, d_model)\n",
    "print(f\"Original: {x.shape}  (batch, seq_len, d_model={d_model})\")\n",
    "\n",
    "# PyTorch way - reshape then transpose\n",
    "x_torch = x.view(batch, seq_len, heads, d_model // heads).transpose(1, 2)\n",
    "print(f\"PyTorch view+transpose: {x_torch.shape}\")\n",
    "\n",
    "# Einops way - split d into (heads, d_head) using parentheses\n",
    "x_einops = rearrange(x, 'b s (h d) -> b h s d', h=heads)\n",
    "print(f\"Einops 'b s (h d) -> b h s d': {x_einops.shape}\")\n",
    "\n",
    "print(f\"\\nMatch: {torch.allclose(x_torch, x_einops)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4742c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And back: merge heads back together after attention\n",
    "# (batch, heads, seq_len, d_head) -> (batch, seq_len, d_model)\n",
    "\n",
    "# PyTorch way\n",
    "back_torch = x_torch.transpose(1, 2).contiguous().view(batch, seq_len, d_model)\n",
    "print(f\"PyTorch transpose+view: {back_torch.shape}\")\n",
    "\n",
    "# Einops way - just reverse the pattern!\n",
    "back_einops = rearrange(x_einops, 'b h s d -> b s (h d)')\n",
    "print(f\"Einops 'b h s d -> b s (h d)': {back_einops.shape}\")\n",
    "\n",
    "print(f\"\\nMatch: {torch.allclose(back_torch, back_einops)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49e199",
   "metadata": {},
   "source": [
    "## Practical Example: Multi-Head Attention in One Cell\n",
    "\n",
    "Let's put einsum and einops together for a complete multi-head attention implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihead_attention(q, k, v, heads):\n",
    "    \"\"\"\n",
    "    Multi-head attention using einsum and einops.\n",
    "    \n",
    "    q, k, v: (batch, seq_len, d_model)\n",
    "    Returns: (batch, seq_len, d_model)\n",
    "    \"\"\"\n",
    "    # 1. Split into heads: (batch, seq, d_model) -> (batch, heads, seq, d_head)\n",
    "    q = rearrange(q, 'b s (h d) -> b h s d', h=heads)\n",
    "    k = rearrange(k, 'b s (h d) -> b h s d', h=heads)\n",
    "    v = rearrange(v, 'b s (h d) -> b h s d', h=heads)\n",
    "    \n",
    "    # 2. Attention scores: Q @ K.T for each head\n",
    "    # (batch, heads, seq_q, d) @ (batch, heads, seq_k, d) -> (batch, heads, seq_q, seq_k)\n",
    "    scores = einsum('bhqd,bhkd->bhqk', q, k)\n",
    "    \n",
    "    # 3. Scale and softmax\n",
    "    d_head = q.shape[-1]\n",
    "    scores = scores / (d_head ** 0.5)\n",
    "    attn_weights = torch.softmax(scores, dim=-1)\n",
    "    \n",
    "    # 4. Apply attention to values\n",
    "    # (batch, heads, seq_q, seq_k) @ (batch, heads, seq_k, d) -> (batch, heads, seq_q, d)\n",
    "    out = einsum('bhqk,bhkd->bhqd', attn_weights, v)\n",
    "    \n",
    "    # 5. Merge heads back: (batch, heads, seq, d_head) -> (batch, seq, d_model)\n",
    "    out = rearrange(out, 'b h s d -> b s (h d)')\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb99426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it!\n",
    "batch, seq_len, d_model, heads = 2, 4, 12, 3\n",
    "\n",
    "torch.manual_seed(42)\n",
    "q = torch.randn(batch, seq_len, d_model)\n",
    "k = torch.randn(batch, seq_len, d_model)\n",
    "v = torch.randn(batch, seq_len, d_model)\n",
    "\n",
    "out = multihead_attention(q, k, v, heads)\n",
    "print(f\"Input shape:  {q.shape}\")\n",
    "print(f\"Output shape: {out.shape}\")\n",
    "print(f\"\\nOutput[0, 0, :6]: {out[0, 0, :6].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34102358",
   "metadata": {},
   "source": [
    "## Summary: The Einsum/Einops Mental Model\n",
    "\n",
    "### Einsum\n",
    "- Labels dimensions with letters\n",
    "- Multiply elements where indices align\n",
    "- Sum over indices that don't appear in output\n",
    "- **\"ij,jk->ik\"** = \"sum over j, keep i and k\"\n",
    "\n",
    "### Einops Rearrange  \n",
    "- Names dimensions explicitly\n",
    "- Parentheses merge: `(h w)` combines height and width\n",
    "- Parentheses split: `(h d)` splits into heads and d_head\n",
    "- **\"b h w c -> b c h w\"** = \"move channels before height/width\"\n",
    "\n",
    "### When to use what:\n",
    "| Task | Tool |\n",
    "|------|------|\n",
    "| Matrix multiply, dot products | einsum |\n",
    "| Batch operations | einsum |\n",
    "| Reshape, transpose | einops rearrange |\n",
    "| Split/merge dimensions | einops rearrange |\n",
    "| Self-documenting shapes | both! |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e2b31",
   "metadata": {},
   "source": [
    "## Quick Reference: Common Patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49908f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common einsum patterns\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 5)\n",
    "v = torch.randn(4)\n",
    "\n",
    "print(\"EINSUM PATTERNS:\")\n",
    "print(f\"Sum all:          einsum('ij->')        = {einsum('ij->', A).shape}\")\n",
    "print(f\"Sum rows:         einsum('ij->j')       = {einsum('ij->j', A).shape}\")\n",
    "print(f\"Sum cols:         einsum('ij->i')       = {einsum('ij->i', A).shape}\")\n",
    "print(f\"Transpose:        einsum('ij->ji')      = {einsum('ij->ji', A).shape}\")\n",
    "print(f\"Matrix multiply:  einsum('ij,jk->ik')   = {einsum('ij,jk->ik', A, B).shape}\")\n",
    "print(f\"Dot product:      einsum('i,i->')       = {einsum('i,i->', v, v).shape}\")\n",
    "print(f\"Outer product:    einsum('i,j->ij')     = {einsum('i,j->ij', v, v).shape}\")\n",
    "print(f\"Hadamard:         einsum('ij,ij->ij')   = {einsum('ij,ij->ij', A, A).shape}\")\n",
    "print(f\"Trace:            einsum('ii->')        = {einsum('ii->', torch.randn(3,3)).shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common einops patterns\n",
    "x = torch.randn(2, 3, 4, 5)  # (batch, channels, height, width)\n",
    "\n",
    "print(\"\\nEINOPS REARRANGE PATTERNS:\")\n",
    "print(f\"Original:         {x.shape}\")\n",
    "print(f\"Transpose HW:     'b c h w -> b c w h'     = {rearrange(x, 'b c h w -> b c w h').shape}\")\n",
    "print(f\"NCHW to NHWC:     'b c h w -> b h w c'     = {rearrange(x, 'b c h w -> b h w c').shape}\")\n",
    "print(f\"Flatten spatial:  'b c h w -> b c (h w)'   = {rearrange(x, 'b c h w -> b c (h w)').shape}\")\n",
    "print(f\"Flatten all:      'b c h w -> b (c h w)'   = {rearrange(x, 'b c h w -> b (c h w)').shape}\")\n",
    "print(f\"Split channels:   'b (g c) h w -> b g c h w' = {rearrange(x, 'b (g c) h w -> b g c h w', g=1).shape}\")\n",
    "print(f\"Merge batch+chan: 'b c h w -> (b c) h w'   = {rearrange(x, 'b c h w -> (b c) h w').shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2a4797",
   "metadata": {},
   "source": [
    "## Bonus: Image Patching for Vision Transformers\n",
    "\n",
    "ViT needs to split images into patches. This is a perfect use case for einops!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split image into patches\n",
    "# Input: (batch, channels, height, width)\n",
    "# Output: (batch, num_patches, patch_size * patch_size * channels)\n",
    "\n",
    "batch, channels, height, width = 2, 3, 8, 8\n",
    "patch_size = 4\n",
    "\n",
    "images = torch.randn(batch, channels, height, width)\n",
    "print(f\"Input images: {images.shape}\")\n",
    "\n",
    "# Split into patches and flatten each patch\n",
    "patches = rearrange(\n",
    "    images, \n",
    "    'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', \n",
    "    p1=patch_size, \n",
    "    p2=patch_size\n",
    ")\n",
    "\n",
    "num_patches = (height // patch_size) * (width // patch_size)\n",
    "patch_dim = patch_size * patch_size * channels\n",
    "\n",
    "print(f\"Patches: {patches.shape}\")\n",
    "print(f\"  num_patches = ({height}//{patch_size}) × ({width}//{patch_size}) = {num_patches}\")\n",
    "print(f\"  patch_dim = {patch_size} × {patch_size} × {channels} = {patch_dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e52d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the patching\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "# Create a simple test image with a pattern\n",
    "test_img = torch.zeros(1, 1, 8, 8)\n",
    "test_img[0, 0, :4, :4] = 1  # top-left = white\n",
    "test_img[0, 0, :4, 4:] = 0.5  # top-right = gray\n",
    "test_img[0, 0, 4:, :4] = 0.3  # bottom-left = dark gray\n",
    "test_img[0, 0, 4:, 4:] = 0.7  # bottom-right = light gray\n",
    "\n",
    "# Show original\n",
    "axes[0].imshow(test_img[0, 0], cmap='gray', vmin=0, vmax=1)\n",
    "axes[0].set_title('Original 8×8')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Extract patches\n",
    "test_patches = rearrange(test_img, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=4, p2=4)\n",
    "\n",
    "# Show each patch\n",
    "for i in range(4):\n",
    "    patch = test_patches[0, i].reshape(4, 4)\n",
    "    axes[i+1].imshow(patch, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[i+1].set_title(f'Patch {i}')\n",
    "    axes[i+1].axis('off')\n",
    "\n",
    "plt.suptitle(\"Image → Patches (for Vision Transformer)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e2237",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Einsum** expresses tensor operations by labeling dimensions\n",
    "   - Same index = align/multiply element-wise\n",
    "   - Missing from output = sum over it\n",
    "   - Makes complex operations like attention readable\n",
    "\n",
    "2. **Einops rearrange** expresses shape transformations with named dimensions\n",
    "   - No more cryptic `permute(0, 3, 1, 2)`\n",
    "   - Parentheses split/merge dimensions\n",
    "   - Self-documenting code\n",
    "\n",
    "3. **Both tools** make your code:\n",
    "   - Easier to read\n",
    "   - Easier to debug (shapes are explicit)\n",
    "   - Less error-prone (no off-by-one dimension mistakes)\n",
    "\n",
    "**Practice**: Next time you write a `transpose`, `reshape`, or `bmm`, try expressing it with einsum/einops first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e757f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        # Create a learnable position embedding matrix of shape (n_ctx, d_model)\n",
    "        # Each row corresponds to a position (up to max sequence length), each column to a dimension in the embedding\n",
    "        self.W_pos = nn.Parameter(t.empty((cfg.n_ctx, cfg.d_model)))\n",
    "        # Initialize the embedding weights with a normal distribution (mean=0, std=cfg.init_range)\n",
    "        # This initialization helps with model stability at the start\n",
    "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
    "\n",
    "    def forward(\n",
    "        self, tokens: Int[Tensor, \"batch position\"]\n",
    "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
    "        # tokens: input tensor of token indices, shape (batch, position)\n",
    "        # Goal: provide a position embedding per position per batch for further processing\n",
    "        batch, seq_len = tokens.shape  # Unpack number of examples and sequence length\n",
    "        # Select position embeddings for the required sequence length ([:seq_len] over positions)\n",
    "        # Shape at this point: (seq_len, d_model)\n",
    "        # Use einops.repeat to expand these embeddings along the batch dimension so each batch gets same position ids\n",
    "        # Output shape: (batch, seq_len, d_model)\n",
    "        return einops.repeat(\n",
    "            self.W_pos[:seq_len],           # only positions up to sequence length\n",
    "            \"seq d_model -> batch seq d_model\",  # instruct einops on reshaping: broadcast across batch\n",
    "            batch=batch\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7b2fe",
   "metadata": {},
   "source": [
    "# Advanced: Let's build up the transformer as a bunch of einops operations\n",
    "\n",
    "We'll use a batch size of 2, sequence length of 3, and embedding dimension of 4. We'll use a hidden dimension of 8 for the MLP. \n",
    "\n",
    "This is the original transformer but using a few tricks. \n",
    "- Self attention (encoder only)\n",
    "- Multi head attention\n",
    "- RoPE\n",
    "- LayerNorm before attention\n",
    "- KV cache to save on compute\n",
    "- MLP with GELU activation\n",
    "- Final layer norm and linear output\n",
    "\n",
    "The goal here is not to focus on the details of the transformer, but rather to show how we could use only einops to create one.\n",
    "\n",
    "1. Embeddings\n",
    "2. RoPE\n",
    "3. Layernorm\n",
    "4. Attention (KV Cache, dot product, softmax, mask, keys, sum, add to residual)\n",
    "5. MLP\n",
    "6. Output\n",
    "7. Multiple heads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
